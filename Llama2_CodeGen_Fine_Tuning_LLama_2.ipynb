{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AhmedSSoliman/Llama2-CodeGen-Fine-Tuning-LLama-2/blob/master/Llama2_CodeGen_Fine_Tuning_LLama_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95fI76pVYT7i",
        "outputId": "36f74075-7a9e-4a04-8c54-6a5449351f22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## Finetune Llama-2-7b on a Google colab\n",
        "\n",
        "This notebook shows how to fine-tune the Llama-2-7b model on Google colab using AutoTrain.\n",
        "\n",
        "We will leverage PEFT library from Hugging Face ecosystem, as well as QLoRA for more memory efficient finetuning"
      ],
      "metadata": {
        "id": "HBXoIpaDzIFx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Install Dependencies**"
      ],
      "metadata": {
        "id": "gfg4ahEYypTp"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-tTvEF1RT3y"
      },
      "source": [
        "Run the cells below to setup and install the required libraries. For our experiment we will need `accelerate`, `peft`, `transformers`, `datasets` and TRL to leverage the recent [`SFTTrainer`](https://huggingface.co/docs/trl/main/en/sft_trainer). We will use `bitsandbytes` to [quantize the base model into 4bit](https://huggingface.co/blog/4bit-transformers-bitsandbytes). We will also install `einops` as it is a requirement to load Falcon models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNnkgBq7Q3EU",
        "outputId": "dedf5388-bde2-4059-a7dd-e70770ab88d2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m92.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.2/244.2 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m492.2/492.2 kB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m86.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for peft (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.6/92.6 MB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.5/188.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m214.7/214.7 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -q -U trl transformers accelerate git+https://github.com/huggingface/peft.git\n",
        "!pip install -q datasets bitsandbytes einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbHZ1MLjtkQm",
        "outputId": "5eed0fd7-eeb7-4cf0-eb42-4fdf7fd68b74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "    \n",
            "    A token is already saved on your machine. Run `huggingface-cli whoami` to get more information or `huggingface-cli logout` if you want to log out.\n",
            "    Setting a new token will erase the existing one.\n",
            "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
            "Token: "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:11:37] Energy consumed for RAM : 0.003020 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:11:37] Energy consumed for all GPUs : 0.009861 kWh. Total GPU Power : 31.445 W\n",
            "[codecarbon INFO @ 13:11:37] Energy consumed for all CPUs : 0.013457 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:11:37] 0.026337 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Add token as git credential? (Y/n) y\n",
            "Token is valid (permission: write).\n",
            "\u001b[1m\u001b[31mCannot authenticate through git-credential as no helper is defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub.\n",
            "Run the following command in your terminal in case you want to set the 'store' credential helper as default.\n",
            "\n",
            "git config --global credential.helper store\n",
            "\n",
            "Read https://git-scm.com/book/en/v2/Git-Tools-Credential-Storage for more details.\u001b[0m\n",
            "Token has not been saved to git credential helper.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rnqmq7amRrU8"
      },
      "source": [
        "# **Dataset**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"kejian/codesearchnet-python-raw-457k\"\n",
        "dataset = load_dataset(dataset_name)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xp5Mn28z_9q4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = dataset.remove_columns(['repo', 'path', 'url', 'code_tokens', 'docstring_tokens', 'language', 'partition', 'avg_line_len'])"
      ],
      "metadata": {
        "id": "GwOxucMMB9Sx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the dataset to a Pandas DataFrame\n",
        "\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(dataset)\n",
        "\n",
        "\n",
        "#read csv file\n",
        "#df = pd.read_csv('train.csv')"
      ],
      "metadata": {
        "id": "BxK8rRBrAMWV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment removal from the docstring column"
      ],
      "metadata": {
        "id": "DFNAdv5wAuTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "#regex for matching any comments starts and ends with \"\"\"\n",
        "pattern1='(?s)(\"\"\")(.*?)(\"\"\")'\n",
        "#regex for matching any comments starts and ends with '''\n",
        "pattern2= '(?s)(\\''')(.*?)(\\''')'\n",
        "#regex for matching any comments starts with #\n",
        "pattern3 = r'(#.*)'\n",
        "#iterate over all rows in df\n",
        "for i in range(0,len(df)):\n",
        "    print('process row# : ',i)\n",
        "    row=df.iloc[i]\n",
        "    code=row[0]\n",
        "    code=re.sub(pattern1, '', code)\n",
        "    code=re.sub(pattern2, '', code)\n",
        "    code=re.sub(pattern3, '', code)\n",
        "    row[0]=code\n",
        "\n",
        "df.to_csv('trains_clean.csv')\n",
        "\n"
      ],
      "metadata": {
        "id": "qqGPVZpj7Xwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Step 1: Load CSV file as `DatasetDict`\n",
        "csv_dataset = load_dataset(\"csv\", data_files=\"train_clean.csv\")\n",
        "\n",
        "# Step 2: Push `DatasetDict` object to HuggingFace Hub\n",
        "csv_dataset.push_to_hub(\"AhmedSSoliman/CodeSearchNet\")"
      ],
      "metadata": {
        "id": "wIWte8LL_pqe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Configure Dataset for training**"
      ],
      "metadata": {
        "id": "OFcCMFzCWEDO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86,
          "referenced_widgets": [
            "3a1b1dbe3bae41109d063853bd34374a",
            "d6bb9105ed604843a9b5d78e1f5a1684",
            "90c7541f5d274bf9af2c8887cbe2cc39",
            "6016d6696875478aa25b20b0eb6e5cae",
            "71b2df00163b40358b10e8fc3f9b8d45",
            "6f8ff5c66848447c8adc9735642fb434",
            "6d52b567a5584451a5470c4cfc4631a0",
            "2bddb364f8ad4f3982e5f69656d89388",
            "984cc05deea64b8eb9263af7fdeacca2",
            "d5e4365a3c074c1eaab5c71530dfe2c4",
            "bf1548816c7647f8baf3bb005b9c33b3"
          ]
        },
        "id": "0X3kHnskSWU4",
        "outputId": "70c09b6b-4fe0-43b5-85fc-058fcb30966d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Found cached dataset csv (/root/.cache/huggingface/datasets/AhmedSSoliman___csv/AhmedSSoliman--CodeSearchNet-37334a6d9e3e1840/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a1b1dbe3bae41109d063853bd34374a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset_name = \"AhmedSSoliman/CodeSearchNet\"\n",
        "dataset = load_dataset(dataset_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Select only 2000 rows random from the dataset"
      ],
      "metadata": {
        "id": "qUvuXiwb9T4C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3zk3yVJ4_g7"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "train_dataset = dataset['train']\n",
        "# Get the total number of records in the dataset\n",
        "num_records = len(train_dataset)\n",
        "\n",
        "# Generate a list of 100k random indices\n",
        "indices = random.sample(range(num_records), 2000)\n",
        "\n",
        "# Select the 100k records with the random indices\n",
        "train_dataset = train_dataset.select(indices)\n",
        "dataset = train_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1Iq4gvr5x7r",
        "outputId": "b88050aa-60c2-4fc7-ad8c-8d341bce9dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['code', 'docstring'],\n",
              "    num_rows: 2000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "# Convert the dataset to a Pandas DataFrame\n",
        "df = pd.DataFrame(dataset)"
      ],
      "metadata": {
        "id": "CxQ57VXcWBOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "J2v-ar41YkWm",
        "outputId": "530db663-7ba6-409f-c4f0-9487d65fb10b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                code  \\\n",
              "0  def parse_hh_mm_ss(self):\\n        \\n        s...   \n",
              "1  def specificity(self):\\n        \\n        ids ...   \n",
              "2  def fw_int_to_hex(*args):\\n    \\n    return bi...   \n",
              "3  def tryCKeywords(self, block, isBrace):\\n     ...   \n",
              "4  def local_obj(self):\\n        \\n        if sel...   \n",
              "\n",
              "                                           docstring  \n",
              "0    Parses raw time\\n\\n        :return: Time parsed  \n",
              "1  Loosely based on http://www.w3.org/TR/REC-CSS2...  \n",
              "2  Pack integers into hex string.\\n\\n    Use litt...  \n",
              "3  Check for if, else, while, do, switch, private...  \n",
              "4  Buffered result of :meth:`make` which is (prob...  "
            ],
            "text/html": [
              "\n",
              "\n",
              "  <div id=\"df-8fae38e4-50de-4b1b-b656-8b0d9f8f3557\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>code</th>\n",
              "      <th>docstring</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>def parse_hh_mm_ss(self):\\n        \\n        s...</td>\n",
              "      <td>Parses raw time\\n\\n        :return: Time parsed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>def specificity(self):\\n        \\n        ids ...</td>\n",
              "      <td>Loosely based on http://www.w3.org/TR/REC-CSS2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>def fw_int_to_hex(*args):\\n    \\n    return bi...</td>\n",
              "      <td>Pack integers into hex string.\\n\\n    Use litt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>def tryCKeywords(self, block, isBrace):\\n     ...</td>\n",
              "      <td>Check for if, else, while, do, switch, private...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>def local_obj(self):\\n        \\n        if sel...</td>\n",
              "      <td>Buffered result of :meth:`make` which is (prob...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fae38e4-50de-4b1b-b656-8b0d9f8f3557')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "\n",
              "\n",
              "\n",
              "    <div id=\"df-e367070f-c7b7-4830-9a6e-eb6243730546\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-e367070f-c7b7-4830-9a6e-eb6243730546')\"\n",
              "              title=\"Suggest charts.\"\n",
              "              style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "    </div>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "    background-color: #E8F0FE;\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: #1967D2;\n",
              "    height: 32px;\n",
              "    padding: 0 0 0 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: #E2EBFA;\n",
              "    box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: #174EA6;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "    background-color: #3B4455;\n",
              "    fill: #D2E3FC;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart:hover {\n",
              "    background-color: #434B5C;\n",
              "    box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "    filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "    fill: #FFFFFF;\n",
              "  }\n",
              "</style>\n",
              "\n",
              "    <script>\n",
              "      async function quickchart(key) {\n",
              "        const containerElement = document.querySelector('#' + key);\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      }\n",
              "    </script>\n",
              "\n",
              "      <script>\n",
              "\n",
              "function displayQuickchartButton(domScope) {\n",
              "  let quickchartButtonEl =\n",
              "    domScope.querySelector('#df-e367070f-c7b7-4830-9a6e-eb6243730546 button.colab-df-quickchart');\n",
              "  quickchartButtonEl.style.display =\n",
              "    google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "}\n",
              "\n",
              "        displayQuickchartButton(document);\n",
              "      </script>\n",
              "      <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8fae38e4-50de-4b1b-b656-8b0d9f8f3557 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8fae38e4-50de-4b1b-b656-8b0d9f8f3557');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Add text column to the dataset which contains the Question and the answer of this quesion through the dataset"
      ],
      "metadata": {
        "id": "_bN1IyZz9057"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_col = []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "\n",
        "    input_query = str(row['docstring'])\n",
        "    response = str(row['code'])\n",
        "\n",
        "    if(len(input_query.strip())==0):\n",
        "      text = \"### Input: \\n\" + input_query + \"\\n### Response: \\n\" + response\n",
        "\n",
        "    else:\n",
        "      text =  (\n",
        "           \"### Input: \\n\"\n",
        "          + input_query\n",
        "          + \"\\n### Response: \\n\"\n",
        "          + response\n",
        "      )\n",
        "\n",
        "      text_col.append(text)\n"
      ],
      "metadata": {
        "id": "IrAbAMwMU8aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[:, \"text\"] = text_col\n",
        "print(df.head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RKscEbYFabHR",
        "outputId": "b21d4494-0dac-4933-8e78-8b858c237027"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method NDFrame.head of                                                    code  \\\n",
            "0     def parse_hh_mm_ss(self):\\n        \\n        s...   \n",
            "1     def specificity(self):\\n        \\n        ids ...   \n",
            "2     def fw_int_to_hex(*args):\\n    \\n    return bi...   \n",
            "3     def tryCKeywords(self, block, isBrace):\\n     ...   \n",
            "4     def local_obj(self):\\n        \\n        if sel...   \n",
            "...                                                 ...   \n",
            "1995  def notify_created(room, event, user):\\n    \\n...   \n",
            "1996  def julian(mon, day, year):\\n    \\n    ig = 15...   \n",
            "1997  def processMailList(platformNames=[], emails=[...   \n",
            "1998  def push_progress(self, status, object_id, pro...   \n",
            "1999  def unauthorized_callback(self):\\n        \\n  ...   \n",
            "\n",
            "                                              docstring  \\\n",
            "0       Parses raw time\\n\\n        :return: Time parsed   \n",
            "1     Loosely based on http://www.w3.org/TR/REC-CSS2...   \n",
            "2     Pack integers into hex string.\\n\\n    Use litt...   \n",
            "3     Check for if, else, while, do, switch, private...   \n",
            "4     Buffered result of :meth:`make` which is (prob...   \n",
            "...                                                 ...   \n",
            "1995  Notifies about the creation of a chatroom.\\n\\n...   \n",
            "1996                                 returns julian day   \n",
            "1997  Method to perform the email search.\\n\\n    Arg...   \n",
            "1998  Prints progress information.\\n\\n        :param...   \n",
            "1999  Redirect to login url with next param set as r...   \n",
            "\n",
            "                                                   text  \n",
            "0     ### Input: \\nParses raw time\\n\\n        :retur...  \n",
            "1     ### Input: \\nLoosely based on http://www.w3.or...  \n",
            "2     ### Input: \\nPack integers into hex string.\\n\\...  \n",
            "3     ### Input: \\nCheck for if, else, while, do, sw...  \n",
            "4     ### Input: \\nBuffered result of :meth:`make` w...  \n",
            "...                                                 ...  \n",
            "1995  ### Input: \\nNotifies about the creation of a ...  \n",
            "1996  ### Input: \\nreturns julian day\\n### Response:...  \n",
            "1997  ### Input: \\nMethod to perform the email searc...  \n",
            "1998  ### Input: \\nPrints progress information.\\n\\n ...  \n",
            "1999  ### Input: \\nRedirect to login url with next p...  \n",
            "\n",
            "[2000 rows x 3 columns]>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"train.csv\", index = False)\n"
      ],
      "metadata": {
        "id": "hbu3hNyyaYkw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pushing the CSV file data to the huggingface hub"
      ],
      "metadata": {
        "id": "hSA-37PV84P6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "# Step 1: Load CSV file as `DatasetDict`\n",
        "csv_dataset = load_dataset(\"csv\", data_files=\"train.csv\")\n",
        "\n",
        "# Step 2: Push `DatasetDict` object to HuggingFace Hub\n",
        "csv_dataset.push_to_hub(\"AhmedSSoliman/CodeSearchNet-py\")\n"
      ],
      "metadata": {
        "id": "7hI4QN0JhtLC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is another function to add a text column which contains the question and the corresponding answer"
      ],
      "metadata": {
        "id": "uyUq48Ou-ODN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DcOakzzw6lcT"
      },
      "outputs": [],
      "source": [
        "def formatting_prompts_func(example):\n",
        "    output_texts = []\n",
        "    for i in range(len(example['code'])):\n",
        "        text = f\"### Question: {example['docstring'][i]}\\n ### Answer: {example['code'][i]}\"\n",
        "        output_texts.append(text)\n",
        "    return output_texts\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Autotrain**"
      ],
      "metadata": {
        "id": "nhRk3zGlb0_A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autotrain-advanced"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "JoQTKiclb4NP",
        "outputId": "51004aa4-5f98-48d8-df2e-6d0db316df6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting autotrain-advanced\n",
            "  Downloading autotrain_advanced-0.6.5-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.3/89.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting albumentations==1.3.0 (from autotrain-advanced)\n",
            "  Downloading albumentations-1.3.0-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.5/123.5 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting codecarbon==2.2.3 (from autotrain-advanced)\n",
            "  Downloading codecarbon-2.2.3-py3-none-any.whl (174 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m174.1/174.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting datasets[vision]~=2.13.0 (from autotrain-advanced)\n",
            "  Downloading datasets-2.13.1-py3-none-any.whl (486 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m486.2/486.2 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting evaluate==0.3.0 (from autotrain-advanced)\n",
            "  Downloading evaluate-0.3.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipadic==1.0.0 (from autotrain-advanced)\n",
            "  Downloading ipadic-1.0.0.tar.gz (13.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jiwer==2.2.0 (from autotrain-advanced)\n",
            "  Downloading jiwer-2.2.0-py3-none-any.whl (13 kB)\n",
            "Collecting joblib==1.2.0 (from autotrain-advanced)\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting loguru==0.7.0 (from autotrain-advanced)\n",
            "  Downloading loguru-0.7.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.0/60.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nltk==3.5 (from autotrain-advanced)\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.5.3 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (1.5.3)\n",
            "Collecting Pillow==8.2.0 (from autotrain-advanced)\n",
            "  Downloading Pillow-8.2.0.tar.gz (47.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.9/47.9 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting protobuf==4.23.4 (from autotrain-advanced)\n",
            "  Downloading protobuf-4.23.4-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m31.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic==1.10.11 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (1.10.11)\n",
            "Requirement already satisfied: pyyaml==6.0.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (6.0.1)\n",
            "Collecting sacremoses==0.0.53 (from autotrain-advanced)\n",
            "  Downloading sacremoses-0.0.53.tar.gz (880 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m880.6/880.6 kB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scikit-learn==1.2.2 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (1.2.2)\n",
            "Collecting sentencepiece==0.1.99 (from autotrain-advanced)\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tqdm==4.62.1 (from autotrain-advanced)\n",
            "  Downloading tqdm-4.62.1-py2.py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.2/76.2 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: werkzeug==2.3.6 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.3.6)\n",
            "Requirement already satisfied: huggingface-hub>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (0.16.4)\n",
            "Collecting triton==2.0.0.post1 (from autotrain-advanced)\n",
            "  Downloading triton-2.0.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (63.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests==2.31.0 (from autotrain-advanced)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.37.0 (from autotrain-advanced)\n",
            "  Downloading gradio-3.37.0-py3-none-any.whl (19.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/19.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: einops==0.6.1 in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (0.6.1)\n",
            "Collecting invisible-watermark==0.2.0 (from autotrain-advanced)\n",
            "  Downloading invisible_watermark-0.2.0-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (2.12.3)\n",
            "Requirement already satisfied: peft in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (0.5.0.dev0)\n",
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (0.4.7)\n",
            "Collecting tiktoken (from autotrain-advanced)\n",
            "  Downloading tiktoken-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (4.31.0)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (0.21.0)\n",
            "Collecting diffusers (from autotrain-advanced)\n",
            "  Downloading diffusers-0.18.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m71.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: bitsandbytes in /usr/local/lib/python3.10/dist-packages (from autotrain-advanced) (0.41.0)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->autotrain-advanced) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->autotrain-advanced) (1.10.1)\n",
            "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->autotrain-advanced) (0.19.3)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->autotrain-advanced) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations==1.3.0->autotrain-advanced) (4.8.0.74)\n",
            "Collecting arrow (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading arrow-1.2.3-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.4/66.4 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pynvml (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading pynvml-11.5.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (5.9.5)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (9.0.0)\n",
            "Collecting fuzzywuzzy (from codecarbon==2.2.3->autotrain-advanced)\n",
            "  Downloading fuzzywuzzy-0.18.0-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from codecarbon==2.2.3->autotrain-advanced) (8.1.6)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (2.14.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (0.3.7)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (2023.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate==0.3.0->autotrain-advanced) (23.1)\n",
            "Collecting responses<0.19 (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading aiofiles-23.1.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: aiohttp~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.37.0->autotrain-advanced) (3.8.4)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.37.0->autotrain-advanced) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading fastapi-0.100.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.7/65.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading ffmpy-0.3.1.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client>=0.2.10 (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading gradio_client-0.2.10-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.0/289.0 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading httpx-0.24.1-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.37.0->autotrain-advanced) (3.1.2)\n",
            "Requirement already satisfied: markdown-it-py[linkify]>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.37.0->autotrain-advanced) (3.0.0)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.37.0->autotrain-advanced) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.37.0->autotrain-advanced) (3.7.1)\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading mdit_py_plugins-0.3.3-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.5/50.5 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson~=3.0 (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading orjson-3.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.7/138.7 kB\u001b[0m \u001b[31m17.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading python_multipart-0.0.6-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.7/45.7 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.37.0->autotrain-advanced) (4.7.1)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading uvicorn-0.23.1-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.5/59.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (1.4.1)\n",
            "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (4.7.0.72)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from invisible-watermark==0.2.0->autotrain-advanced) (2.0.1+cu118)\n",
            "Collecting python-Levenshtein (from jiwer==2.2.0->autotrain-advanced)\n",
            "  Downloading python_Levenshtein-0.21.1-py3-none-any.whl (9.4 kB)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from nltk==3.5->autotrain-advanced) (2022.10.31)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests==2.31.0->autotrain-advanced) (2023.5.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sacremoses==0.0.53->autotrain-advanced) (1.16.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.2.2->autotrain-advanced) (3.2.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0.post1->autotrain-advanced) (3.25.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0.post1->autotrain-advanced) (3.12.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0.post1->autotrain-advanced) (16.0.6)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets[vision]~=2.13.0->autotrain-advanced) (9.0.0)\n",
            "Collecting dill (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->autotrain-advanced) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.5.3->autotrain-advanced) (2022.7.1)\n",
            "Requirement already satisfied: importlib-metadata in /usr/lib/python3/dist-packages (from diffusers->autotrain-advanced) (4.6.4)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from peft->autotrain-advanced) (0.3.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.56.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (3.4.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (67.7.2)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (0.7.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.10/dist-packages (from tensorboard->autotrain-advanced) (0.40.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers->autotrain-advanced) (0.13.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.37.0->autotrain-advanced) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.37.0->autotrain-advanced) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.37.0->autotrain-advanced) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.37.0->autotrain-advanced) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.37.0->autotrain-advanced) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp~=3.0->gradio==3.37.0->autotrain-advanced) (1.3.1)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.37.0->autotrain-advanced) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.37.0->autotrain-advanced) (4.3.3)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.37.0->autotrain-advanced) (0.12.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard->autotrain-advanced) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->autotrain-advanced) (0.1.2)\n",
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.37.0->autotrain-advanced) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.37.0->autotrain-advanced) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.37.0->autotrain-advanced) (4.41.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.37.0->autotrain-advanced) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.37.0->autotrain-advanced) (3.1.0)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting mdit-py-plugins<=0.3.3 (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading mdit_py_plugins-0.3.2-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.1-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.5/46.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.3.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.8-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.7-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading mdit_py_plugins-0.2.6-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.5-py3-none-any.whl (39 kB)\n",
            "INFO: pip is looking at multiple versions of mdit-py-plugins to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading mdit_py_plugins-0.2.4-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.3-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.2-py3-none-any.whl (39 kB)\n",
            "  Downloading mdit_py_plugins-0.2.1-py3-none-any.whl (38 kB)\n",
            "  Downloading mdit_py_plugins-0.2.0-py3-none-any.whl (38 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading mdit_py_plugins-0.1.0-py3-none-any.whl (37 kB)\n",
            "Collecting markdown-it-py[linkify]>=2.0.0 (from gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m87.5/87.5 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading markdown_it_py-2.2.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.5/84.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->autotrain-advanced) (3.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->autotrain-advanced) (2.25.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.16.1->albumentations==1.3.0->autotrain-advanced) (2023.7.10)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->invisible-watermark==0.2.0->autotrain-advanced) (1.11.1)\n",
            "INFO: pip is looking at multiple versions of torch to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torch (from invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading torch-2.0.1-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m68.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu11==11.7.101 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91 (from torch->invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m14.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch (from invisible-watermark==0.2.0->autotrain-advanced)\n",
            "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading torch-1.13.1-cp310-cp310-manylinux1_x86_64.whl (887.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m887.5/887.5 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11>=0.8 (from uvicorn>=0.14.0->gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.28.0,>=0.27.0 (from fastapi->gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpcore<0.18.0,>=0.15.0 (from httpx->gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading httpcore-0.17.3-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.5/74.5 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.37.0->autotrain-advanced) (1.3.0)\n",
            "INFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting multiprocess (from evaluate==0.3.0->autotrain-advanced)\n",
            "  Downloading multiprocess-0.70.14-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Levenshtein==0.21.1 (from python-Levenshtein->jiwer==2.2.0->autotrain-advanced)\n",
            "  Downloading Levenshtein-0.21.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (172 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.5/172.5 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rapidfuzz<4.0.0,>=2.3.0 (from Levenshtein==0.21.1->python-Levenshtein->jiwer==2.2.0->autotrain-advanced)\n",
            "  Downloading rapidfuzz-3.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.18.0,>=0.15.0->httpx->gradio==3.37.0->autotrain-advanced) (3.7.1)\n",
            "INFO: pip is looking at multiple versions of imageio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting imageio>=2.4.1 (from scikit-image>=0.16.1->albumentations==1.3.0->autotrain-advanced)\n",
            "  Downloading imageio-2.31.1-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.31.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.30.0-py3-none-any.whl (312 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m312.7/312.7 kB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.29.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m93.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.28.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.28.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.27.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m106.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of imageio to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading imageio-2.26.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.26.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m110.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.25.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m90.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.24.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.23.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m108.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading imageio-2.22.4-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m110.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m110.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.22.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m102.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.21.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m91.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.20.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.5-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.3-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m106.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.2-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m105.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.1-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m107.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.19.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m80.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.18.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m103.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.17.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m100.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.16.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.16.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m103.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.15.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.14.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m105.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.14.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m104.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.4-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.3-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m105.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m103.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.13.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m104.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.12.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m107.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.11.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m93.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.11.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m103.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.5-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.4-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.3-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m91.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.2-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m112.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.10.1-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading imageio-2.9.0-py3-none-any.whl (3.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m100.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.37.0->autotrain-advanced) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.37.0->autotrain-advanced)\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->autotrain-advanced) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard->autotrain-advanced) (3.2.2)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->httpcore<0.18.0,>=0.15.0->httpx->gradio==3.37.0->autotrain-advanced) (1.1.2)\n",
            "Building wheels for collected packages: ipadic, nltk, Pillow, sacremoses, ffmpy\n",
            "  Building wheel for ipadic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipadic: filename=ipadic-1.0.0-py3-none-any.whl size=13556703 sha256=7dc0fff7230e754339a63c5a727afb80397d164b3566ffd075dc7b364cbaceeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5b/ea/e3/2f6e0860a327daba3b030853fce4483ed37468bbf1101c59c3\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434677 sha256=7256012b7ec248d36b002cba8527eb86f58f933ef16ce190f1e5f8f1fdd2a8ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/ab/82/f9667f6f884d272670a15382599a9c753a1dfdc83f7412e37d\n",
            "  Building wheel for Pillow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Pillow: filename=Pillow-8.2.0-cp310-cp310-linux_x86_64.whl size=1159096 sha256=25f006014f1ccc9e9de22aec09644bee041a197938a80d564ce5754127b10f29\n",
            "  Stored in directory: /root/.cache/pip/wheels/70/8a/2c/7f8208f565545ea014c5644ed58e3dece5a462b98fe8d6d148\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.53-py3-none-any.whl size=895241 sha256=95af241c4dda6955be9aec9cce9dedc6e71a27931c29c54fa8ce3a6d616582a3\n",
            "  Stored in directory: /root/.cache/pip/wheels/00/24/97/a2ea5324f36bc626e1ea0267f33db6aa80d157ee977e9e42fb\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.1-py3-none-any.whl size=5579 sha256=6d6d8e74798b160e1b73ce8bfe8cf118a86dbc4f1a7f42618e062b2b867d76fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/a6/d1/1c0828c304a4283b2c1639a09ad86f83d7c487ef34c6b4a1bf\n",
            "Successfully built ipadic nltk Pillow sacremoses ffmpy\n",
            "Installing collected packages: sentencepiece, pydub, ipadic, fuzzywuzzy, ffmpy, websockets, uc-micro-py, tqdm, semantic-version, requests, rapidfuzz, python-multipart, pynvml, protobuf, Pillow, orjson, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cublas-cu11, markdown-it-py, loguru, joblib, h11, dill, aiofiles, uvicorn, tiktoken, starlette, sacremoses, responses, nvidia-cudnn-cu11, nltk, multiprocess, mdit-py-plugins, linkify-it-py, Levenshtein, imageio, httpcore, arrow, torch, python-Levenshtein, httpx, fastapi, diffusers, codecarbon, triton, jiwer, invisible-watermark, gradio-client, datasets, albumentations, gradio, evaluate, autotrain-advanced\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.65.0\n",
            "    Uninstalling tqdm-4.65.0:\n",
            "      Successfully uninstalled tqdm-4.65.0\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.27.1\n",
            "    Uninstalling requests-2.27.1:\n",
            "      Successfully uninstalled requests-2.27.1\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 8.4.0\n",
            "    Uninstalling Pillow-8.4.0:\n",
            "      Successfully uninstalled Pillow-8.4.0\n",
            "  Attempting uninstall: markdown-it-py\n",
            "    Found existing installation: markdown-it-py 3.0.0\n",
            "    Uninstalling markdown-it-py-3.0.0:\n",
            "      Successfully uninstalled markdown-it-py-3.0.0\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.3.1\n",
            "    Uninstalling joblib-1.3.1:\n",
            "      Successfully uninstalled joblib-1.3.1\n",
            "  Attempting uninstall: dill\n",
            "    Found existing installation: dill 0.3.7\n",
            "    Uninstalling dill-0.3.7:\n",
            "      Successfully uninstalled dill-0.3.7\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.8.1\n",
            "    Uninstalling nltk-3.8.1:\n",
            "      Successfully uninstalled nltk-3.8.1\n",
            "  Attempting uninstall: multiprocess\n",
            "    Found existing installation: multiprocess 0.70.15\n",
            "    Uninstalling multiprocess-0.70.15:\n",
            "      Successfully uninstalled multiprocess-0.70.15\n",
            "  Attempting uninstall: imageio\n",
            "    Found existing installation: imageio 2.25.1\n",
            "    Uninstalling imageio-2.25.1:\n",
            "      Successfully uninstalled imageio-2.25.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 2.0.0\n",
            "    Uninstalling triton-2.0.0:\n",
            "      Successfully uninstalled triton-2.0.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.14.0\n",
            "    Uninstalling datasets-2.14.0:\n",
            "      Successfully uninstalled datasets-2.14.0\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 1.2.1\n",
            "    Uninstalling albumentations-1.2.1:\n",
            "      Successfully uninstalled albumentations-1.2.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.27.1, but you have requests 2.31.0 which is incompatible.\n",
            "torchaudio 2.0.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchdata 0.6.1 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchtext 0.15.2 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\n",
            "torchvision 0.15.2+cu118 requires torch==2.0.1, but you have torch 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Levenshtein-0.21.1 Pillow-8.2.0 aiofiles-23.1.0 albumentations-1.3.0 arrow-1.2.3 autotrain-advanced-0.6.5 codecarbon-2.2.3 datasets-2.13.1 diffusers-0.18.2 dill-0.3.6 evaluate-0.3.0 fastapi-0.100.0 ffmpy-0.3.1 fuzzywuzzy-0.18.0 gradio-3.37.0 gradio-client-0.2.10 h11-0.14.0 httpcore-0.17.3 httpx-0.24.1 imageio-2.9.0 invisible-watermark-0.2.0 ipadic-1.0.0 jiwer-2.2.0 joblib-1.2.0 linkify-it-py-2.0.2 loguru-0.7.0 markdown-it-py-2.2.0 mdit-py-plugins-0.3.3 multiprocess-0.70.14 nltk-3.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 orjson-3.9.2 protobuf-4.23.4 pydub-0.25.1 pynvml-11.5.0 python-Levenshtein-0.21.1 python-multipart-0.0.6 rapidfuzz-3.1.2 requests-2.31.0 responses-0.18.0 sacremoses-0.0.53 semantic-version-2.10.0 sentencepiece-0.1.99 starlette-0.27.0 tiktoken-0.4.0 torch-1.13.1 tqdm-4.62.1 triton-2.0.0.post1 uc-micro-py-1.0.2 uvicorn-0.23.1 websockets-11.0.3\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_multiprocess",
                  "datasets",
                  "dill",
                  "multiprocess",
                  "requests",
                  "tqdm"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain setup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "27yWvHI7cJvi",
        "outputId": "fd24081c-1cde-4350-d09a-f11064216632"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-26 11:49:20.699683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2023-07-26 11:49:22.960\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mautotrain.cli.run_dreambooth\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m15\u001b[0m - \u001b[33m\u001b[1m❌ Some DreamBooth components are missing! Please run `autotrain setup` to install it. Ignore this warning if you are not using DreamBooth or running `autotrain setup` already.\u001b[0m\n",
            "\u001b[32m2023-07-26 11:49:23.848\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m34\u001b[0m - \u001b[1mInstalling latest transformers@main\u001b[0m\n",
            "\u001b[32m2023-07-26 11:49:52.936\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m36\u001b[0m - \u001b[1mSuccessfully installed latest transformers\u001b[0m\n",
            "\u001b[32m2023-07-26 11:49:52.937\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m40\u001b[0m - \u001b[1mInstalling latest peft@main\u001b[0m\n",
            "\u001b[32m2023-07-26 11:50:06.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m42\u001b[0m - \u001b[1mSuccessfully installed latest peft\u001b[0m\n",
            "\u001b[32m2023-07-26 11:50:06.325\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[1mInstalling latest diffusers@main\u001b[0m\n",
            "\u001b[32m2023-07-26 11:50:23.825\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m48\u001b[0m - \u001b[1mSuccessfully installed latest diffusers\u001b[0m\n",
            "\u001b[32m2023-07-26 11:50:23.826\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m52\u001b[0m - \u001b[1mInstalling latest trl@main\u001b[0m\n",
            "\u001b[32m2023-07-26 11:50:32.187\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_setup\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m54\u001b[0m - \u001b[1mSuccessfully installed latest trl\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm -help"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYIUGocWckqL",
        "outputId": "4f7248fc-35da-43a2-c3ac-460afa2a9cb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-26 11:50:39.489189: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "usage: autotrain <command> [<args>] llm\n",
            "       [-h]\n",
            "       [--train]\n",
            "       [--deploy]\n",
            "       [--inference]\n",
            "       [--data_path DATA_PATH]\n",
            "       [--train_split TRAIN_SPLIT]\n",
            "       [--valid_split VALID_SPLIT]\n",
            "       [--text_column TEXT_COLUMN]\n",
            "       [--model MODEL]\n",
            "       [--learning_rate LEARNING_RATE]\n",
            "       [--num_train_epochs NUM_TRAIN_EPOCHS]\n",
            "       [--train_batch_size TRAIN_BATCH_SIZE]\n",
            "       [--eval_batch_size EVAL_BATCH_SIZE]\n",
            "       [--warmup_ratio WARMUP_RATIO]\n",
            "       [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
            "       [--optimizer OPTIMIZER]\n",
            "       [--scheduler SCHEDULER]\n",
            "       [--weight_decay WEIGHT_DECAY]\n",
            "       [--max_grad_norm MAX_GRAD_NORM]\n",
            "       [--seed SEED]\n",
            "       [--add_eos_token]\n",
            "       [--block_size BLOCK_SIZE]\n",
            "       [--use_peft]\n",
            "       [--lora_r LORA_R]\n",
            "       [--lora_alpha LORA_ALPHA]\n",
            "       [--lora_dropout LORA_DROPOUT]\n",
            "       [--training_type TRAINING_TYPE]\n",
            "       [--train_on_inputs]\n",
            "       [--logging_steps LOGGING_STEPS]\n",
            "       [--project_name PROJECT_NAME]\n",
            "       [--evaluation_strategy EVALUATION_STRATEGY]\n",
            "       [--save_total_limit SAVE_TOTAL_LIMIT]\n",
            "       [--save_strategy SAVE_STRATEGY]\n",
            "       [--auto_find_batch_size]\n",
            "       [--fp16]\n",
            "       [--push_to_hub]\n",
            "       [--use_int8]\n",
            "       [--model_max_length MODEL_MAX_LENGTH]\n",
            "       [--repo_id REPO_ID]\n",
            "       [--use_int4]\n",
            "       [--trainer TRAINER]\n",
            "       [--target_modules TARGET_MODULES]\n",
            "autotrain <command> [<args>] llm: error: argument -h/--help: ignored explicit argument 'elp'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Training using AutoTrain**"
      ],
      "metadata": {
        "id": "eMJ8czbmCz-Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Command for training"
      ],
      "metadata": {
        "id": "C346Ly-C5uUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm --train --deploy --project_name Llama2-CodeGen-PEFT-QLora --model meta-llama/Llama-2-7b --data_path . --text_column text --use_peft --use_int4 --lora_r 32 --lora_alpha 64 --lora_dropout 0.1 --learning_rate 2e-4 --fp16 --train_batch_size 4 --num_train_epochs 5 --trainer sft --push_to_hub --repo_id AhmedSSoliman/Llama2-CodeGen-PEFT-QLora"
      ],
      "metadata": {
        "id": "SMJMjTyiLl4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training 5 epochs"
      ],
      "metadata": {
        "id": "FOvP9JRT5oCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm --train --deploy --project_name Llama2-CodeGen-PEFT-QLora --model TinyPixel/Llama-2-7B-bf16-sharded --data_path . --text_column text --use_peft --use_int4 --lora_r 32 --lora_alpha 64 --lora_dropout 0.1 --learning_rate 2e-4 --fp16 --train_batch_size 4 --num_train_epochs 5 --trainer sft --push_to_hub --repo_id AhmedSSoliman/Llama2-CodeGen-PEFT-QLora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjmvgc9YBc6o",
        "outputId": "ee690f8b-b637-4fe6-ddb4-c7cf2c87396b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:16:52] Energy consumed for RAM : 0.003854 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:16:52] Energy consumed for all GPUs : 0.012621 kWh. Total GPU Power : 31.543000000000003 W\n",
            "[codecarbon INFO @ 13:16:52] Energy consumed for all CPUs : 0.017175 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:16:52] 0.033651 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-26 13:16:57.000042: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/usr/local/lib/python3.10/dist-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda20CUDACachingAllocator9allocatorE'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
            "  warn(\n",
            "> \u001b[1mINFO    Running LLM\u001b[0m\n",
            "> \u001b[1mINFO    Train: True\u001b[0m\n",
            "> \u001b[1mINFO    loading dataset from csv\u001b[0m\n",
            "Downloading (…)okenizer_config.json: 100% 676/676 [00:00<00:00, 4.16MB/s]\n",
            "Downloading tokenizer.model: 100% 500k/500k [00:00<00:00, 32.0MB/s]\n",
            "Downloading (…)/main/tokenizer.json: 100% 1.84M/1.84M [00:00<00:00, 4.50MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 411/411 [00:00<00:00, 2.42MB/s]\n",
            "Using pad_token, but it is not set yet.\n",
            "Downloading (…)lve/main/config.json: 100% 626/626 [00:00<00:00, 3.17MB/s]\n",
            "Downloading (…)model.bin.index.json: 100% 26.8k/26.8k [00:00<00:00, 95.2MB/s]\n",
            "Downloading shards:   0% 0/14 [00:00<?, ?it/s]\n",
            "Downloading (…)l-00001-of-00014.bin:   0% 0.00/981M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:   4% 41.9M/981M [00:00<00:02, 416MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  10% 94.4M/981M [00:00<00:01, 452MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  15% 147M/981M [00:00<00:01, 465MB/s] \u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  20% 199M/981M [00:00<00:01, 462MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  26% 252M/981M [00:00<00:01, 449MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  31% 304M/981M [00:00<00:01, 421MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  36% 357M/981M [00:00<00:01, 398MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  41% 398M/981M [00:00<00:01, 396MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  46% 451M/981M [00:01<00:01, 405MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  50% 493M/981M [00:01<00:01, 407MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  54% 535M/981M [00:02<00:04, 109MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  59% 577M/981M [00:02<00:02, 135MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  62% 608M/981M [00:02<00:02, 148MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  65% 640M/981M [00:02<00:02, 159MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  68% 671M/981M [00:02<00:01, 164MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  72% 703M/981M [00:03<00:01, 165MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  75% 734M/981M [00:03<00:01, 167MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  77% 755M/981M [00:03<00:01, 162MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  79% 776M/981M [00:03<00:01, 156MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  81% 797M/981M [00:03<00:01, 138MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  83% 818M/981M [00:03<00:01, 124MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  85% 839M/981M [00:04<00:01, 126MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  90% 881M/981M [00:04<00:00, 176MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin:  94% 923M/981M [00:04<00:00, 222MB/s]\u001b[A\n",
            "Downloading (…)l-00001-of-00014.bin: 100% 981M/981M [00:04<00:00, 218MB/s]\n",
            "Downloading shards:   7% 1/14 [00:04<01:00,  4.63s/it]\n",
            "Downloading (…)l-00002-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:   5% 52.4M/967M [00:00<00:02, 443MB/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:17:07] Energy consumed for RAM : 0.003894 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:17:07] Energy consumed for all GPUs : 0.012752 kWh. Total GPU Power : 31.543000000000003 W\n",
            "[codecarbon INFO @ 13:17:07] Energy consumed for all CPUs : 0.017352 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:17:07] 0.033999 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\rDownloading (…)l-00002-of-00014.bin:  11% 105M/967M [00:00<00:02, 417MB/s] \u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  15% 147M/967M [00:00<00:01, 412MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  20% 189M/967M [00:00<00:01, 408MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  24% 231M/967M [00:00<00:01, 391MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  29% 283M/967M [00:00<00:01, 403MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  34% 325M/967M [00:00<00:01, 393MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  38% 367M/967M [00:00<00:01, 391MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  42% 409M/967M [00:01<00:01, 388MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  47% 451M/967M [00:01<00:01, 315MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  51% 493M/967M [00:01<00:01, 293MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  54% 524M/967M [00:01<00:01, 278MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  57% 556M/967M [00:01<00:01, 271MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  61% 587M/967M [00:01<00:01, 264MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  64% 619M/967M [00:01<00:01, 264MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  67% 650M/967M [00:02<00:01, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  70% 682M/967M [00:02<00:01, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  74% 713M/967M [00:02<00:01, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  77% 744M/967M [00:02<00:00, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  80% 776M/967M [00:02<00:00, 247MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  84% 807M/967M [00:02<00:00, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  87% 839M/967M [00:02<00:00, 231MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  90% 870M/967M [00:03<00:00, 203MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  93% 902M/967M [00:03<00:00, 195MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  95% 923M/967M [00:03<00:00, 191MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin:  98% 944M/967M [00:03<00:00, 185MB/s]\u001b[A\n",
            "Downloading (…)l-00002-of-00014.bin: 100% 967M/967M [00:03<00:00, 267MB/s]\n",
            "Downloading shards:  14% 2/14 [00:08<00:49,  4.11s/it]\n",
            "Downloading (…)l-00003-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:   5% 52.4M/967M [00:00<00:02, 388MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  10% 94.4M/967M [00:00<00:03, 226MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  13% 126M/967M [00:00<00:03, 211MB/s] \u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  16% 157M/967M [00:00<00:03, 203MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  20% 189M/967M [00:00<00:03, 199MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  25% 241M/967M [00:01<00:02, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  29% 283M/967M [00:02<00:10, 68.3MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  31% 304M/967M [00:03<00:16, 40.3MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  35% 336M/967M [00:04<00:11, 52.8MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  37% 357M/967M [00:04<00:09, 62.1MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  39% 377M/967M [00:04<00:08, 72.5MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  41% 398M/967M [00:04<00:06, 82.8MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  43% 419M/967M [00:04<00:05, 92.2MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  46% 440M/967M [00:04<00:05, 101MB/s] \u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  48% 461M/967M [00:04<00:04, 109MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  50% 482M/967M [00:05<00:04, 119MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  52% 503M/967M [00:05<00:03, 133MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  54% 524M/967M [00:05<00:03, 146MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  57% 556M/967M [00:05<00:02, 167MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  61% 587M/967M [00:05<00:01, 190MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  63% 608M/967M [00:05<00:01, 194MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  66% 640M/967M [00:05<00:01, 210MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  70% 682M/967M [00:05<00:01, 252MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  75% 724M/967M [00:06<00:00, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  79% 765M/967M [00:06<00:00, 314MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  84% 807M/967M [00:06<00:00, 337MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  88% 849M/967M [00:06<00:00, 353MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin:  92% 891M/967M [00:06<00:00, 363MB/s]\u001b[A\n",
            "Downloading (…)l-00003-of-00014.bin: 100% 967M/967M [00:06<00:00, 145MB/s]\n",
            "Downloading shards:  21% 3/14 [00:15<00:58,  5.34s/it]\n",
            "Downloading (…)l-00004-of-00014.bin:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:   2% 21.0M/990M [00:00<00:06, 153MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:   4% 41.9M/990M [00:00<00:05, 181MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:   8% 83.9M/990M [00:00<00:03, 264MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  13% 126M/990M [00:00<00:02, 311MB/s] \u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  17% 168M/990M [00:00<00:02, 338MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  22% 220M/990M [00:00<00:02, 369MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  26% 262M/990M [00:00<00:02, 350MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  31% 304M/990M [00:01<00:02, 302MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  35% 346M/990M [00:01<00:02, 301MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  38% 377M/990M [00:01<00:02, 283MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  41% 409M/990M [00:01<00:02, 263MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  44% 440M/990M [00:01<00:02, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  48% 472M/990M [00:01<00:01, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  51% 503M/990M [00:01<00:01, 257MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  54% 535M/990M [00:01<00:01, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  57% 566M/990M [00:02<00:01, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  60% 598M/990M [00:02<00:01, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  64% 629M/990M [00:02<00:01, 229MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  67% 661M/990M [00:02<00:01, 209MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  70% 692M/990M [00:02<00:01, 182MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  72% 713M/990M [00:02<00:01, 165MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  74% 734M/990M [00:03<00:01, 157MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  76% 755M/990M [00:03<00:01, 155MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  78% 776M/990M [00:03<00:01, 161MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  82% 807M/990M [00:03<00:01, 176MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  85% 839M/990M [00:03<00:00, 192MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  88% 870M/990M [00:03<00:00, 200MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  91% 902M/990M [00:03<00:00, 208MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin:  94% 933M/990M [00:04<00:00, 207MB/s]\u001b[A\n",
            "Downloading (…)l-00004-of-00014.bin: 100% 990M/990M [00:04<00:00, 234MB/s]\n",
            "Downloading shards:  29% 4/14 [00:19<00:49,  4.95s/it]\n",
            "Downloading (…)l-00005-of-00014.bin:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:17:22] Energy consumed for RAM : 0.003934 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:17:22] Energy consumed for all GPUs : 0.012884 kWh. Total GPU Power : 31.641000000000002 W\n",
            "[codecarbon INFO @ 13:17:22] Energy consumed for all CPUs : 0.017529 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:17:22] 0.034347 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\rDownloading (…)l-00005-of-00014.bin:   4% 41.9M/944M [00:02<00:58, 15.4MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:   9% 83.9M/944M [00:02<00:24, 34.6MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  11% 105M/944M [00:02<00:18, 45.5MB/s] \u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  13% 126M/944M [00:03<00:14, 58.0MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  16% 147M/944M [00:03<00:11, 72.3MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  18% 168M/944M [00:03<00:08, 87.2MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  20% 189M/944M [00:03<00:07, 102MB/s] \u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  22% 210M/944M [00:03<00:06, 114MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  24% 231M/944M [00:03<00:05, 123MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  27% 252M/944M [00:03<00:05, 131MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  29% 273M/944M [00:04<00:04, 139MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  31% 294M/944M [00:04<00:04, 150MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  33% 315M/944M [00:04<00:03, 162MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  37% 346M/944M [00:04<00:03, 189MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  40% 377M/944M [00:04<00:02, 198MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  44% 419M/944M [00:04<00:02, 234MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  48% 451M/944M [00:04<00:02, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  51% 482M/944M [00:04<00:01, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  54% 514M/944M [00:05<00:01, 231MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  58% 545M/944M [00:05<00:01, 224MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  61% 577M/944M [00:05<00:01, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  64% 608M/944M [00:05<00:01, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  69% 650M/944M [00:05<00:01, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  73% 692M/944M [00:05<00:00, 307MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  78% 734M/944M [00:07<00:04, 52.3MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  81% 765M/944M [00:07<00:02, 66.6MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  84% 797M/944M [00:08<00:01, 78.7MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  88% 828M/944M [00:08<00:01, 86.6MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  90% 849M/944M [00:08<00:01, 90.0MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  92% 870M/944M [00:08<00:00, 97.8MB/s]\u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin:  94% 891M/944M [00:08<00:00, 110MB/s] \u001b[A\n",
            "Downloading (…)l-00005-of-00014.bin: 100% 944M/944M [00:09<00:00, 103MB/s]\n",
            "Downloading shards:  36% 5/14 [00:28<00:58,  6.50s/it]\n",
            "Downloading (…)l-00006-of-00014.bin:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:   5% 52.4M/990M [00:00<00:01, 484MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  11% 105M/990M [00:00<00:02, 412MB/s] \u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  15% 147M/990M [00:00<00:02, 398MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  19% 189M/990M [00:00<00:02, 376MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  23% 231M/990M [00:00<00:02, 280MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  26% 262M/990M [00:00<00:02, 284MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  31% 304M/990M [00:00<00:02, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  35% 346M/990M [00:01<00:01, 326MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  39% 388M/990M [00:01<00:01, 344MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  43% 430M/990M [00:01<00:01, 352MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  48% 472M/990M [00:01<00:01, 362MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  52% 514M/990M [00:01<00:01, 366MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  56% 556M/990M [00:01<00:01, 372MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  60% 598M/990M [00:01<00:01, 267MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  65% 640M/990M [00:01<00:01, 292MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  69% 682M/990M [00:02<00:00, 314MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  73% 724M/990M [00:02<00:01, 257MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  76% 755M/990M [00:02<00:01, 166MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  79% 786M/990M [00:02<00:01, 184MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  83% 818M/990M [00:02<00:00, 203MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  86% 849M/990M [00:03<00:00, 220MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  89% 881M/990M [00:03<00:00, 237MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin:  93% 923M/990M [00:03<00:00, 264MB/s]\u001b[A\n",
            "Downloading (…)l-00006-of-00014.bin: 100% 990M/990M [00:03<00:00, 287MB/s]\n",
            "Downloading shards:  43% 6/14 [00:32<00:44,  5.55s/it]\n",
            "Downloading (…)l-00007-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:   5% 52.4M/967M [00:00<00:01, 474MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  11% 105M/967M [00:00<00:03, 233MB/s] \u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  14% 136M/967M [00:00<00:03, 216MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  17% 168M/967M [00:00<00:03, 222MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  21% 199M/967M [00:00<00:03, 230MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  24% 231M/967M [00:00<00:03, 236MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  27% 262M/967M [00:01<00:03, 231MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  30% 294M/967M [00:01<00:02, 225MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  35% 336M/967M [00:01<00:02, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  39% 377M/967M [00:01<00:04, 144MB/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:17:37] Energy consumed for RAM : 0.003973 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:17:37] Energy consumed for all GPUs : 0.013016 kWh. Total GPU Power : 31.641000000000002 W\n",
            "[codecarbon INFO @ 13:17:37] Energy consumed for all CPUs : 0.017706 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:17:37] 0.034696 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading (…)l-00007-of-00014.bin:  41% 398M/967M [00:04<00:18, 31.0MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  44% 430M/967M [00:04<00:12, 42.4MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  48% 461M/967M [00:04<00:08, 56.3MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  51% 493M/967M [00:05<00:06, 71.9MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  54% 524M/967M [00:05<00:05, 85.9MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  56% 545M/967M [00:05<00:04, 91.0MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  59% 566M/967M [00:05<00:04, 94.4MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  61% 587M/967M [00:05<00:03, 104MB/s] \u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  63% 608M/967M [00:05<00:03, 118MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  66% 640M/967M [00:06<00:02, 145MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  69% 671M/967M [00:06<00:01, 169MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  73% 703M/967M [00:06<00:01, 185MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  76% 734M/967M [00:06<00:01, 198MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  79% 765M/967M [00:06<00:00, 219MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  82% 797M/967M [00:06<00:00, 238MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  87% 839M/967M [00:06<00:00, 275MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  91% 881M/967M [00:06<00:00, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin:  95% 923M/967M [00:07<00:00, 327MB/s]\u001b[A\n",
            "Downloading (…)l-00007-of-00014.bin: 100% 967M/967M [00:07<00:00, 135MB/s]\n",
            "Downloading shards:  50% 7/14 [00:39<00:43,  6.14s/it]\n",
            "Downloading (…)l-00008-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:   2% 21.0M/967M [00:00<00:07, 126MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:   4% 41.9M/967M [00:01<00:31, 29.8MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:   8% 73.4M/967M [00:01<00:15, 59.0MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  12% 115M/967M [00:01<00:08, 103MB/s]  \u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  17% 168M/967M [00:01<00:04, 163MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  23% 220M/967M [00:01<00:03, 218MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  27% 262M/967M [00:01<00:02, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  31% 304M/967M [00:01<00:02, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  36% 346M/967M [00:02<00:01, 315MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  40% 388M/967M [00:02<00:02, 196MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  43% 419M/967M [00:02<00:02, 196MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  47% 451M/967M [00:02<00:02, 188MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  50% 482M/967M [00:03<00:02, 169MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  52% 503M/967M [00:03<00:03, 153MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  54% 524M/967M [00:03<00:02, 151MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  56% 545M/967M [00:03<00:02, 156MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  60% 577M/967M [00:03<00:02, 185MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  63% 608M/967M [00:03<00:01, 203MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  66% 640M/967M [00:03<00:01, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  69% 671M/967M [00:03<00:01, 223MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  73% 703M/967M [00:04<00:01, 235MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  76% 734M/967M [00:04<00:01, 223MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  81% 786M/967M [00:04<00:00, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  85% 818M/967M [00:07<00:04, 35.0MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  89% 860M/967M [00:07<00:02, 50.5MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  92% 891M/967M [00:07<00:01, 61.5MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin:  95% 923M/967M [00:07<00:00, 74.2MB/s]\u001b[A\n",
            "Downloading (…)l-00008-of-00014.bin: 100% 967M/967M [00:08<00:00, 116MB/s] \n",
            "Downloading shards:  57% 8/14 [00:48<00:41,  6.88s/it]\n",
            "Downloading (…)l-00009-of-00014.bin:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:   4% 41.9M/990M [00:00<00:02, 366MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:   8% 83.9M/990M [00:00<00:02, 305MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  12% 115M/990M [00:00<00:03, 275MB/s] \u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  15% 147M/990M [00:00<00:03, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  18% 178M/990M [00:00<00:03, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  21% 210M/990M [00:00<00:02, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  24% 241M/990M [00:00<00:02, 269MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  29% 283M/990M [00:01<00:02, 300MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  33% 325M/990M [00:01<00:02, 325MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  37% 367M/990M [00:01<00:01, 346MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  41% 409M/990M [00:01<00:01, 355MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  46% 451M/990M [00:01<00:01, 365MB/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:17:52] Energy consumed for RAM : 0.004013 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:17:52] Energy consumed for all GPUs : 0.013148 kWh. Total GPU Power : 31.641000000000002 W\n",
            "[codecarbon INFO @ 13:17:52] Energy consumed for all CPUs : 0.017883 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:17:52] 0.035044 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading (…)l-00009-of-00014.bin:  50% 493M/990M [00:01<00:01, 368MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  54% 535M/990M [00:01<00:01, 378MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  58% 577M/990M [00:01<00:01, 325MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  62% 619M/990M [00:01<00:01, 298MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  66% 650M/990M [00:02<00:01, 286MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  69% 682M/990M [00:02<00:01, 273MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  72% 713M/990M [00:02<00:01, 271MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  75% 744M/990M [00:02<00:00, 264MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  78% 776M/990M [00:02<00:00, 262MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  82% 807M/990M [00:02<00:00, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  85% 839M/990M [00:02<00:00, 254MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  88% 870M/990M [00:02<00:00, 256MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  91% 902M/990M [00:03<00:00, 178MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin:  95% 944M/990M [00:03<00:00, 218MB/s]\u001b[A\n",
            "Downloading (…)l-00009-of-00014.bin: 100% 990M/990M [00:03<00:00, 279MB/s]\n",
            "Downloading shards:  64% 9/14 [00:51<00:29,  5.87s/it]\n",
            "Downloading (…)l-00010-of-00014.bin:   0% 0.00/944M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:   4% 41.9M/944M [00:00<00:02, 357MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:   9% 83.9M/944M [00:00<00:02, 361MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  13% 126M/944M [00:00<00:02, 380MB/s] \u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  18% 168M/944M [00:00<00:02, 288MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  21% 199M/944M [00:00<00:03, 229MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  24% 231M/944M [00:00<00:03, 188MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  28% 262M/944M [00:01<00:04, 170MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  31% 294M/944M [00:01<00:03, 178MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  34% 325M/944M [00:01<00:03, 197MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  38% 357M/944M [00:01<00:02, 208MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  41% 388M/944M [00:01<00:02, 219MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  44% 419M/944M [00:01<00:02, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  48% 451M/944M [00:03<00:08, 61.1MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  51% 482M/944M [00:03<00:05, 79.9MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  54% 514M/944M [00:03<00:04, 103MB/s] \u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  59% 556M/944M [00:03<00:02, 136MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  63% 598M/944M [00:03<00:02, 170MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  68% 640M/944M [00:03<00:01, 208MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  72% 682M/944M [00:03<00:01, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  77% 724M/944M [00:04<00:00, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  82% 776M/944M [00:04<00:00, 313MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  87% 818M/944M [00:05<00:01, 98.3MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  91% 860M/944M [00:05<00:00, 122MB/s] \u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin:  94% 891M/944M [00:05<00:00, 134MB/s]\u001b[A\n",
            "Downloading (…)l-00010-of-00014.bin: 100% 944M/944M [00:06<00:00, 157MB/s]\n",
            "Downloading shards:  71% 10/14 [00:58<00:23,  5.95s/it]\n",
            "Downloading (…)l-00011-of-00014.bin:   0% 0.00/990M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:   5% 52.4M/990M [00:00<00:02, 398MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  10% 94.4M/990M [00:00<00:03, 233MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  13% 126M/990M [00:00<00:03, 225MB/s] \u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  16% 157M/990M [00:00<00:03, 221MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  19% 189M/990M [00:00<00:03, 222MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  22% 220M/990M [00:00<00:03, 212MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  26% 262M/990M [00:01<00:02, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  30% 294M/990M [00:04<00:23, 30.1MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  35% 346M/990M [00:04<00:13, 48.6MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  39% 388M/990M [00:04<00:09, 64.2MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  42% 419M/990M [00:05<00:08, 70.5MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  44% 440M/990M [00:05<00:06, 80.9MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  47% 461M/990M [00:05<00:05, 91.0MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  50% 493M/990M [00:05<00:04, 115MB/s] \u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  53% 524M/990M [00:05<00:03, 132MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  56% 556M/990M [00:05<00:02, 146MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  59% 587M/990M [00:05<00:02, 169MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  62% 619M/990M [00:05<00:02, 185MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  66% 650M/990M [00:06<00:01, 207MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  70% 692M/990M [00:06<00:01, 245MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  74% 734M/990M [00:06<00:00, 272MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  78% 776M/990M [00:06<00:00, 298MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  83% 818M/990M [00:06<00:00, 318MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  87% 860M/990M [00:06<00:00, 331MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin:  91% 902M/990M [00:06<00:00, 345MB/s]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:18:07] Energy consumed for RAM : 0.004053 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:18:07] Energy consumed for all GPUs : 0.013279 kWh. Total GPU Power : 31.543000000000003 W\n",
            "[codecarbon INFO @ 13:18:07] Energy consumed for all CPUs : 0.018060 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:07] 0.035392 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading (…)l-00011-of-00014.bin:  95% 944M/990M [00:06<00:00, 362MB/s]\u001b[A\n",
            "Downloading (…)l-00011-of-00014.bin: 100% 990M/990M [00:07<00:00, 141MB/s]\n",
            "Downloading shards:  79% 11/14 [01:05<00:18,  6.31s/it]\n",
            "Downloading (…)l-00012-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:   4% 41.9M/967M [00:00<00:02, 396MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:   9% 83.9M/967M [00:00<00:02, 404MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  13% 126M/967M [00:00<00:02, 383MB/s] \u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  17% 168M/967M [00:00<00:02, 303MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  22% 210M/967M [00:00<00:02, 282MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  25% 241M/967M [00:00<00:02, 277MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  28% 273M/967M [00:00<00:02, 266MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  31% 304M/967M [00:01<00:02, 268MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  35% 336M/967M [00:01<00:02, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  38% 367M/967M [00:01<00:02, 254MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  41% 398M/967M [00:01<00:02, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  44% 430M/967M [00:01<00:02, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  48% 461M/967M [00:01<00:02, 243MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  52% 503M/967M [00:01<00:01, 248MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  55% 535M/967M [00:01<00:01, 246MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  59% 566M/967M [00:02<00:01, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  62% 598M/967M [00:02<00:01, 255MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  65% 629M/967M [00:02<00:01, 250MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  68% 661M/967M [00:02<00:01, 211MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  72% 692M/967M [00:02<00:01, 165MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  74% 713M/967M [00:03<00:01, 152MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  76% 734M/967M [00:03<00:01, 157MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  79% 765M/967M [00:03<00:01, 183MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  82% 797M/967M [00:03<00:00, 206MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  86% 828M/967M [00:03<00:00, 212MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  89% 860M/967M [00:03<00:00, 227MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  92% 891M/967M [00:03<00:00, 225MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin:  95% 923M/967M [00:03<00:00, 232MB/s]\u001b[A\n",
            "Downloading (…)l-00012-of-00014.bin: 100% 967M/967M [00:04<00:00, 236MB/s]\n",
            "Downloading shards:  86% 12/14 [01:09<00:11,  5.67s/it]\n",
            "Downloading (…)l-00013-of-00014.bin:   0% 0.00/967M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:   4% 41.9M/967M [00:00<00:02, 339MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:   9% 83.9M/967M [00:00<00:02, 350MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  13% 126M/967M [00:00<00:02, 335MB/s] \u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  17% 168M/967M [00:00<00:02, 348MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  22% 210M/967M [00:00<00:02, 362MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  26% 252M/967M [00:00<00:01, 372MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  30% 294M/967M [00:00<00:01, 378MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  35% 336M/967M [00:00<00:01, 377MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  39% 377M/967M [00:01<00:01, 386MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  43% 419M/967M [00:01<00:01, 385MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  48% 461M/967M [00:01<00:01, 335MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  52% 503M/967M [00:01<00:01, 288MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  55% 535M/967M [00:01<00:01, 294MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  59% 566M/967M [00:01<00:01, 288MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  62% 598M/967M [00:01<00:01, 279MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  65% 629M/967M [00:01<00:01, 273MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  68% 661M/967M [00:02<00:01, 258MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  72% 692M/967M [00:02<00:01, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  75% 724M/967M [00:02<00:00, 249MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  78% 755M/967M [00:02<00:00, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  81% 786M/967M [00:02<00:00, 259MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  85% 818M/967M [00:02<00:00, 251MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  88% 849M/967M [00:02<00:00, 257MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  91% 881M/967M [00:02<00:00, 241MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  94% 912M/967M [00:03<00:00, 218MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin:  98% 944M/967M [00:03<00:00, 206MB/s]\u001b[A\n",
            "Downloading (…)l-00013-of-00014.bin: 100% 967M/967M [00:03<00:00, 274MB/s]\n",
            "Downloading shards:  93% 13/14 [01:13<00:05,  5.06s/it]\n",
            "Downloading (…)l-00014-of-00014.bin:   0% 0.00/847M [00:00<?, ?B/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:   6% 52.4M/847M [00:00<00:01, 447MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  12% 105M/847M [00:00<00:02, 263MB/s] \u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  16% 136M/847M [00:00<00:02, 240MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  20% 168M/847M [00:00<00:02, 239MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  24% 199M/847M [00:00<00:02, 236MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  27% 231M/847M [00:00<00:02, 240MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  32% 273M/847M [00:01<00:02, 271MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  37% 315M/847M [00:01<00:01, 304MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  42% 357M/847M [00:01<00:01, 334MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  47% 398M/847M [00:01<00:01, 352MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  52% 440M/847M [00:01<00:01, 365MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  57% 482M/847M [00:01<00:00, 371MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  62% 524M/847M [00:01<00:00, 329MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  67% 566M/847M [00:01<00:00, 312MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  72% 608M/847M [00:02<00:00, 285MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  75% 640M/847M [00:02<00:00, 270MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  79% 671M/847M [00:02<00:00, 270MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  83% 703M/847M [00:02<00:00, 273MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  87% 734M/847M [00:02<00:00, 267MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  90% 765M/847M [00:02<00:00, 260MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin:  94% 797M/847M [00:02<00:00, 261MB/s]\u001b[A\n",
            "Downloading (…)l-00014-of-00014.bin: 100% 847M/847M [00:03<00:00, 280MB/s]\n",
            "Downloading shards: 100% 14/14 [01:16<00:00,  5.45s/it]\n",
            "Loading checkpoint shards:   0% 0/14 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:18:22] Energy consumed for RAM : 0.004093 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:18:22] Energy consumed for all GPUs : 0.013411 kWh. Total GPU Power : 31.641000000000002 W\n",
            "[codecarbon INFO @ 13:18:22] Energy consumed for all CPUs : 0.018237 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:22] 0.035741 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  14% 2/14 [00:12<01:17,  6.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:18:37] Energy consumed for RAM : 0.004132 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:18:37] Energy consumed for all GPUs : 0.013542 kWh. Total GPU Power : 31.543000000000003 W\n",
            "[codecarbon INFO @ 13:18:37] Energy consumed for all CPUs : 0.018414 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:37] 0.036089 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  29% 4/14 [00:26<01:06,  6.64s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:18:52] Energy consumed for RAM : 0.004172 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:18:52] Energy consumed for all GPUs : 0.013677 kWh. Total GPU Power : 32.428 W\n",
            "[codecarbon INFO @ 13:18:52] Energy consumed for all CPUs : 0.018591 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:18:52] 0.036441 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  50% 7/14 [00:46<00:47,  6.73s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:19:07] Energy consumed for RAM : 0.004212 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:19:07] Energy consumed for all GPUs : 0.013808 kWh. Total GPU Power : 31.543000000000003 W\n",
            "[codecarbon INFO @ 13:19:07] Energy consumed for all CPUs : 0.018769 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:07] 0.036789 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  64% 9/14 [01:00<00:34,  6.84s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:19:22] Energy consumed for RAM : 0.004252 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:19:22] Energy consumed for all GPUs : 0.013940 kWh. Total GPU Power : 31.641000000000002 W\n",
            "[codecarbon INFO @ 13:19:22] Energy consumed for all CPUs : 0.018946 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:22] 0.037137 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  79% 11/14 [01:14<00:20,  6.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:19:37] Energy consumed for RAM : 0.004291 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:19:37] Energy consumed for all GPUs : 0.014072 kWh. Total GPU Power : 31.641000000000002 W\n",
            "[codecarbon INFO @ 13:19:37] Energy consumed for all CPUs : 0.019123 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:37] 0.037486 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  93% 13/14 [01:27<00:06,  6.91s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:19:52] Energy consumed for RAM : 0.004331 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:19:52] Energy consumed for all GPUs : 0.014204 kWh. Total GPU Power : 31.641000000000002 W\n",
            "[codecarbon INFO @ 13:19:52] Energy consumed for all CPUs : 0.019300 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:19:52] 0.037834 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rLoading checkpoint shards: 100% 14/14 [01:33<00:00,  6.40s/it]\rLoading checkpoint shards: 100% 14/14 [01:33<00:00,  6.66s/it]\n",
            "\rDownloading (…)neration_config.json:   0% 0.00/132 [00:00<?, ?B/s]\rDownloading (…)neration_config.json: 100% 132/132 [00:00<00:00, 734kB/s]\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "Running tokenizer on train dataset:   0% 0/2000 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1183 > 1024). Running this sequence through the model will result in indexing errors\n",
            "> \u001b[1mINFO    creating trainer\u001b[0m\n",
            "  0% 0/685 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:20:07] Energy consumed for RAM : 0.004371 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:20:07] Energy consumed for all GPUs : 0.014472 kWh. Total GPU Power : 64.47200000000001 W\n",
            "[codecarbon INFO @ 13:20:07] Energy consumed for all CPUs : 0.019477 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:07] 0.038320 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 1/685 [00:14<2:45:06, 14.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:20:22] Energy consumed for RAM : 0.004410 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:20:22] Energy consumed for all GPUs : 0.014744 kWh. Total GPU Power : 65.253 W\n",
            "[codecarbon INFO @ 13:20:22] Energy consumed for all CPUs : 0.019654 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:22] 0.038808 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 2/685 [00:28<2:40:38, 14.11s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:20:37] Energy consumed for RAM : 0.004450 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:20:37] Energy consumed for all GPUs : 0.015033 kWh. Total GPU Power : 69.599 W\n",
            "[codecarbon INFO @ 13:20:37] Energy consumed for all CPUs : 0.019831 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:37] 0.039314 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  0% 3/685 [00:41<2:37:51, 13.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:20:52] Energy consumed for RAM : 0.004490 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:20:52] Energy consumed for all GPUs : 0.015362 kWh. Total GPU Power : 78.95400000000001 W\n",
            "[codecarbon INFO @ 13:20:52] Energy consumed for all CPUs : 0.020008 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:20:52] 0.039860 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1% 4/685 [00:55<2:35:42, 13.72s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:21:07] Energy consumed for RAM : 0.004530 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:21:07] Energy consumed for all GPUs : 0.015665 kWh. Total GPU Power : 72.92 W\n",
            "[codecarbon INFO @ 13:21:07] Energy consumed for all CPUs : 0.020185 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:07] 0.040380 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1% 5/685 [01:08<2:34:13, 13.61s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:21:22] Energy consumed for RAM : 0.004569 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:21:22] Energy consumed for all GPUs : 0.015974 kWh. Total GPU Power : 74.036 W\n",
            "[codecarbon INFO @ 13:21:22] Energy consumed for all CPUs : 0.020362 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:22] 0.040905 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1% 6/685 [01:22<2:33:14, 13.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:21:37] Energy consumed for RAM : 0.004609 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:21:37] Energy consumed for all GPUs : 0.016276 kWh. Total GPU Power : 72.718 W\n",
            "[codecarbon INFO @ 13:21:37] Energy consumed for all CPUs : 0.020539 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:37] 0.041424 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1% 7/685 [01:35<2:32:42, 13.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:21:52] Energy consumed for RAM : 0.004649 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:21:52] Energy consumed for all GPUs : 0.016564 kWh. Total GPU Power : 69.057 W\n",
            "[codecarbon INFO @ 13:21:52] Energy consumed for all CPUs : 0.020716 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:21:52] 0.041929 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  1% 8/685 [01:49<2:32:24, 13.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:22:07] Energy consumed for RAM : 0.004688 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:22:07] Energy consumed for all GPUs : 0.016816 kWh. Total GPU Power : 60.585 W\n",
            "[codecarbon INFO @ 13:22:07] Energy consumed for all CPUs : 0.020893 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:07] 0.042398 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  1% 10/685 [02:16<2:31:52, 13.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:22:22] Energy consumed for RAM : 0.004728 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:22:22] Energy consumed for all GPUs : 0.017101 kWh. Total GPU Power : 68.514 W\n",
            "[codecarbon INFO @ 13:22:22] Energy consumed for all CPUs : 0.021070 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:22] 0.042900 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  2% 11/685 [02:29<2:31:26, 13.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:22:37] Energy consumed for RAM : 0.004768 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:22:37] Energy consumed for all GPUs : 0.017379 kWh. Total GPU Power : 66.7 W\n",
            "[codecarbon INFO @ 13:22:37] Energy consumed for all CPUs : 0.021247 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:37] 0.043394 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  2% 12/685 [02:43<2:31:08, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:22:52] Energy consumed for RAM : 0.004808 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:22:52] Energy consumed for all GPUs : 0.017658 kWh. Total GPU Power : 67.09100000000001 W\n",
            "[codecarbon INFO @ 13:22:52] Energy consumed for all CPUs : 0.021424 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:22:52] 0.043890 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  2% 13/685 [02:56<2:30:52, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:23:07] Energy consumed for RAM : 0.004847 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:23:07] Energy consumed for all GPUs : 0.017928 kWh. Total GPU Power : 64.787 W\n",
            "[codecarbon INFO @ 13:23:07] Energy consumed for all CPUs : 0.021601 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:07] 0.044376 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  2% 14/685 [03:10<2:30:36, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:23:22] Energy consumed for RAM : 0.004887 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:23:22] Energy consumed for all GPUs : 0.018201 kWh. Total GPU Power : 65.76400000000001 W\n",
            "[codecarbon INFO @ 13:23:22] Energy consumed for all CPUs : 0.021778 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:22] 0.044867 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  2% 15/685 [03:23<2:30:29, 13.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:23:37] Energy consumed for RAM : 0.004927 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:23:37] Energy consumed for all GPUs : 0.018453 kWh. Total GPU Power : 60.56100000000001 W\n",
            "[codecarbon INFO @ 13:23:37] Energy consumed for all CPUs : 0.021955 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:37] 0.045336 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  2% 16/685 [03:36<2:30:09, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:23:52] Energy consumed for RAM : 0.004966 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:23:52] Energy consumed for all GPUs : 0.018744 kWh. Total GPU Power : 69.934 W\n",
            "[codecarbon INFO @ 13:23:52] Energy consumed for all CPUs : 0.022133 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:23:52] 0.045844 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  2% 17/685 [03:50<2:29:52, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:24:07] Energy consumed for RAM : 0.005006 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:24:07] Energy consumed for all GPUs : 0.019032 kWh. Total GPU Power : 69.154 W\n",
            "[codecarbon INFO @ 13:24:07] Energy consumed for all CPUs : 0.022310 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:07] 0.046348 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  3% 18/685 [04:03<2:29:39, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:24:22] Energy consumed for RAM : 0.005046 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:24:22] Energy consumed for all GPUs : 0.019317 kWh. Total GPU Power : 68.471 W\n",
            "[codecarbon INFO @ 13:24:22] Energy consumed for all CPUs : 0.022487 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:22] 0.046850 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  3% 20/685 [04:30<2:29:14, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:24:37] Energy consumed for RAM : 0.005086 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:24:37] Energy consumed for all GPUs : 0.019586 kWh. Total GPU Power : 64.68900000000001 W\n",
            "[codecarbon INFO @ 13:24:37] Energy consumed for all CPUs : 0.022664 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:37] 0.047336 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  3% 21/685 [04:44<2:29:00, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:24:52] Energy consumed for RAM : 0.005125 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:24:52] Energy consumed for all GPUs : 0.019868 kWh. Total GPU Power : 67.733 W\n",
            "[codecarbon INFO @ 13:24:52] Energy consumed for all CPUs : 0.022841 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:24:52] 0.047834 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  3% 22/685 [04:57<2:28:45, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:25:07] Energy consumed for RAM : 0.005165 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:25:07] Energy consumed for all GPUs : 0.020125 kWh. Total GPU Power : 61.757 W\n",
            "[codecarbon INFO @ 13:25:07] Energy consumed for all CPUs : 0.023018 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:07] 0.048308 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  3% 23/685 [05:11<2:28:35, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:25:22] Energy consumed for RAM : 0.005205 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:25:22] Energy consumed for all GPUs : 0.020395 kWh. Total GPU Power : 64.747 W\n",
            "[codecarbon INFO @ 13:25:22] Energy consumed for all CPUs : 0.023195 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:22] 0.048794 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  4% 24/685 [05:24<2:28:21, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:25:37] Energy consumed for RAM : 0.005245 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:25:37] Energy consumed for all GPUs : 0.020682 kWh. Total GPU Power : 68.959 W\n",
            "[codecarbon INFO @ 13:25:37] Energy consumed for all CPUs : 0.023372 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:37] 0.049298 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  4% 25/685 [05:38<2:28:08, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:25:52] Energy consumed for RAM : 0.005284 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:25:52] Energy consumed for all GPUs : 0.020964 kWh. Total GPU Power : 67.83 W\n",
            "[codecarbon INFO @ 13:25:52] Energy consumed for all CPUs : 0.023549 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:25:52] 0.049797 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  4% 26/685 [05:51<2:27:53, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:26:07] Energy consumed for RAM : 0.005324 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:26:07] Energy consumed for all GPUs : 0.021254 kWh. Total GPU Power : 69.739 W\n",
            "[codecarbon INFO @ 13:26:07] Energy consumed for all CPUs : 0.023726 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:07] 0.050304 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  4% 27/685 [06:05<2:27:38, 13.46s/it]\r                                      \r{'loss': 1.5533, 'learning_rate': 7.82608695652174e-05, 'epoch': 0.2}\n",
            "\r  4% 27/685 [06:05<2:27:38, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:26:22] Energy consumed for RAM : 0.005364 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:26:22] Energy consumed for all GPUs : 0.021578 kWh. Total GPU Power : 77.836 W\n",
            "[codecarbon INFO @ 13:26:22] Energy consumed for all CPUs : 0.023903 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:22] 0.050845 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  4% 28/685 [06:18<2:27:23, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:26:37] Energy consumed for RAM : 0.005403 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:26:37] Energy consumed for all GPUs : 0.021893 kWh. Total GPU Power : 75.497 W\n",
            "[codecarbon INFO @ 13:26:37] Energy consumed for all CPUs : 0.024080 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:37] 0.051376 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  4% 30/685 [06:45<2:26:51, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:26:52] Energy consumed for RAM : 0.005443 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:26:52] Energy consumed for all GPUs : 0.022189 kWh. Total GPU Power : 71.158 W\n",
            "[codecarbon INFO @ 13:26:52] Energy consumed for all CPUs : 0.024257 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:26:52] 0.051889 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5% 31/685 [06:58<2:26:35, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:27:07] Energy consumed for RAM : 0.005483 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:27:07] Energy consumed for all GPUs : 0.022465 kWh. Total GPU Power : 66.269 W\n",
            "[codecarbon INFO @ 13:27:07] Energy consumed for all CPUs : 0.024434 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:07] 0.052382 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5% 32/685 [07:12<2:26:22, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:27:22] Energy consumed for RAM : 0.005523 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:27:22] Energy consumed for all GPUs : 0.022733 kWh. Total GPU Power : 64.45400000000001 W\n",
            "[codecarbon INFO @ 13:27:22] Energy consumed for all CPUs : 0.024611 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:22] 0.052867 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5% 33/685 [07:25<2:26:08, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:27:37] Energy consumed for RAM : 0.005562 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:27:37] Energy consumed for all GPUs : 0.023021 kWh. Total GPU Power : 69.154 W\n",
            "[codecarbon INFO @ 13:27:37] Energy consumed for all CPUs : 0.024788 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:37] 0.053371 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5% 34/685 [07:39<2:25:53, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:27:52] Energy consumed for RAM : 0.005602 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:27:52] Energy consumed for all GPUs : 0.023327 kWh. Total GPU Power : 73.641 W\n",
            "[codecarbon INFO @ 13:27:52] Energy consumed for all CPUs : 0.024965 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:27:52] 0.053895 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5% 35/685 [07:52<2:25:42, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:28:07] Energy consumed for RAM : 0.005642 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:28:07] Energy consumed for all GPUs : 0.023624 kWh. Total GPU Power : 71.3 W\n",
            "[codecarbon INFO @ 13:28:07] Energy consumed for all CPUs : 0.025142 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:07] 0.054408 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5% 36/685 [08:06<2:25:41, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:28:22] Energy consumed for RAM : 0.005681 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:28:22] Energy consumed for all GPUs : 0.023881 kWh. Total GPU Power : 61.660000000000004 W\n",
            "[codecarbon INFO @ 13:28:22] Energy consumed for all CPUs : 0.025319 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:22] 0.054882 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  5% 37/685 [08:19<2:25:36, 13.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:28:37] Energy consumed for RAM : 0.005721 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:28:37] Energy consumed for all GPUs : 0.024195 kWh. Total GPU Power : 75.447 W\n",
            "[codecarbon INFO @ 13:28:37] Energy consumed for all CPUs : 0.025497 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:37] 0.055413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  6% 38/685 [08:33<2:25:14, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:28:52] Energy consumed for RAM : 0.005761 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:28:52] Energy consumed for all GPUs : 0.024483 kWh. Total GPU Power : 69.24 W\n",
            "[codecarbon INFO @ 13:28:52] Energy consumed for all CPUs : 0.025673 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:28:52] 0.055918 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  6% 40/685 [09:00<2:24:41, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:29:07] Energy consumed for RAM : 0.005801 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:29:07] Energy consumed for all GPUs : 0.024765 kWh. Total GPU Power : 67.775 W\n",
            "[codecarbon INFO @ 13:29:07] Energy consumed for all CPUs : 0.025851 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:07] 0.056416 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  6% 41/685 [09:13<2:24:24, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:29:22] Energy consumed for RAM : 0.005840 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:29:22] Energy consumed for all GPUs : 0.025067 kWh. Total GPU Power : 72.47000000000001 W\n",
            "[codecarbon INFO @ 13:29:22] Energy consumed for all CPUs : 0.026028 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:22] 0.056935 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  6% 42/685 [09:26<2:24:21, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:29:37] Energy consumed for RAM : 0.005880 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:29:37] Energy consumed for all GPUs : 0.025347 kWh. Total GPU Power : 67.132 W\n",
            "[codecarbon INFO @ 13:29:37] Energy consumed for all CPUs : 0.026205 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:37] 0.057431 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  6% 43/685 [09:40<2:24:11, 13.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:29:52] Energy consumed for RAM : 0.005920 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:29:52] Energy consumed for all GPUs : 0.025609 kWh. Total GPU Power : 62.968999999999994 W\n",
            "[codecarbon INFO @ 13:29:52] Energy consumed for all CPUs : 0.026382 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:29:52] 0.057910 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  6% 44/685 [09:53<2:23:58, 13.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:30:07] Energy consumed for RAM : 0.005960 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:30:07] Energy consumed for all GPUs : 0.025875 kWh. Total GPU Power : 64.005 W\n",
            "[codecarbon INFO @ 13:30:07] Energy consumed for all CPUs : 0.026559 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:07] 0.058393 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  7% 45/685 [10:07<2:23:41, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:30:22] Energy consumed for RAM : 0.005999 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:30:22] Energy consumed for all GPUs : 0.026133 kWh. Total GPU Power : 62.05000000000001 W\n",
            "[codecarbon INFO @ 13:30:22] Energy consumed for all CPUs : 0.026736 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:22] 0.058868 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  7% 46/685 [10:20<2:23:28, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:30:37] Energy consumed for RAM : 0.006039 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:30:37] Energy consumed for all GPUs : 0.026450 kWh. Total GPU Power : 76.179 W\n",
            "[codecarbon INFO @ 13:30:37] Energy consumed for all CPUs : 0.026913 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:37] 0.059402 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  7% 47/685 [10:34<2:23:09, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:30:52] Energy consumed for RAM : 0.006079 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:30:52] Energy consumed for all GPUs : 0.026741 kWh. Total GPU Power : 69.88 W\n",
            "[codecarbon INFO @ 13:30:52] Energy consumed for all CPUs : 0.027090 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:30:52] 0.059910 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  7% 49/685 [11:01<2:22:39, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:31:07] Energy consumed for RAM : 0.006118 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:31:07] Energy consumed for all GPUs : 0.027044 kWh. Total GPU Power : 72.86 W\n",
            "[codecarbon INFO @ 13:31:07] Energy consumed for all CPUs : 0.027267 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:07] 0.060430 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  7% 50/685 [11:14<2:22:23, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:31:22] Energy consumed for RAM : 0.006158 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:31:22] Energy consumed for all GPUs : 0.027336 kWh. Total GPU Power : 69.934 W\n",
            "[codecarbon INFO @ 13:31:22] Energy consumed for all CPUs : 0.027444 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:22] 0.060938 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  7% 51/685 [11:28<2:22:09, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:31:37] Energy consumed for RAM : 0.006198 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:31:37] Energy consumed for all GPUs : 0.027632 kWh. Total GPU Power : 71.149 W\n",
            "[codecarbon INFO @ 13:31:37] Energy consumed for all CPUs : 0.027621 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:37] 0.061451 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  8% 52/685 [11:41<2:21:55, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:31:52] Energy consumed for RAM : 0.006238 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:31:52] Energy consumed for all GPUs : 0.027922 kWh. Total GPU Power : 69.782 W\n",
            "[codecarbon INFO @ 13:31:52] Energy consumed for all CPUs : 0.027798 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:31:52] 0.061958 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  8% 53/685 [11:55<2:21:42, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:32:07] Energy consumed for RAM : 0.006277 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:32:07] Energy consumed for all GPUs : 0.028202 kWh. Total GPU Power : 67.09100000000001 W\n",
            "[codecarbon INFO @ 13:32:07] Energy consumed for all CPUs : 0.027975 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:32:07] 0.062454 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  8% 54/685 [12:08<2:21:27, 13.45s/it]\r                                      \r{'loss': 1.3582, 'learning_rate': 0.0001536231884057971, 'epoch': 0.39}\n",
            "\r  8% 54/685 [12:08<2:21:27, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:32:22] Energy consumed for RAM : 0.006317 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:32:22] Energy consumed for all GPUs : 0.028499 kWh. Total GPU Power : 71.539 W\n",
            "[codecarbon INFO @ 13:32:22] Energy consumed for all CPUs : 0.028152 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:32:22] 0.062969 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  8% 55/685 [12:21<2:21:12, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:32:37] Energy consumed for RAM : 0.006357 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:32:37] Energy consumed for all GPUs : 0.028792 kWh. Total GPU Power : 70.368 W\n",
            "[codecarbon INFO @ 13:32:37] Energy consumed for all CPUs : 0.028329 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:32:37] 0.063478 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  8% 56/685 [12:35<2:21:02, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:32:52] Energy consumed for RAM : 0.006396 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:32:52] Energy consumed for all GPUs : 0.029118 kWh. Total GPU Power : 78.127 W\n",
            "[codecarbon INFO @ 13:32:52] Energy consumed for all CPUs : 0.028506 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:32:52] 0.064020 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  8% 57/685 [12:48<2:20:51, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:33:07] Energy consumed for RAM : 0.006436 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:33:07] Energy consumed for all GPUs : 0.029417 kWh. Total GPU Power : 71.983 W\n",
            "[codecarbon INFO @ 13:33:07] Energy consumed for all CPUs : 0.028683 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:33:07] 0.064537 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  9% 59/685 [13:15<2:20:26, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:33:22] Energy consumed for RAM : 0.006476 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:33:22] Energy consumed for all GPUs : 0.029721 kWh. Total GPU Power : 73.055 W\n",
            "[codecarbon INFO @ 13:33:22] Energy consumed for all CPUs : 0.028860 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:33:22] 0.065058 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  9% 60/685 [13:29<2:20:10, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:33:37] Energy consumed for RAM : 0.006516 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:33:37] Energy consumed for all GPUs : 0.029992 kWh. Total GPU Power : 64.982 W\n",
            "[codecarbon INFO @ 13:33:37] Energy consumed for all CPUs : 0.029037 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:33:37] 0.065545 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  9% 61/685 [13:42<2:19:54, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:33:52] Energy consumed for RAM : 0.006555 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:33:52] Energy consumed for all GPUs : 0.030279 kWh. Total GPU Power : 68.904 W\n",
            "[codecarbon INFO @ 13:33:52] Energy consumed for all CPUs : 0.029215 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:33:52] 0.066048 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  9% 62/685 [13:56<2:19:40, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:34:07] Energy consumed for RAM : 0.006595 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:34:07] Energy consumed for all GPUs : 0.030568 kWh. Total GPU Power : 69.587 W\n",
            "[codecarbon INFO @ 13:34:07] Energy consumed for all CPUs : 0.029392 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:34:07] 0.066555 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  9% 63/685 [14:09<2:19:22, 13.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:34:22] Energy consumed for RAM : 0.006635 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:34:22] Energy consumed for all GPUs : 0.030838 kWh. Total GPU Power : 64.68900000000001 W\n",
            "[codecarbon INFO @ 13:34:22] Energy consumed for all CPUs : 0.029569 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:34:22] 0.067041 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  9% 64/685 [14:22<2:19:06, 13.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:34:37] Energy consumed for RAM : 0.006674 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:34:37] Energy consumed for all GPUs : 0.031127 kWh. Total GPU Power : 69.587 W\n",
            "[codecarbon INFO @ 13:34:37] Energy consumed for all CPUs : 0.029746 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:34:37] 0.067547 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r  9% 65/685 [14:36<2:18:46, 13.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:34:52] Energy consumed for RAM : 0.006714 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:34:52] Energy consumed for all GPUs : 0.031412 kWh. Total GPU Power : 68.458 W\n",
            "[codecarbon INFO @ 13:34:52] Energy consumed for all CPUs : 0.029923 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:34:52] 0.068049 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10% 66/685 [14:49<2:18:32, 13.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:35:07] Energy consumed for RAM : 0.006754 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:35:07] Energy consumed for all GPUs : 0.031678 kWh. Total GPU Power : 63.81 W\n",
            "[codecarbon INFO @ 13:35:07] Energy consumed for all CPUs : 0.030100 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:35:07] 0.068531 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10% 67/685 [15:03<2:18:16, 13.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:35:22] Energy consumed for RAM : 0.006794 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:35:22] Energy consumed for all GPUs : 0.031966 kWh. Total GPU Power : 69.24 W\n",
            "[codecarbon INFO @ 13:35:22] Energy consumed for all CPUs : 0.030277 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:35:22] 0.069036 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 10% 69/685 [15:30<2:17:46, 13.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:35:37] Energy consumed for RAM : 0.006833 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:35:37] Energy consumed for all GPUs : 0.032262 kWh. Total GPU Power : 71.105 W\n",
            "[codecarbon INFO @ 13:35:37] Energy consumed for all CPUs : 0.030454 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:35:37] 0.069549 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10% 70/685 [15:43<2:17:30, 13.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:35:52] Energy consumed for RAM : 0.006873 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:35:52] Energy consumed for all GPUs : 0.032534 kWh. Total GPU Power : 65.431 W\n",
            "[codecarbon INFO @ 13:35:52] Energy consumed for all CPUs : 0.030631 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:35:52] 0.070038 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 10% 71/685 [15:56<2:17:14, 13.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:36:07] Energy consumed for RAM : 0.006913 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:36:07] Energy consumed for all GPUs : 0.032857 kWh. Total GPU Power : 77.54300000000002 W\n",
            "[codecarbon INFO @ 13:36:07] Energy consumed for all CPUs : 0.030808 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:36:07] 0.070578 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 11% 72/685 [16:10<2:17:01, 13.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:36:22] Energy consumed for RAM : 0.006953 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:36:22] Energy consumed for all GPUs : 0.033151 kWh. Total GPU Power : 70.661 W\n",
            "[codecarbon INFO @ 13:36:22] Energy consumed for all CPUs : 0.030985 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:36:22] 0.071089 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 11% 73/685 [16:23<2:16:51, 13.42s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:36:37] Energy consumed for RAM : 0.006992 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:36:37] Energy consumed for all GPUs : 0.033431 kWh. Total GPU Power : 67.384 W\n",
            "[codecarbon INFO @ 13:36:37] Energy consumed for all CPUs : 0.031162 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:36:37] 0.071586 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 11% 74/685 [16:37<2:16:36, 13.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:36:52] Energy consumed for RAM : 0.007032 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:36:52] Energy consumed for all GPUs : 0.033719 kWh. Total GPU Power : 69.197 W\n",
            "[codecarbon INFO @ 13:36:52] Energy consumed for all CPUs : 0.031339 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:36:52] 0.072090 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 11% 75/685 [16:50<2:16:21, 13.41s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:37:07] Energy consumed for RAM : 0.007072 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:37:07] Energy consumed for all GPUs : 0.033966 kWh. Total GPU Power : 59.289 W\n",
            "[codecarbon INFO @ 13:37:07] Energy consumed for all CPUs : 0.031516 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:37:07] 0.072554 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 11% 76/685 [17:03<2:16:00, 13.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:37:22] Energy consumed for RAM : 0.007111 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:37:22] Energy consumed for all GPUs : 0.034257 kWh. Total GPU Power : 69.782 W\n",
            "[codecarbon INFO @ 13:37:22] Energy consumed for all CPUs : 0.031693 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:37:22] 0.073061 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 11% 78/685 [17:30<2:15:23, 13.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:37:37] Energy consumed for RAM : 0.007151 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:37:37] Energy consumed for all GPUs : 0.034545 kWh. Total GPU Power : 69.197 W\n",
            "[codecarbon INFO @ 13:37:37] Energy consumed for all CPUs : 0.031870 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:37:37] 0.073566 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 12% 79/685 [17:43<2:15:04, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:37:52] Energy consumed for RAM : 0.007191 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:37:52] Energy consumed for all GPUs : 0.034850 kWh. Total GPU Power : 73.251 W\n",
            "[codecarbon INFO @ 13:37:52] Energy consumed for all CPUs : 0.032047 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:37:52] 0.074088 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 12% 80/685 [17:57<2:14:49, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:38:07] Energy consumed for RAM : 0.007231 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:38:07] Energy consumed for all GPUs : 0.035167 kWh. Total GPU Power : 76.324 W\n",
            "[codecarbon INFO @ 13:38:07] Energy consumed for all CPUs : 0.032224 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:38:07] 0.074622 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 12% 81/685 [18:10<2:14:35, 13.37s/it]\r                                      \r{'loss': 1.32, 'learning_rate': 0.00019642857142857144, 'epoch': 0.59}\n",
            "\r 12% 81/685 [18:10<2:14:35, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:38:22] Energy consumed for RAM : 0.007270 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:38:22] Energy consumed for all GPUs : 0.035464 kWh. Total GPU Power : 71.34400000000001 W\n",
            "[codecarbon INFO @ 13:38:22] Energy consumed for all CPUs : 0.032401 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:38:22] 0.075136 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 12% 82/685 [18:24<2:14:22, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:38:37] Energy consumed for RAM : 0.007310 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:38:37] Energy consumed for all GPUs : 0.035773 kWh. Total GPU Power : 74.226 W\n",
            "[codecarbon INFO @ 13:38:37] Energy consumed for all CPUs : 0.032579 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:38:37] 0.075662 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 12% 83/685 [18:37<2:14:07, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:38:52] Energy consumed for RAM : 0.007350 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:38:52] Energy consumed for all GPUs : 0.036055 kWh. Total GPU Power : 67.57900000000001 W\n",
            "[codecarbon INFO @ 13:38:52] Energy consumed for all CPUs : 0.032756 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:38:52] 0.076160 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 12% 84/685 [18:50<2:13:54, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:39:07] Energy consumed for RAM : 0.007389 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:39:07] Energy consumed for all GPUs : 0.036325 kWh. Total GPU Power : 64.982 W\n",
            "[codecarbon INFO @ 13:39:07] Energy consumed for all CPUs : 0.032933 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:39:07] 0.076647 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 12% 85/685 [19:04<2:13:44, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:39:22] Energy consumed for RAM : 0.007429 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:39:22] Energy consumed for all GPUs : 0.036613 kWh. Total GPU Power : 69.24 W\n",
            "[codecarbon INFO @ 13:39:22] Energy consumed for all CPUs : 0.033110 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:39:22] 0.077152 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 13% 87/685 [19:30<2:13:10, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:39:37] Energy consumed for RAM : 0.007469 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:39:37] Energy consumed for all GPUs : 0.036897 kWh. Total GPU Power : 68.068 W\n",
            "[codecarbon INFO @ 13:39:37] Energy consumed for all CPUs : 0.033287 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:39:37] 0.077652 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 13% 88/685 [19:44<2:12:58, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:39:52] Energy consumed for RAM : 0.007509 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:39:52] Energy consumed for all GPUs : 0.037154 kWh. Total GPU Power : 61.991 W\n",
            "[codecarbon INFO @ 13:39:52] Energy consumed for all CPUs : 0.033464 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:39:52] 0.078127 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 13% 89/685 [19:57<2:12:45, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:40:07] Energy consumed for RAM : 0.007548 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:40:07] Energy consumed for all GPUs : 0.037447 kWh. Total GPU Power : 70.368 W\n",
            "[codecarbon INFO @ 13:40:07] Energy consumed for all CPUs : 0.033641 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:40:07] 0.078637 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 13% 90/685 [20:10<2:12:32, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:40:22] Energy consumed for RAM : 0.007588 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:40:22] Energy consumed for all GPUs : 0.037745 kWh. Total GPU Power : 71.495 W\n",
            "[codecarbon INFO @ 13:40:22] Energy consumed for all CPUs : 0.033818 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:40:22] 0.079151 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 13% 91/685 [20:24<2:12:19, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:40:37] Energy consumed for RAM : 0.007628 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:40:37] Energy consumed for all GPUs : 0.038018 kWh. Total GPU Power : 65.626 W\n",
            "[codecarbon INFO @ 13:40:37] Energy consumed for all CPUs : 0.033995 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:40:37] 0.079641 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 13% 92/685 [20:37<2:12:06, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:40:52] Energy consumed for RAM : 0.007667 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:40:52] Energy consumed for all GPUs : 0.038330 kWh. Total GPU Power : 74.811 W\n",
            "[codecarbon INFO @ 13:40:52] Energy consumed for all CPUs : 0.034172 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:40:52] 0.080169 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 14% 93/685 [20:51<2:11:53, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:41:07] Energy consumed for RAM : 0.007707 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:41:07] Energy consumed for all GPUs : 0.038635 kWh. Total GPU Power : 73.303 W\n",
            "[codecarbon INFO @ 13:41:07] Energy consumed for all CPUs : 0.034349 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:41:07] 0.080691 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 14% 94/685 [21:04<2:11:37, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:41:22] Energy consumed for RAM : 0.007747 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:41:22] Energy consumed for all GPUs : 0.038906 kWh. Total GPU Power : 65.08 W\n",
            "[codecarbon INFO @ 13:41:22] Energy consumed for all CPUs : 0.034526 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:41:22] 0.081179 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 14% 96/685 [21:31<2:11:12, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:41:37] Energy consumed for RAM : 0.007787 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:41:37] Energy consumed for all GPUs : 0.039203 kWh. Total GPU Power : 71.44200000000001 W\n",
            "[codecarbon INFO @ 13:41:37] Energy consumed for all CPUs : 0.034703 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:41:37] 0.081693 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 14% 97/685 [21:44<2:10:59, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:41:52] Energy consumed for RAM : 0.007826 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:41:52] Energy consumed for all GPUs : 0.039490 kWh. Total GPU Power : 68.904 W\n",
            "[codecarbon INFO @ 13:41:52] Energy consumed for all CPUs : 0.034880 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:41:52] 0.082196 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 14% 98/685 [21:57<2:10:43, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:42:07] Energy consumed for RAM : 0.007866 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:42:07] Energy consumed for all GPUs : 0.039775 kWh. Total GPU Power : 68.654 W\n",
            "[codecarbon INFO @ 13:42:07] Energy consumed for all CPUs : 0.035057 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:42:07] 0.082699 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 14% 99/685 [22:11<2:10:28, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:42:22] Energy consumed for RAM : 0.007906 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:42:22] Energy consumed for all GPUs : 0.040090 kWh. Total GPU Power : 75.497 W\n",
            "[codecarbon INFO @ 13:42:22] Energy consumed for all CPUs : 0.035234 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:42:22] 0.083230 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15% 100/685 [22:24<2:10:13, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:42:37] Energy consumed for RAM : 0.007945 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:42:37] Energy consumed for all GPUs : 0.040347 kWh. Total GPU Power : 61.893 W\n",
            "[codecarbon INFO @ 13:42:37] Energy consumed for all CPUs : 0.035411 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:42:37] 0.083704 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15% 101/685 [22:37<2:10:01, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:42:52] Energy consumed for RAM : 0.007985 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:42:52] Energy consumed for all GPUs : 0.040628 kWh. Total GPU Power : 67.523 W\n",
            "[codecarbon INFO @ 13:42:52] Energy consumed for all CPUs : 0.035588 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:42:52] 0.084202 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15% 102/685 [22:51<2:09:49, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:43:07] Energy consumed for RAM : 0.008025 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:43:07] Energy consumed for all GPUs : 0.040946 kWh. Total GPU Power : 76.277 W\n",
            "[codecarbon INFO @ 13:43:07] Energy consumed for all CPUs : 0.035765 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:43:07] 0.084736 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15% 103/685 [23:04<2:09:40, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:43:22] Energy consumed for RAM : 0.008065 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:43:22] Energy consumed for all GPUs : 0.041218 kWh. Total GPU Power : 65.27500000000002 W\n",
            "[codecarbon INFO @ 13:43:22] Energy consumed for all CPUs : 0.035942 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:43:22] 0.085225 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 15% 104/685 [23:18<2:09:23, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:43:37] Energy consumed for RAM : 0.008104 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:43:37] Energy consumed for all GPUs : 0.041542 kWh. Total GPU Power : 77.88400000000001 W\n",
            "[codecarbon INFO @ 13:43:37] Energy consumed for all CPUs : 0.036119 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:43:37] 0.085766 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 15% 106/685 [23:44<2:08:58, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:43:52] Energy consumed for RAM : 0.008144 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:43:52] Energy consumed for all GPUs : 0.041824 kWh. Total GPU Power : 67.775 W\n",
            "[codecarbon INFO @ 13:43:52] Energy consumed for all CPUs : 0.036296 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:43:52] 0.086264 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16% 107/685 [23:58<2:08:42, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:44:07] Energy consumed for RAM : 0.008184 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:44:07] Energy consumed for all GPUs : 0.042106 kWh. Total GPU Power : 67.872 W\n",
            "[codecarbon INFO @ 13:44:07] Energy consumed for all CPUs : 0.036474 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:44:07] 0.086764 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16% 108/685 [24:11<2:08:32, 13.37s/it]\r                                       \r{'loss': 1.2552, 'learning_rate': 0.00018766233766233769, 'epoch': 0.79}\n",
            "\r 16% 108/685 [24:11<2:08:32, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:44:22] Energy consumed for RAM : 0.008224 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:44:22] Energy consumed for all GPUs : 0.042401 kWh. Total GPU Power : 70.715 W\n",
            "[codecarbon INFO @ 13:44:22] Energy consumed for all CPUs : 0.036651 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:44:22] 0.087275 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16% 109/685 [24:24<2:08:20, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:44:37] Energy consumed for RAM : 0.008263 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:44:37] Energy consumed for all GPUs : 0.042666 kWh. Total GPU Power : 63.81 W\n",
            "[codecarbon INFO @ 13:44:37] Energy consumed for all CPUs : 0.036828 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:44:37] 0.087757 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16% 110/685 [24:38<2:08:03, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:44:52] Energy consumed for RAM : 0.008303 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:44:52] Energy consumed for all GPUs : 0.042953 kWh. Total GPU Power : 68.904 W\n",
            "[codecarbon INFO @ 13:44:52] Energy consumed for all CPUs : 0.037005 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:44:52] 0.088261 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16% 111/685 [24:51<2:07:51, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:45:07] Energy consumed for RAM : 0.008343 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:45:07] Energy consumed for all GPUs : 0.043264 kWh. Total GPU Power : 74.57000000000001 W\n",
            "[codecarbon INFO @ 13:45:07] Energy consumed for all CPUs : 0.037182 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:45:07] 0.088788 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16% 112/685 [25:04<2:07:37, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:45:22] Energy consumed for RAM : 0.008382 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:45:22] Energy consumed for all GPUs : 0.043511 kWh. Total GPU Power : 59.484 W\n",
            "[codecarbon INFO @ 13:45:22] Energy consumed for all CPUs : 0.037359 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:45:22] 0.089252 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 16% 113/685 [25:18<2:07:19, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:45:37] Energy consumed for RAM : 0.008422 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:45:37] Energy consumed for all GPUs : 0.043787 kWh. Total GPU Power : 66.212 W\n",
            "[codecarbon INFO @ 13:45:37] Energy consumed for all CPUs : 0.037536 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:45:37] 0.089745 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 17% 115/685 [25:44<2:06:48, 13.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:45:52] Energy consumed for RAM : 0.008462 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:45:52] Energy consumed for all GPUs : 0.044100 kWh. Total GPU Power : 75.35000000000001 W\n",
            "[codecarbon INFO @ 13:45:52] Energy consumed for all CPUs : 0.037713 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:45:52] 0.090275 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 17% 116/685 [25:58<2:06:33, 13.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:46:07] Energy consumed for RAM : 0.008502 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:46:07] Energy consumed for all GPUs : 0.044375 kWh. Total GPU Power : 66.057 W\n",
            "[codecarbon INFO @ 13:46:07] Energy consumed for all CPUs : 0.037890 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:46:07] 0.090767 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 17% 117/685 [26:11<2:06:24, 13.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:46:22] Energy consumed for RAM : 0.008541 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:46:22] Energy consumed for all GPUs : 0.044645 kWh. Total GPU Power : 64.885 W\n",
            "[codecarbon INFO @ 13:46:22] Energy consumed for all CPUs : 0.038067 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:46:22] 0.091254 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 17% 118/685 [26:25<2:06:11, 13.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:46:37] Energy consumed for RAM : 0.008581 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:46:37] Energy consumed for all GPUs : 0.044901 kWh. Total GPU Power : 61.344 W\n",
            "[codecarbon INFO @ 13:46:37] Energy consumed for all CPUs : 0.038244 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:46:37] 0.091726 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 17% 119/685 [26:38<2:06:02, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:46:52] Energy consumed for RAM : 0.008621 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:46:52] Energy consumed for all GPUs : 0.045177 kWh. Total GPU Power : 66.407 W\n",
            "[codecarbon INFO @ 13:46:52] Energy consumed for all CPUs : 0.038421 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:46:52] 0.092219 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 18% 120/685 [26:51<2:05:49, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:47:07] Energy consumed for RAM : 0.008660 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:47:07] Energy consumed for all GPUs : 0.045466 kWh. Total GPU Power : 69.337 W\n",
            "[codecarbon INFO @ 13:47:07] Energy consumed for all CPUs : 0.038598 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:47:07] 0.092724 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 18% 121/685 [27:05<2:05:36, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:47:22] Energy consumed for RAM : 0.008700 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:47:22] Energy consumed for all GPUs : 0.045722 kWh. Total GPU Power : 61.502 W\n",
            "[codecarbon INFO @ 13:47:22] Energy consumed for all CPUs : 0.038775 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:47:22] 0.093197 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 18% 122/685 [27:18<2:05:26, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:47:37] Energy consumed for RAM : 0.008740 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:47:37] Energy consumed for all GPUs : 0.045999 kWh. Total GPU Power : 66.7 W\n",
            "[codecarbon INFO @ 13:47:37] Energy consumed for all CPUs : 0.038952 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:47:37] 0.093691 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 18% 124/685 [27:45<2:05:02, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:47:52] Energy consumed for RAM : 0.008780 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:47:52] Energy consumed for all GPUs : 0.046285 kWh. Total GPU Power : 68.654 W\n",
            "[codecarbon INFO @ 13:47:52] Energy consumed for all CPUs : 0.039129 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:47:52] 0.094194 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 18% 125/685 [27:58<2:04:47, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:48:07] Energy consumed for RAM : 0.008819 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:48:07] Energy consumed for all GPUs : 0.046571 kWh. Total GPU Power : 68.611 W\n",
            "[codecarbon INFO @ 13:48:07] Energy consumed for all CPUs : 0.039306 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:48:07] 0.094697 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 18% 126/685 [28:12<2:04:38, 13.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:48:22] Energy consumed for RAM : 0.008859 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:48:22] Energy consumed for all GPUs : 0.046819 kWh. Total GPU Power : 59.582 W\n",
            "[codecarbon INFO @ 13:48:22] Energy consumed for all CPUs : 0.039483 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:48:22] 0.095161 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 19% 127/685 [28:25<2:04:22, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:48:37] Energy consumed for RAM : 0.008899 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:48:37] Energy consumed for all GPUs : 0.047111 kWh. Total GPU Power : 70.173 W\n",
            "[codecarbon INFO @ 13:48:37] Energy consumed for all CPUs : 0.039661 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:48:37] 0.095670 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 19% 128/685 [28:38<2:04:10, 13.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:48:52] Energy consumed for RAM : 0.008939 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:48:52] Energy consumed for all GPUs : 0.047411 kWh. Total GPU Power : 72.08 W\n",
            "[codecarbon INFO @ 13:48:52] Energy consumed for all CPUs : 0.039838 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:48:52] 0.096187 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 19% 129/685 [28:52<2:03:53, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:49:07] Energy consumed for RAM : 0.008978 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:49:07] Energy consumed for all GPUs : 0.047704 kWh. Total GPU Power : 70.27 W\n",
            "[codecarbon INFO @ 13:49:07] Energy consumed for all CPUs : 0.040015 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:49:07] 0.096696 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 19% 130/685 [29:05<2:03:39, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:49:22] Energy consumed for RAM : 0.009018 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:49:22] Energy consumed for all GPUs : 0.047979 kWh. Total GPU Power : 66.212 W\n",
            "[codecarbon INFO @ 13:49:22] Energy consumed for all CPUs : 0.040192 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:49:22] 0.097189 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 19% 131/685 [29:18<2:03:22, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:49:37] Energy consumed for RAM : 0.009058 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:49:37] Energy consumed for all GPUs : 0.048265 kWh. Total GPU Power : 68.611 W\n",
            "[codecarbon INFO @ 13:49:37] Energy consumed for all CPUs : 0.040369 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:49:37] 0.097691 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 19% 133/685 [29:45<2:02:59, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:49:52] Energy consumed for RAM : 0.009097 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:49:52] Energy consumed for all GPUs : 0.048569 kWh. Total GPU Power : 73.108 W\n",
            "[codecarbon INFO @ 13:49:52] Energy consumed for all CPUs : 0.040546 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:49:52] 0.098212 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20% 134/685 [29:59<2:02:48, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:50:07] Energy consumed for RAM : 0.009137 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:50:07] Energy consumed for all GPUs : 0.048874 kWh. Total GPU Power : 73.4 W\n",
            "[codecarbon INFO @ 13:50:07] Energy consumed for all CPUs : 0.040723 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:50:07] 0.098734 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20% 135/685 [30:12<2:02:36, 13.38s/it]\r                                       \r{'loss': 1.2336, 'learning_rate': 0.0001788961038961039, 'epoch': 0.99}\n",
            "\r 20% 135/685 [30:12<2:02:36, 13.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:50:22] Energy consumed for RAM : 0.009177 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:50:22] Energy consumed for all GPUs : 0.049175 kWh. Total GPU Power : 72.373 W\n",
            "[codecarbon INFO @ 13:50:22] Energy consumed for all CPUs : 0.040900 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:50:22] 0.099252 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20% 136/685 [30:25<2:02:21, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:50:37] Energy consumed for RAM : 0.009217 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:50:37] Energy consumed for all GPUs : 0.049477 kWh. Total GPU Power : 72.373 W\n",
            "[codecarbon INFO @ 13:50:37] Energy consumed for all CPUs : 0.041077 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:50:37] 0.099770 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20% 137/685 [30:39<2:02:04, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:50:52] Energy consumed for RAM : 0.009256 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:50:52] Energy consumed for all GPUs : 0.049771 kWh. Total GPU Power : 70.617 W\n",
            "[codecarbon INFO @ 13:50:52] Energy consumed for all CPUs : 0.041254 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:50:52] 0.100281 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20% 138/685 [30:53<2:03:32, 13.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:51:07] Energy consumed for RAM : 0.009296 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:51:07] Energy consumed for all GPUs : 0.050057 kWh. Total GPU Power : 68.849 W\n",
            "[codecarbon INFO @ 13:51:07] Energy consumed for all CPUs : 0.041431 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:51:07] 0.100784 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20% 139/685 [31:06<2:02:49, 13.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:51:22] Energy consumed for RAM : 0.009336 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:51:22] Energy consumed for all GPUs : 0.050383 kWh. Total GPU Power : 78.322 W\n",
            "[codecarbon INFO @ 13:51:22] Energy consumed for all CPUs : 0.041608 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:51:22] 0.101327 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 20% 140/685 [31:19<2:02:12, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:51:37] Energy consumed for RAM : 0.009375 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:51:37] Energy consumed for all GPUs : 0.050643 kWh. Total GPU Power : 62.382 W\n",
            "[codecarbon INFO @ 13:51:37] Energy consumed for all CPUs : 0.041785 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:51:37] 0.101803 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 21% 141/685 [31:33<2:01:44, 13.43s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:51:52] Energy consumed for RAM : 0.009415 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:51:52] Energy consumed for all GPUs : 0.050901 kWh. Total GPU Power : 61.991 W\n",
            "[codecarbon INFO @ 13:51:52] Energy consumed for all CPUs : 0.041962 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:51:52] 0.102278 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 21% 143/685 [31:59<2:00:58, 13.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:52:07] Energy consumed for RAM : 0.009455 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:52:07] Energy consumed for all GPUs : 0.051178 kWh. Total GPU Power : 66.603 W\n",
            "[codecarbon INFO @ 13:52:07] Energy consumed for all CPUs : 0.042139 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:52:07] 0.102772 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 21% 144/685 [32:13<2:00:40, 13.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:52:22] Energy consumed for RAM : 0.009495 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:52:22] Energy consumed for all GPUs : 0.051469 kWh. Total GPU Power : 69.88 W\n",
            "[codecarbon INFO @ 13:52:22] Energy consumed for all CPUs : 0.042316 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:52:22] 0.103280 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 21% 145/685 [32:26<2:00:23, 13.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:52:37] Energy consumed for RAM : 0.009534 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:52:37] Energy consumed for all GPUs : 0.051750 kWh. Total GPU Power : 67.67700000000002 W\n",
            "[codecarbon INFO @ 13:52:37] Energy consumed for all CPUs : 0.042493 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:52:37] 0.103778 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 21% 146/685 [32:39<2:00:05, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:52:52] Energy consumed for RAM : 0.009574 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:52:52] Energy consumed for all GPUs : 0.052033 kWh. Total GPU Power : 67.872 W\n",
            "[codecarbon INFO @ 13:52:52] Energy consumed for all CPUs : 0.042670 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:52:52] 0.104277 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 21% 147/685 [32:53<1:59:45, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:53:07] Energy consumed for RAM : 0.009614 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:53:07] Energy consumed for all GPUs : 0.052290 kWh. Total GPU Power : 61.795 W\n",
            "[codecarbon INFO @ 13:53:07] Energy consumed for all CPUs : 0.042847 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:53:07] 0.104751 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 22% 148/685 [33:06<1:59:38, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:53:22] Energy consumed for RAM : 0.009653 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:53:22] Energy consumed for all GPUs : 0.052581 kWh. Total GPU Power : 69.88 W\n",
            "[codecarbon INFO @ 13:53:22] Energy consumed for all CPUs : 0.043024 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:53:22] 0.105259 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 22% 149/685 [33:20<1:59:23, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:53:37] Energy consumed for RAM : 0.009693 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:53:37] Energy consumed for all GPUs : 0.052879 kWh. Total GPU Power : 71.495 W\n",
            "[codecarbon INFO @ 13:53:37] Energy consumed for all CPUs : 0.043201 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:53:37] 0.105773 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 22% 150/685 [33:33<1:59:10, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:53:52] Energy consumed for RAM : 0.009733 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:53:52] Energy consumed for all GPUs : 0.053168 kWh. Total GPU Power : 69.49 W\n",
            "[codecarbon INFO @ 13:53:52] Energy consumed for all CPUs : 0.043378 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:53:52] 0.106279 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 22% 152/685 [34:00<1:58:42, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:54:07] Energy consumed for RAM : 0.009773 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:54:07] Energy consumed for all GPUs : 0.053463 kWh. Total GPU Power : 70.91 W\n",
            "[codecarbon INFO @ 13:54:07] Energy consumed for all CPUs : 0.043555 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:54:07] 0.106791 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 22% 153/685 [34:13<1:58:31, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:54:22] Energy consumed for RAM : 0.009812 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:54:22] Energy consumed for all GPUs : 0.053750 kWh. Total GPU Power : 68.947 W\n",
            "[codecarbon INFO @ 13:54:22] Energy consumed for all CPUs : 0.043733 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:54:22] 0.107295 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 22% 154/685 [34:26<1:58:17, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:54:37] Energy consumed for RAM : 0.009852 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:54:37] Energy consumed for all GPUs : 0.054078 kWh. Total GPU Power : 78.85800000000002 W\n",
            "[codecarbon INFO @ 13:54:37] Energy consumed for all CPUs : 0.043910 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:54:37] 0.107840 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 23% 155/685 [34:40<1:58:04, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:54:52] Energy consumed for RAM : 0.009892 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:54:52] Energy consumed for all GPUs : 0.054339 kWh. Total GPU Power : 62.57699999999999 W\n",
            "[codecarbon INFO @ 13:54:52] Energy consumed for all CPUs : 0.044087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:54:52] 0.108317 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 23% 156/685 [34:53<1:57:50, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:55:07] Energy consumed for RAM : 0.009931 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:55:07] Energy consumed for all GPUs : 0.054598 kWh. Total GPU Power : 62.186 W\n",
            "[codecarbon INFO @ 13:55:07] Energy consumed for all CPUs : 0.044264 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:55:07] 0.108793 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 23% 157/685 [35:06<1:57:37, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:55:22] Energy consumed for RAM : 0.009971 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:55:22] Energy consumed for all GPUs : 0.054886 kWh. Total GPU Power : 69.24 W\n",
            "[codecarbon INFO @ 13:55:22] Energy consumed for all CPUs : 0.044441 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:55:22] 0.109298 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 23% 158/685 [35:20<1:57:25, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:55:37] Energy consumed for RAM : 0.010011 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:55:37] Energy consumed for all GPUs : 0.055179 kWh. Total GPU Power : 70.422 W\n",
            "[codecarbon INFO @ 13:55:37] Energy consumed for all CPUs : 0.044618 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:55:37] 0.109808 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 23% 159/685 [35:33<1:57:13, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:55:52] Energy consumed for RAM : 0.010051 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:55:52] Energy consumed for all GPUs : 0.055499 kWh. Total GPU Power : 76.81200000000001 W\n",
            "[codecarbon INFO @ 13:55:52] Energy consumed for all CPUs : 0.044795 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:55:52] 0.110344 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 24% 161/685 [36:00<1:56:41, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:56:07] Energy consumed for RAM : 0.010090 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:56:07] Energy consumed for all GPUs : 0.055792 kWh. Total GPU Power : 70.368 W\n",
            "[codecarbon INFO @ 13:56:07] Energy consumed for all CPUs : 0.044972 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:56:07] 0.110854 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 24% 162/685 [36:13<1:56:29, 13.36s/it]\r                                       \r{'loss': 1.1885, 'learning_rate': 0.00017012987012987013, 'epoch': 1.18}\n",
            "\r 24% 162/685 [36:13<1:56:29, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:56:22] Energy consumed for RAM : 0.010130 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:56:22] Energy consumed for all GPUs : 0.056049 kWh. Total GPU Power : 61.795 W\n",
            "[codecarbon INFO @ 13:56:22] Energy consumed for all CPUs : 0.045149 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:56:22] 0.111328 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 24% 163/685 [36:27<1:56:16, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:56:37] Energy consumed for RAM : 0.010170 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:56:37] Energy consumed for all GPUs : 0.056387 kWh. Total GPU Power : 81.194 W\n",
            "[codecarbon INFO @ 13:56:37] Energy consumed for all CPUs : 0.045326 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:56:37] 0.111883 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 24% 164/685 [36:40<1:56:03, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:56:52] Energy consumed for RAM : 0.010209 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:56:52] Energy consumed for all GPUs : 0.056706 kWh. Total GPU Power : 76.764 W\n",
            "[codecarbon INFO @ 13:56:52] Energy consumed for all CPUs : 0.045503 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:56:52] 0.112419 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 24% 165/685 [36:53<1:55:46, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:57:07] Energy consumed for RAM : 0.010249 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:57:07] Energy consumed for all GPUs : 0.057005 kWh. Total GPU Power : 71.78800000000001 W\n",
            "[codecarbon INFO @ 13:57:07] Energy consumed for all CPUs : 0.045680 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:57:07] 0.112934 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 24% 166/685 [37:07<1:55:33, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:57:22] Energy consumed for RAM : 0.010289 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:57:22] Energy consumed for all GPUs : 0.057302 kWh. Total GPU Power : 71.44200000000001 W\n",
            "[codecarbon INFO @ 13:57:22] Energy consumed for all CPUs : 0.045857 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:57:22] 0.113449 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 24% 167/685 [37:20<1:55:21, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:57:37] Energy consumed for RAM : 0.010329 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:57:37] Energy consumed for all GPUs : 0.057580 kWh. Total GPU Power : 66.741 W\n",
            "[codecarbon INFO @ 13:57:37] Energy consumed for all CPUs : 0.046034 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:57:37] 0.113943 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25% 168/685 [37:33<1:55:09, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:57:52] Energy consumed for RAM : 0.010368 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:57:52] Energy consumed for all GPUs : 0.057843 kWh. Total GPU Power : 63.164 W\n",
            "[codecarbon INFO @ 13:57:52] Energy consumed for all CPUs : 0.046211 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:57:52] 0.114423 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 25% 170/685 [38:00<1:54:43, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:58:07] Energy consumed for RAM : 0.010408 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:58:07] Energy consumed for all GPUs : 0.058129 kWh. Total GPU Power : 68.654 W\n",
            "[codecarbon INFO @ 13:58:07] Energy consumed for all CPUs : 0.046388 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:58:07] 0.114925 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25% 171/685 [38:14<1:54:26, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:58:22] Energy consumed for RAM : 0.010448 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:58:22] Energy consumed for all GPUs : 0.058388 kWh. Total GPU Power : 62.382 W\n",
            "[codecarbon INFO @ 13:58:22] Energy consumed for all CPUs : 0.046565 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:58:22] 0.115402 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25% 172/685 [38:27<1:54:13, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:58:37] Energy consumed for RAM : 0.010488 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:58:37] Energy consumed for all GPUs : 0.058691 kWh. Total GPU Power : 72.665 W\n",
            "[codecarbon INFO @ 13:58:37] Energy consumed for all CPUs : 0.046742 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:58:37] 0.115921 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25% 173/685 [38:40<1:53:59, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:58:52] Energy consumed for RAM : 0.010527 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:58:52] Energy consumed for all GPUs : 0.058967 kWh. Total GPU Power : 66.253 W\n",
            "[codecarbon INFO @ 13:58:52] Energy consumed for all CPUs : 0.046920 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:58:52] 0.116413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 25% 174/685 [38:54<1:53:47, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:59:07] Energy consumed for RAM : 0.010567 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:59:07] Energy consumed for all GPUs : 0.059247 kWh. Total GPU Power : 67.286 W\n",
            "[codecarbon INFO @ 13:59:07] Energy consumed for all CPUs : 0.047097 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:59:07] 0.116910 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 26% 175/685 [39:07<1:53:31, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:59:22] Energy consumed for RAM : 0.010607 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:59:22] Energy consumed for all GPUs : 0.059502 kWh. Total GPU Power : 61.40400000000001 W\n",
            "[codecarbon INFO @ 13:59:22] Energy consumed for all CPUs : 0.047274 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:59:22] 0.117382 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 26% 176/685 [39:20<1:53:19, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:59:37] Energy consumed for RAM : 0.010646 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:59:37] Energy consumed for all GPUs : 0.059785 kWh. Total GPU Power : 67.97 W\n",
            "[codecarbon INFO @ 13:59:37] Energy consumed for all CPUs : 0.047451 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:59:37] 0.117882 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 26% 177/685 [39:34<1:53:08, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 13:59:52] Energy consumed for RAM : 0.010686 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 13:59:52] Energy consumed for all GPUs : 0.060085 kWh. Total GPU Power : 72.08 W\n",
            "[codecarbon INFO @ 13:59:52] Energy consumed for all CPUs : 0.047628 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 13:59:52] 0.118399 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 26% 179/685 [40:00<1:52:42, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:00:07] Energy consumed for RAM : 0.010726 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:00:07] Energy consumed for all GPUs : 0.060365 kWh. Total GPU Power : 67.286 W\n",
            "[codecarbon INFO @ 14:00:07] Energy consumed for all CPUs : 0.047805 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:00:07] 0.118896 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 26% 180/685 [40:14<1:52:27, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:00:22] Energy consumed for RAM : 0.010766 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:00:22] Energy consumed for all GPUs : 0.060647 kWh. Total GPU Power : 67.775 W\n",
            "[codecarbon INFO @ 14:00:22] Energy consumed for all CPUs : 0.047982 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:00:22] 0.119395 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 26% 181/685 [40:27<1:52:14, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:00:37] Energy consumed for RAM : 0.010805 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:00:37] Energy consumed for all GPUs : 0.060944 kWh. Total GPU Power : 71.246 W\n",
            "[codecarbon INFO @ 14:00:37] Energy consumed for all CPUs : 0.048159 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:00:37] 0.119908 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 27% 182/685 [40:41<1:52:02, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:00:52] Energy consumed for RAM : 0.010845 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:00:52] Energy consumed for all GPUs : 0.061220 kWh. Total GPU Power : 66.253 W\n",
            "[codecarbon INFO @ 14:00:52] Energy consumed for all CPUs : 0.048336 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:00:52] 0.120400 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 27% 183/685 [40:54<1:51:49, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:01:07] Energy consumed for RAM : 0.010885 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:01:07] Energy consumed for all GPUs : 0.061527 kWh. Total GPU Power : 73.88700000000001 W\n",
            "[codecarbon INFO @ 14:01:07] Energy consumed for all CPUs : 0.048513 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:01:07] 0.120925 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 27% 184/685 [41:07<1:51:35, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:01:22] Energy consumed for RAM : 0.010924 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:01:22] Energy consumed for all GPUs : 0.061834 kWh. Total GPU Power : 73.738 W\n",
            "[codecarbon INFO @ 14:01:22] Energy consumed for all CPUs : 0.048690 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:01:22] 0.121449 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 27% 185/685 [41:21<1:51:20, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:01:37] Energy consumed for RAM : 0.010964 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:01:37] Energy consumed for all GPUs : 0.062106 kWh. Total GPU Power : 65.373 W\n",
            "[codecarbon INFO @ 14:01:37] Energy consumed for all CPUs : 0.048867 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:01:37] 0.121937 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 27% 186/685 [41:34<1:51:07, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:01:52] Energy consumed for RAM : 0.011004 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:01:52] Energy consumed for all GPUs : 0.062382 kWh. Total GPU Power : 66.31 W\n",
            "[codecarbon INFO @ 14:01:52] Energy consumed for all CPUs : 0.049044 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:01:52] 0.122430 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 27% 188/685 [42:01<1:50:36, 13.35s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:02:07] Energy consumed for RAM : 0.011044 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:02:07] Energy consumed for all GPUs : 0.062669 kWh. Total GPU Power : 68.904 W\n",
            "[codecarbon INFO @ 14:02:07] Energy consumed for all CPUs : 0.049221 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:02:07] 0.122934 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 28% 189/685 [42:14<1:50:24, 13.36s/it]\r                                       \r{'loss': 1.2022, 'learning_rate': 0.00016136363636363635, 'epoch': 1.38}\n",
            "\r 28% 189/685 [42:14<1:50:24, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:02:22] Energy consumed for RAM : 0.011083 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:02:22] Energy consumed for all GPUs : 0.062950 kWh. Total GPU Power : 67.57900000000001 W\n",
            "[codecarbon INFO @ 14:02:22] Energy consumed for all CPUs : 0.049398 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:02:22] 0.123432 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 28% 190/685 [42:27<1:50:11, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:02:37] Energy consumed for RAM : 0.011123 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:02:37] Energy consumed for all GPUs : 0.063223 kWh. Total GPU Power : 65.569 W\n",
            "[codecarbon INFO @ 14:02:37] Energy consumed for all CPUs : 0.049575 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:02:37] 0.123922 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 28% 191/685 [42:41<1:49:59, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:02:52] Energy consumed for RAM : 0.011163 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:02:52] Energy consumed for all GPUs : 0.063498 kWh. Total GPU Power : 66.017 W\n",
            "[codecarbon INFO @ 14:02:52] Energy consumed for all CPUs : 0.049752 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:02:52] 0.124413 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 28% 192/685 [42:54<1:49:47, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:03:07] Energy consumed for RAM : 0.011202 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:03:07] Energy consumed for all GPUs : 0.063797 kWh. Total GPU Power : 71.69 W\n",
            "[codecarbon INFO @ 14:03:07] Energy consumed for all CPUs : 0.049929 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:03:07] 0.124928 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 28% 193/685 [43:08<1:49:34, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:03:22] Energy consumed for RAM : 0.011242 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:03:22] Energy consumed for all GPUs : 0.064098 kWh. Total GPU Power : 72.515 W\n",
            "[codecarbon INFO @ 14:03:22] Energy consumed for all CPUs : 0.050106 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:03:22] 0.125447 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 28% 194/685 [43:21<1:49:21, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:03:37] Energy consumed for RAM : 0.011282 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:03:37] Energy consumed for all GPUs : 0.064354 kWh. Total GPU Power : 61.344 W\n",
            "[codecarbon INFO @ 14:03:37] Energy consumed for all CPUs : 0.050283 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:03:37] 0.125919 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 28% 195/685 [43:34<1:49:06, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:03:52] Energy consumed for RAM : 0.011322 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:03:52] Energy consumed for all GPUs : 0.064632 kWh. Total GPU Power : 66.839 W\n",
            "[codecarbon INFO @ 14:03:52] Energy consumed for all CPUs : 0.050460 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:03:52] 0.126414 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 29% 196/685 [43:48<1:48:54, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:04:07] Energy consumed for RAM : 0.011361 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:04:07] Energy consumed for all GPUs : 0.064921 kWh. Total GPU Power : 69.587 W\n",
            "[codecarbon INFO @ 14:04:07] Energy consumed for all CPUs : 0.050637 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:04:07] 0.126920 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 29% 198/685 [44:14<1:48:28, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:04:22] Energy consumed for RAM : 0.011401 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:04:22] Energy consumed for all GPUs : 0.065240 kWh. Total GPU Power : 76.374 W\n",
            "[codecarbon INFO @ 14:04:22] Energy consumed for all CPUs : 0.050815 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:04:22] 0.127455 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 29% 199/685 [44:28<1:48:17, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:04:37] Energy consumed for RAM : 0.011441 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:04:37] Energy consumed for all GPUs : 0.065530 kWh. Total GPU Power : 69.685 W\n",
            "[codecarbon INFO @ 14:04:37] Energy consumed for all CPUs : 0.050992 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:04:37] 0.127962 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 29% 200/685 [44:41<1:47:59, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:04:52] Energy consumed for RAM : 0.011481 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:04:52] Energy consumed for all GPUs : 0.065808 kWh. Total GPU Power : 66.839 W\n",
            "[codecarbon INFO @ 14:04:52] Energy consumed for all CPUs : 0.051169 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:04:52] 0.128457 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 29% 201/685 [44:54<1:47:47, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:05:07] Energy consumed for RAM : 0.011520 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:05:07] Energy consumed for all GPUs : 0.066086 kWh. Total GPU Power : 66.896 W\n",
            "[codecarbon INFO @ 14:05:07] Energy consumed for all CPUs : 0.051346 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:05:07] 0.128952 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 29% 202/685 [45:08<1:47:34, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:05:22] Energy consumed for RAM : 0.011560 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:05:22] Energy consumed for all GPUs : 0.066387 kWh. Total GPU Power : 72.275 W\n",
            "[codecarbon INFO @ 14:05:22] Energy consumed for all CPUs : 0.051523 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:05:22] 0.129469 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30% 203/685 [45:21<1:47:22, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:05:37] Energy consumed for RAM : 0.011600 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:05:37] Energy consumed for all GPUs : 0.066634 kWh. Total GPU Power : 59.484 W\n",
            "[codecarbon INFO @ 14:05:37] Energy consumed for all CPUs : 0.051700 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:05:37] 0.129934 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30% 204/685 [45:35<1:47:11, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:05:52] Energy consumed for RAM : 0.011639 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:05:52] Energy consumed for all GPUs : 0.066960 kWh. Total GPU Power : 78.127 W\n",
            "[codecarbon INFO @ 14:05:52] Energy consumed for all CPUs : 0.051877 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:05:52] 0.130476 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30% 205/685 [45:48<1:46:58, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:06:07] Energy consumed for RAM : 0.011679 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:06:07] Energy consumed for all GPUs : 0.067246 kWh. Total GPU Power : 68.654 W\n",
            "[codecarbon INFO @ 14:06:07] Energy consumed for all CPUs : 0.052054 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:06:07] 0.130978 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 30% 207/685 [46:15<1:46:32, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:06:22] Energy consumed for RAM : 0.011719 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:06:22] Energy consumed for all GPUs : 0.067531 kWh. Total GPU Power : 68.514 W\n",
            "[codecarbon INFO @ 14:06:22] Energy consumed for all CPUs : 0.052231 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:06:22] 0.131481 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 30% 208/685 [46:28<1:46:22, 13.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:06:37] Energy consumed for RAM : 0.011759 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:06:37] Energy consumed for all GPUs : 0.067787 kWh. Total GPU Power : 61.59900000000001 W\n",
            "[codecarbon INFO @ 14:06:37] Energy consumed for all CPUs : 0.052408 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:06:37] 0.131954 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 31% 209/685 [46:41<1:46:07, 13.38s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:06:52] Energy consumed for RAM : 0.011798 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:06:52] Energy consumed for all GPUs : 0.068087 kWh. Total GPU Power : 71.983 W\n",
            "[codecarbon INFO @ 14:06:52] Energy consumed for all CPUs : 0.052585 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:06:52] 0.132470 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 31% 210/685 [46:55<1:45:51, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:07:07] Energy consumed for RAM : 0.011838 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:07:07] Energy consumed for all GPUs : 0.068375 kWh. Total GPU Power : 69.142 W\n",
            "[codecarbon INFO @ 14:07:07] Energy consumed for all CPUs : 0.052762 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:07:07] 0.132975 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 31% 211/685 [47:08<1:45:37, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:07:22] Energy consumed for RAM : 0.011878 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:07:22] Energy consumed for all GPUs : 0.068665 kWh. Total GPU Power : 69.685 W\n",
            "[codecarbon INFO @ 14:07:22] Energy consumed for all CPUs : 0.052939 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:07:22] 0.133481 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 31% 212/685 [47:21<1:45:20, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:07:37] Energy consumed for RAM : 0.011917 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:07:37] Energy consumed for all GPUs : 0.068946 kWh. Total GPU Power : 67.482 W\n",
            "[codecarbon INFO @ 14:07:37] Energy consumed for all CPUs : 0.053116 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:07:37] 0.133979 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 31% 213/685 [47:35<1:45:07, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:07:52] Energy consumed for RAM : 0.011957 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:07:52] Energy consumed for all GPUs : 0.069224 kWh. Total GPU Power : 66.993 W\n",
            "[codecarbon INFO @ 14:07:52] Energy consumed for all CPUs : 0.053293 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:07:52] 0.134475 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 31% 214/685 [47:48<1:44:54, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:08:07] Energy consumed for RAM : 0.011997 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:08:07] Energy consumed for all GPUs : 0.069506 kWh. Total GPU Power : 67.67700000000002 W\n",
            "[codecarbon INFO @ 14:08:07] Energy consumed for all CPUs : 0.053470 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:08:07] 0.134973 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.1927, 'learning_rate': 0.0001525974025974026, 'epoch': 1.58}\n",
            " 32% 216/685 [48:15<1:44:27, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:08:22] Energy consumed for RAM : 0.012037 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:08:22] Energy consumed for all GPUs : 0.069802 kWh. Total GPU Power : 71.149 W\n",
            "[codecarbon INFO @ 14:08:22] Energy consumed for all CPUs : 0.053647 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:08:22] 0.135486 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32% 217/685 [48:28<1:44:14, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:08:37] Energy consumed for RAM : 0.012076 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:08:37] Energy consumed for all GPUs : 0.070077 kWh. Total GPU Power : 66.057 W\n",
            "[codecarbon INFO @ 14:08:37] Energy consumed for all CPUs : 0.053824 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:08:37] 0.135977 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32% 218/685 [48:42<1:43:58, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:08:52] Energy consumed for RAM : 0.012116 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:08:52] Energy consumed for all GPUs : 0.070368 kWh. Total GPU Power : 69.88 W\n",
            "[codecarbon INFO @ 14:08:52] Energy consumed for all CPUs : 0.054001 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:08:52] 0.136485 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32% 219/685 [48:55<1:43:48, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:09:07] Energy consumed for RAM : 0.012156 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:09:07] Energy consumed for all GPUs : 0.070652 kWh. Total GPU Power : 68.263 W\n",
            "[codecarbon INFO @ 14:09:07] Energy consumed for all CPUs : 0.054178 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:09:07] 0.136986 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32% 220/685 [49:08<1:43:36, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:09:22] Energy consumed for RAM : 0.012195 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:09:22] Energy consumed for all GPUs : 0.070945 kWh. Total GPU Power : 70.422 W\n",
            "[codecarbon INFO @ 14:09:22] Energy consumed for all CPUs : 0.054355 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:09:22] 0.137495 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32% 221/685 [49:22<1:43:23, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:09:37] Energy consumed for RAM : 0.012235 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:09:37] Energy consumed for all GPUs : 0.071224 kWh. Total GPU Power : 67.23000000000002 W\n",
            "[codecarbon INFO @ 14:09:37] Energy consumed for all CPUs : 0.054532 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:09:37] 0.137992 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 32% 222/685 [49:35<1:43:08, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:09:52] Energy consumed for RAM : 0.012275 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:09:52] Energy consumed for all GPUs : 0.071521 kWh. Total GPU Power : 71.149 W\n",
            "[codecarbon INFO @ 14:09:52] Energy consumed for all CPUs : 0.054709 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:09:52] 0.138505 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 33% 223/685 [49:49<1:42:54, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:10:07] Energy consumed for RAM : 0.012315 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:10:07] Energy consumed for all GPUs : 0.071823 kWh. Total GPU Power : 72.568 W\n",
            "[codecarbon INFO @ 14:10:07] Energy consumed for all CPUs : 0.054886 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:10:07] 0.139024 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 33% 225/685 [50:15<1:42:25, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:10:22] Energy consumed for RAM : 0.012354 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:10:22] Energy consumed for all GPUs : 0.072112 kWh. Total GPU Power : 69.49 W\n",
            "[codecarbon INFO @ 14:10:22] Energy consumed for all CPUs : 0.055063 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:10:22] 0.139530 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 33% 226/685 [50:29<1:42:10, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:10:37] Energy consumed for RAM : 0.012394 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:10:37] Energy consumed for all GPUs : 0.072382 kWh. Total GPU Power : 64.729 W\n",
            "[codecarbon INFO @ 14:10:37] Energy consumed for all CPUs : 0.055240 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:10:37] 0.140016 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 33% 227/685 [50:42<1:42:00, 13.36s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:10:52] Energy consumed for RAM : 0.012434 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:10:52] Energy consumed for all GPUs : 0.072698 kWh. Total GPU Power : 76.032 W\n",
            "[codecarbon INFO @ 14:10:52] Energy consumed for all CPUs : 0.055417 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:10:52] 0.140549 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 33% 228/685 [50:55<1:41:48, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:11:07] Energy consumed for RAM : 0.012473 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:11:07] Energy consumed for all GPUs : 0.072960 kWh. Total GPU Power : 62.968999999999994 W\n",
            "[codecarbon INFO @ 14:11:07] Energy consumed for all CPUs : 0.055595 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:11:07] 0.141028 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 33% 229/685 [51:09<1:41:37, 13.37s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:11:22] Energy consumed for RAM : 0.012513 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:11:22] Energy consumed for all GPUs : 0.073252 kWh. Total GPU Power : 70.075 W\n",
            "[codecarbon INFO @ 14:11:22] Energy consumed for all CPUs : 0.055772 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:11:22] 0.141537 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 34% 230/685 [51:22<1:41:35, 13.40s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:11:37] Energy consumed for RAM : 0.012553 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:11:37] Energy consumed for all GPUs : 0.073547 kWh. Total GPU Power : 70.9 W\n",
            "[codecarbon INFO @ 14:11:37] Energy consumed for all CPUs : 0.055949 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:11:37] 0.142049 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 34% 231/685 [51:36<1:41:43, 13.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:11:52] Energy consumed for RAM : 0.012593 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:11:52] Energy consumed for all GPUs : 0.073801 kWh. Total GPU Power : 60.952 W\n",
            "[codecarbon INFO @ 14:11:52] Energy consumed for all CPUs : 0.056126 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:11:52] 0.142519 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 34% 232/685 [51:49<1:41:37, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:12:07] Energy consumed for RAM : 0.012632 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:12:07] Energy consumed for all GPUs : 0.074103 kWh. Total GPU Power : 72.613 W\n",
            "[codecarbon INFO @ 14:12:07] Energy consumed for all CPUs : 0.056303 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:12:07] 0.143038 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 34% 233/685 [52:03<1:41:24, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:12:22] Energy consumed for RAM : 0.012672 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:12:22] Energy consumed for all GPUs : 0.074332 kWh. Total GPU Power : 55.01800000000001 W\n",
            "[codecarbon INFO @ 14:12:22] Energy consumed for all CPUs : 0.056480 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:12:22] 0.143484 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 34% 235/685 [52:30<1:40:55, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:12:37] Energy consumed for RAM : 0.012712 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:12:37] Energy consumed for all GPUs : 0.074600 kWh. Total GPU Power : 64.435 W\n",
            "[codecarbon INFO @ 14:12:37] Energy consumed for all CPUs : 0.056657 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:12:37] 0.143969 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 34% 236/685 [52:43<1:40:40, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:12:52] Energy consumed for RAM : 0.012751 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:12:52] Energy consumed for all GPUs : 0.074894 kWh. Total GPU Power : 70.705 W\n",
            "[codecarbon INFO @ 14:12:52] Energy consumed for all CPUs : 0.056834 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:12:52] 0.144480 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35% 237/685 [52:56<1:40:25, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:13:07] Energy consumed for RAM : 0.012791 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:13:07] Energy consumed for all GPUs : 0.075174 kWh. Total GPU Power : 67.132 W\n",
            "[codecarbon INFO @ 14:13:07] Energy consumed for all CPUs : 0.057011 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:13:07] 0.144976 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35% 238/685 [53:10<1:40:19, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:13:22] Energy consumed for RAM : 0.012831 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:13:22] Energy consumed for all GPUs : 0.075489 kWh. Total GPU Power : 75.786 W\n",
            "[codecarbon INFO @ 14:13:22] Energy consumed for all CPUs : 0.057188 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:13:22] 0.145508 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35% 239/685 [53:23<1:40:07, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:13:37] Energy consumed for RAM : 0.012871 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:13:37] Energy consumed for all GPUs : 0.075796 kWh. Total GPU Power : 73.68600000000002 W\n",
            "[codecarbon INFO @ 14:13:37] Energy consumed for all CPUs : 0.057365 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:13:37] 0.146031 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35% 240/685 [53:37<1:39:54, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:13:52] Energy consumed for RAM : 0.012910 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:13:52] Energy consumed for all GPUs : 0.076105 kWh. Total GPU Power : 74.174 W\n",
            "[codecarbon INFO @ 14:13:52] Energy consumed for all CPUs : 0.057542 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:13:52] 0.146557 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35% 241/685 [53:50<1:39:40, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:14:07] Energy consumed for RAM : 0.012950 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:14:07] Energy consumed for all GPUs : 0.076388 kWh. Total GPU Power : 68.012 W\n",
            "[codecarbon INFO @ 14:14:07] Energy consumed for all CPUs : 0.057719 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:14:07] 0.147057 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 35% 242/685 [54:04<1:39:23, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:14:22] Energy consumed for RAM : 0.012990 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:14:22] Energy consumed for all GPUs : 0.076638 kWh. Total GPU Power : 60.206 W\n",
            "[codecarbon INFO @ 14:14:22] Energy consumed for all CPUs : 0.057896 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:14:22] 0.147524 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.1789, 'learning_rate': 0.00014383116883116883, 'epoch': 1.77}\n",
            " 36% 244/685 [54:31<1:38:53, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:14:37] Energy consumed for RAM : 0.013029 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:14:37] Energy consumed for all GPUs : 0.076902 kWh. Total GPU Power : 63.30100000000001 W\n",
            "[codecarbon INFO @ 14:14:37] Energy consumed for all CPUs : 0.058073 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:14:37] 0.148004 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 36% 245/685 [54:44<1:38:40, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:14:52] Energy consumed for RAM : 0.013069 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:14:52] Energy consumed for all GPUs : 0.077186 kWh. Total GPU Power : 68.305 W\n",
            "[codecarbon INFO @ 14:14:52] Energy consumed for all CPUs : 0.058250 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:14:52] 0.148505 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 36% 246/685 [54:58<1:38:25, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:15:07] Energy consumed for RAM : 0.013109 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:15:07] Energy consumed for all GPUs : 0.077505 kWh. Total GPU Power : 76.762 W\n",
            "[codecarbon INFO @ 14:15:07] Energy consumed for all CPUs : 0.058427 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:15:07] 0.149042 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 36% 247/685 [55:11<1:38:10, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:15:22] Energy consumed for RAM : 0.013149 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:15:22] Energy consumed for all GPUs : 0.077804 kWh. Total GPU Power : 71.681 W\n",
            "[codecarbon INFO @ 14:15:22] Energy consumed for all CPUs : 0.058604 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:15:22] 0.149557 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 36% 248/685 [55:25<1:37:56, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:15:37] Energy consumed for RAM : 0.013188 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:15:37] Energy consumed for all GPUs : 0.078056 kWh. Total GPU Power : 60.5 W\n",
            "[codecarbon INFO @ 14:15:37] Energy consumed for all CPUs : 0.058781 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:15:37] 0.150025 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 36% 249/685 [55:38<1:37:44, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:15:52] Energy consumed for RAM : 0.013228 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:15:52] Energy consumed for all GPUs : 0.078346 kWh. Total GPU Power : 69.869 W\n",
            "[codecarbon INFO @ 14:15:52] Energy consumed for all CPUs : 0.058958 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:15:52] 0.150533 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 36% 250/685 [55:51<1:37:31, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:16:07] Energy consumed for RAM : 0.013268 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:16:07] Energy consumed for all GPUs : 0.078626 kWh. Total GPU Power : 67.23000000000002 W\n",
            "[codecarbon INFO @ 14:16:07] Energy consumed for all CPUs : 0.059136 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:16:07] 0.151030 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 37% 251/685 [56:05<1:37:17, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:16:22] Energy consumed for RAM : 0.013307 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:16:22] Energy consumed for all GPUs : 0.078922 kWh. Total GPU Power : 71.095 W\n",
            "[codecarbon INFO @ 14:16:22] Energy consumed for all CPUs : 0.059312 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:16:22] 0.151542 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 37% 252/685 [56:18<1:37:03, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:16:37] Energy consumed for RAM : 0.013347 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:16:37] Energy consumed for all GPUs : 0.079212 kWh. Total GPU Power : 69.63 W\n",
            "[codecarbon INFO @ 14:16:37] Energy consumed for all CPUs : 0.059489 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:16:37] 0.152048 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 37% 254/685 [56:45<1:36:38, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:16:52] Energy consumed for RAM : 0.013387 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:16:52] Energy consumed for all GPUs : 0.079507 kWh. Total GPU Power : 70.998 W\n",
            "[codecarbon INFO @ 14:16:52] Energy consumed for all CPUs : 0.059667 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:16:52] 0.152561 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 37% 255/685 [56:59<1:36:25, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:17:07] Energy consumed for RAM : 0.013427 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:17:07] Energy consumed for all GPUs : 0.079810 kWh. Total GPU Power : 72.808 W\n",
            "[codecarbon INFO @ 14:17:07] Energy consumed for all CPUs : 0.059844 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:17:07] 0.153081 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 37% 256/685 [57:12<1:36:10, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:17:22] Energy consumed for RAM : 0.013466 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:17:22] Energy consumed for all GPUs : 0.080126 kWh. Total GPU Power : 75.786 W\n",
            "[codecarbon INFO @ 14:17:22] Energy consumed for all CPUs : 0.060021 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:17:22] 0.153613 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 38% 257/685 [57:26<1:35:55, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:17:37] Energy consumed for RAM : 0.013506 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:17:37] Energy consumed for all GPUs : 0.080428 kWh. Total GPU Power : 72.658 W\n",
            "[codecarbon INFO @ 14:17:37] Energy consumed for all CPUs : 0.060198 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:17:37] 0.154132 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 38% 258/685 [57:39<1:35:42, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:17:52] Energy consumed for RAM : 0.013546 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:17:52] Energy consumed for all GPUs : 0.080725 kWh. Total GPU Power : 71.388 W\n",
            "[codecarbon INFO @ 14:17:52] Energy consumed for all CPUs : 0.060375 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:17:52] 0.154646 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 38% 259/685 [57:52<1:35:29, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:18:07] Energy consumed for RAM : 0.013585 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:18:07] Energy consumed for all GPUs : 0.080977 kWh. Total GPU Power : 60.5 W\n",
            "[codecarbon INFO @ 14:18:07] Energy consumed for all CPUs : 0.060552 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:18:07] 0.155114 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 38% 260/685 [58:06<1:35:17, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:18:22] Energy consumed for RAM : 0.013625 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:18:22] Energy consumed for all GPUs : 0.081258 kWh. Total GPU Power : 67.425 W\n",
            "[codecarbon INFO @ 14:18:22] Energy consumed for all CPUs : 0.060729 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:18:22] 0.155612 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 38% 261/685 [58:19<1:35:02, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:18:37] Energy consumed for RAM : 0.013665 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:18:37] Energy consumed for all GPUs : 0.081570 kWh. Total GPU Power : 75.104 W\n",
            "[codecarbon INFO @ 14:18:37] Energy consumed for all CPUs : 0.060906 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:18:37] 0.156141 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 38% 262/685 [58:33<1:34:48, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:18:52] Energy consumed for RAM : 0.013705 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:18:52] Energy consumed for all GPUs : 0.081867 kWh. Total GPU Power : 71.29 W\n",
            "[codecarbon INFO @ 14:18:52] Energy consumed for all CPUs : 0.061083 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:18:52] 0.156654 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 39% 264/685 [59:00<1:34:22, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:19:07] Energy consumed for RAM : 0.013744 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:19:07] Energy consumed for all GPUs : 0.082166 kWh. Total GPU Power : 71.734 W\n",
            "[codecarbon INFO @ 14:19:07] Energy consumed for all CPUs : 0.061260 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:19:07] 0.157170 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39% 265/685 [59:13<1:34:10, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:19:22] Energy consumed for RAM : 0.013784 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:19:22] Energy consumed for all GPUs : 0.082424 kWh. Total GPU Power : 62.22400000000001 W\n",
            "[codecarbon INFO @ 14:19:22] Energy consumed for all CPUs : 0.061437 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:19:22] 0.157646 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39% 266/685 [59:27<1:33:58, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:19:37] Energy consumed for RAM : 0.013824 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:19:37] Energy consumed for all GPUs : 0.082704 kWh. Total GPU Power : 67.23000000000002 W\n",
            "[codecarbon INFO @ 14:19:37] Energy consumed for all CPUs : 0.061614 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:19:37] 0.158142 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39% 267/685 [59:40<1:33:42, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:19:52] Energy consumed for RAM : 0.013864 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:19:52] Energy consumed for all GPUs : 0.082993 kWh. Total GPU Power : 69.337 W\n",
            "[codecarbon INFO @ 14:19:52] Energy consumed for all CPUs : 0.061791 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:19:52] 0.158648 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39% 268/685 [59:54<1:33:31, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:20:07] Energy consumed for RAM : 0.013903 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:20:07] Energy consumed for all GPUs : 0.083316 kWh. Total GPU Power : 77.49400000000001 W\n",
            "[codecarbon INFO @ 14:20:07] Energy consumed for all CPUs : 0.061968 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:20:07] 0.159187 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39% 269/685 [1:00:07<1:33:20, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:20:22] Energy consumed for RAM : 0.013943 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:20:22] Energy consumed for all GPUs : 0.083635 kWh. Total GPU Power : 76.66400000000002 W\n",
            "[codecarbon INFO @ 14:20:22] Energy consumed for all CPUs : 0.062145 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:20:22] 0.159723 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 39% 270/685 [1:00:20<1:33:05, 13.46s/it]\r                                         \r{'loss': 1.1918, 'learning_rate': 0.00013506493506493507, 'epoch': 1.97}\n",
            "\r 39% 270/685 [1:00:20<1:33:05, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:20:37] Energy consumed for RAM : 0.013983 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:20:37] Energy consumed for all GPUs : 0.083930 kWh. Total GPU Power : 70.95400000000001 W\n",
            "[codecarbon INFO @ 14:20:37] Energy consumed for all CPUs : 0.062322 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:20:37] 0.160235 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40% 271/685 [1:00:34<1:32:50, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:20:52] Energy consumed for RAM : 0.014022 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:20:52] Energy consumed for all GPUs : 0.084231 kWh. Total GPU Power : 72.32000000000001 W\n",
            "[codecarbon INFO @ 14:20:52] Energy consumed for all CPUs : 0.062499 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:20:52] 0.160753 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 40% 273/685 [1:01:01<1:32:20, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:21:07] Energy consumed for RAM : 0.014062 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:21:07] Energy consumed for all GPUs : 0.084517 kWh. Total GPU Power : 68.696 W\n",
            "[codecarbon INFO @ 14:21:07] Energy consumed for all CPUs : 0.062676 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:21:07] 0.161255 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40% 274/685 [1:01:14<1:32:07, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:21:22] Energy consumed for RAM : 0.014102 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:21:22] Energy consumed for all GPUs : 0.084786 kWh. Total GPU Power : 64.63100000000001 W\n",
            "[codecarbon INFO @ 14:21:22] Energy consumed for all CPUs : 0.062853 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:21:22] 0.161741 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40% 275/685 [1:01:28<1:33:04, 13.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:21:37] Energy consumed for RAM : 0.014142 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:21:37] Energy consumed for all GPUs : 0.085062 kWh. Total GPU Power : 66.196 W\n",
            "[codecarbon INFO @ 14:21:37] Energy consumed for all CPUs : 0.063030 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:21:37] 0.162233 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40% 276/685 [1:01:42<1:32:28, 13.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:21:52] Energy consumed for RAM : 0.014181 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:21:52] Energy consumed for all GPUs : 0.085391 kWh. Total GPU Power : 79.053 W\n",
            "[codecarbon INFO @ 14:21:52] Energy consumed for all CPUs : 0.063207 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:21:52] 0.162779 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 40% 277/685 [1:01:55<1:31:59, 13.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:22:07] Energy consumed for RAM : 0.014221 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:22:07] Energy consumed for all GPUs : 0.085689 kWh. Total GPU Power : 71.583 W\n",
            "[codecarbon INFO @ 14:22:07] Energy consumed for all CPUs : 0.063384 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:22:07] 0.163294 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 41% 278/685 [1:02:09<1:31:36, 13.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:22:22] Energy consumed for RAM : 0.014261 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:22:22] Energy consumed for all GPUs : 0.086009 kWh. Total GPU Power : 76.909 W\n",
            "[codecarbon INFO @ 14:22:22] Energy consumed for all CPUs : 0.063562 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:22:22] 0.163831 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 41% 279/685 [1:02:22<1:31:16, 13.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:22:37] Energy consumed for RAM : 0.014300 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:22:37] Energy consumed for all GPUs : 0.086317 kWh. Total GPU Power : 74.077 W\n",
            "[codecarbon INFO @ 14:22:37] Energy consumed for all CPUs : 0.063739 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:22:37] 0.164356 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 41% 280/685 [1:02:36<1:30:59, 13.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:22:52] Energy consumed for RAM : 0.014340 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:22:52] Energy consumed for all GPUs : 0.086579 kWh. Total GPU Power : 63.00699999999999 W\n",
            "[codecarbon INFO @ 14:22:52] Energy consumed for all CPUs : 0.063916 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:22:52] 0.164835 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 41% 281/685 [1:02:49<1:30:43, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:23:07] Energy consumed for RAM : 0.014380 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:23:07] Energy consumed for all GPUs : 0.086846 kWh. Total GPU Power : 64.142 W\n",
            "[codecarbon INFO @ 14:23:07] Energy consumed for all CPUs : 0.064093 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:23:07] 0.165319 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 41% 282/685 [1:03:02<1:30:29, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:23:22] Energy consumed for RAM : 0.014420 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:23:22] Energy consumed for all GPUs : 0.087139 kWh. Total GPU Power : 70.31400000000002 W\n",
            "[codecarbon INFO @ 14:23:22] Energy consumed for all CPUs : 0.064270 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:23:22] 0.165829 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 41% 284/685 [1:03:29<1:29:57, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:23:37] Energy consumed for RAM : 0.014459 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:23:37] Energy consumed for all GPUs : 0.087466 kWh. Total GPU Power : 78.56600000000002 W\n",
            "[codecarbon INFO @ 14:23:37] Energy consumed for all CPUs : 0.064447 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:23:37] 0.166372 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42% 285/685 [1:03:43<1:29:44, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:23:52] Energy consumed for RAM : 0.014499 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:23:52] Energy consumed for all GPUs : 0.087776 kWh. Total GPU Power : 74.37 W\n",
            "[codecarbon INFO @ 14:23:52] Energy consumed for all CPUs : 0.064624 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:23:52] 0.166899 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42% 286/685 [1:03:56<1:29:30, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:24:07] Energy consumed for RAM : 0.014539 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:24:07] Energy consumed for all GPUs : 0.088077 kWh. Total GPU Power : 72.32000000000001 W\n",
            "[codecarbon INFO @ 14:24:07] Energy consumed for all CPUs : 0.064801 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:24:07] 0.167417 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42% 287/685 [1:04:10<1:29:14, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:24:22] Energy consumed for RAM : 0.014578 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:24:22] Energy consumed for all GPUs : 0.088387 kWh. Total GPU Power : 74.616 W\n",
            "[codecarbon INFO @ 14:24:22] Energy consumed for all CPUs : 0.064978 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:24:22] 0.167944 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42% 288/685 [1:04:23<1:29:02, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:24:37] Energy consumed for RAM : 0.014618 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:24:37] Energy consumed for all GPUs : 0.088686 kWh. Total GPU Power : 71.876 W\n",
            "[codecarbon INFO @ 14:24:37] Energy consumed for all CPUs : 0.065155 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:24:37] 0.168460 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42% 289/685 [1:04:37<1:28:48, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:24:52] Energy consumed for RAM : 0.014658 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:24:52] Energy consumed for all GPUs : 0.088945 kWh. Total GPU Power : 62.126000000000005 W\n",
            "[codecarbon INFO @ 14:24:52] Energy consumed for all CPUs : 0.065332 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:24:52] 0.168935 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42% 290/685 [1:04:50<1:28:35, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:25:07] Energy consumed for RAM : 0.014698 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:25:07] Energy consumed for all GPUs : 0.089231 kWh. Total GPU Power : 68.849 W\n",
            "[codecarbon INFO @ 14:25:07] Energy consumed for all CPUs : 0.065509 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:25:07] 0.169438 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 42% 291/685 [1:05:04<1:28:21, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:25:22] Energy consumed for RAM : 0.014737 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:25:22] Energy consumed for all GPUs : 0.089544 kWh. Total GPU Power : 75.104 W\n",
            "[codecarbon INFO @ 14:25:22] Energy consumed for all CPUs : 0.065686 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:25:22] 0.169967 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 43% 293/685 [1:05:30<1:27:52, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:25:37] Energy consumed for RAM : 0.014777 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:25:37] Energy consumed for all GPUs : 0.089868 kWh. Total GPU Power : 77.88400000000001 W\n",
            "[codecarbon INFO @ 14:25:37] Energy consumed for all CPUs : 0.065863 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:25:37] 0.170508 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 43% 294/685 [1:05:44<1:27:39, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:25:52] Energy consumed for RAM : 0.014817 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:25:52] Energy consumed for all GPUs : 0.090150 kWh. Total GPU Power : 67.71900000000001 W\n",
            "[codecarbon INFO @ 14:25:52] Energy consumed for all CPUs : 0.066040 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:25:52] 0.171007 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 43% 295/685 [1:05:57<1:27:27, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:26:07] Energy consumed for RAM : 0.014857 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:26:07] Energy consumed for all GPUs : 0.090448 kWh. Total GPU Power : 71.583 W\n",
            "[codecarbon INFO @ 14:26:07] Energy consumed for all CPUs : 0.066217 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:26:07] 0.171522 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 43% 296/685 [1:06:11<1:27:11, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:26:22] Energy consumed for RAM : 0.014896 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:26:22] Energy consumed for all GPUs : 0.090716 kWh. Total GPU Power : 64.377 W\n",
            "[codecarbon INFO @ 14:26:22] Energy consumed for all CPUs : 0.066394 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:26:22] 0.172006 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 43% 297/685 [1:06:24<1:26:57, 13.45s/it]\r                                         \r{'loss': 1.1426, 'learning_rate': 0.0001262987012987013, 'epoch': 2.17}\n",
            "\r 43% 297/685 [1:06:24<1:26:57, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:26:37] Energy consumed for RAM : 0.014936 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:26:37] Energy consumed for all GPUs : 0.091017 kWh. Total GPU Power : 72.267 W\n",
            "[codecarbon INFO @ 14:26:37] Energy consumed for all CPUs : 0.066571 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:26:37] 0.172524 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 44% 298/685 [1:06:38<1:26:44, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:26:52] Energy consumed for RAM : 0.014976 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:26:52] Energy consumed for all GPUs : 0.091321 kWh. Total GPU Power : 73.003 W\n",
            "[codecarbon INFO @ 14:26:52] Energy consumed for all CPUs : 0.066749 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:26:52] 0.173045 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 44% 299/685 [1:06:51<1:26:31, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:27:07] Energy consumed for RAM : 0.015015 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:27:07] Energy consumed for all GPUs : 0.091572 kWh. Total GPU Power : 60.402 W\n",
            "[codecarbon INFO @ 14:27:07] Energy consumed for all CPUs : 0.066926 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:27:07] 0.173513 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 44% 300/685 [1:07:05<1:26:19, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:27:22] Energy consumed for RAM : 0.015055 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:27:22] Energy consumed for all GPUs : 0.091837 kWh. Total GPU Power : 63.495999999999995 W\n",
            "[codecarbon INFO @ 14:27:22] Energy consumed for all CPUs : 0.067103 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:27:22] 0.173994 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 44% 301/685 [1:07:18<1:26:04, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:27:37] Energy consumed for RAM : 0.015095 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:27:37] Energy consumed for all GPUs : 0.092129 kWh. Total GPU Power : 70.31400000000002 W\n",
            "[codecarbon INFO @ 14:27:37] Energy consumed for all CPUs : 0.067280 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:27:37] 0.174504 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 44% 303/685 [1:07:45<1:25:37, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:27:52] Energy consumed for RAM : 0.015135 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:27:52] Energy consumed for all GPUs : 0.092425 kWh. Total GPU Power : 71.095 W\n",
            "[codecarbon INFO @ 14:27:52] Energy consumed for all CPUs : 0.067457 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:27:52] 0.175016 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 44% 304/685 [1:07:58<1:25:24, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:28:07] Energy consumed for RAM : 0.015174 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:28:07] Energy consumed for all GPUs : 0.092758 kWh. Total GPU Power : 80.07600000000001 W\n",
            "[codecarbon INFO @ 14:28:07] Energy consumed for all CPUs : 0.067634 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:28:07] 0.175566 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45% 305/685 [1:08:12<1:25:12, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:28:22] Energy consumed for RAM : 0.015214 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:28:22] Energy consumed for all GPUs : 0.093053 kWh. Total GPU Power : 70.9 W\n",
            "[codecarbon INFO @ 14:28:22] Energy consumed for all CPUs : 0.067811 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:28:22] 0.176078 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45% 306/685 [1:08:25<1:24:57, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:28:37] Energy consumed for RAM : 0.015254 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:28:37] Energy consumed for all GPUs : 0.093350 kWh. Total GPU Power : 71.149 W\n",
            "[codecarbon INFO @ 14:28:37] Energy consumed for all CPUs : 0.067988 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:28:37] 0.176591 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45% 307/685 [1:08:39<1:24:45, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:28:52] Energy consumed for RAM : 0.015293 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:28:52] Energy consumed for all GPUs : 0.093644 kWh. Total GPU Power : 70.705 W\n",
            "[codecarbon INFO @ 14:28:52] Energy consumed for all CPUs : 0.068165 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:28:52] 0.177102 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45% 308/685 [1:08:52<1:24:33, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:29:07] Energy consumed for RAM : 0.015333 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:29:07] Energy consumed for all GPUs : 0.093972 kWh. Total GPU Power : 78.71300000000001 W\n",
            "[codecarbon INFO @ 14:29:07] Energy consumed for all CPUs : 0.068342 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:29:07] 0.177647 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45% 309/685 [1:09:06<1:24:20, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:29:22] Energy consumed for RAM : 0.015373 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:29:22] Energy consumed for all GPUs : 0.094279 kWh. Total GPU Power : 73.882 W\n",
            "[codecarbon INFO @ 14:29:22] Energy consumed for all CPUs : 0.068519 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:29:22] 0.178171 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45% 310/685 [1:09:19<1:24:07, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:29:37] Energy consumed for RAM : 0.015413 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:29:37] Energy consumed for all GPUs : 0.094575 kWh. Total GPU Power : 70.998 W\n",
            "[codecarbon INFO @ 14:29:37] Energy consumed for all CPUs : 0.068696 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:29:37] 0.178683 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 45% 311/685 [1:09:33<1:23:52, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:29:52] Energy consumed for RAM : 0.015452 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:29:52] Energy consumed for all GPUs : 0.094872 kWh. Total GPU Power : 71.388 W\n",
            "[codecarbon INFO @ 14:29:52] Energy consumed for all CPUs : 0.068873 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:29:52] 0.179197 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 46% 313/685 [1:09:59<1:23:23, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:30:07] Energy consumed for RAM : 0.015492 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:30:07] Energy consumed for all GPUs : 0.095161 kWh. Total GPU Power : 69.38 W\n",
            "[codecarbon INFO @ 14:30:07] Energy consumed for all CPUs : 0.069050 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:30:07] 0.179703 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 46% 314/685 [1:10:13<1:23:10, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:30:22] Energy consumed for RAM : 0.015532 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:30:22] Energy consumed for all GPUs : 0.095458 kWh. Total GPU Power : 71.486 W\n",
            "[codecarbon INFO @ 14:30:22] Energy consumed for all CPUs : 0.069227 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:30:22] 0.180217 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 46% 315/685 [1:10:26<1:22:59, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:30:37] Energy consumed for RAM : 0.015571 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:30:37] Energy consumed for all GPUs : 0.095763 kWh. Total GPU Power : 73.19800000000001 W\n",
            "[codecarbon INFO @ 14:30:37] Energy consumed for all CPUs : 0.069404 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:30:37] 0.180738 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 46% 316/685 [1:10:40<1:22:46, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:30:52] Energy consumed for RAM : 0.015611 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:30:52] Energy consumed for all GPUs : 0.096043 kWh. Total GPU Power : 67.23000000000002 W\n",
            "[codecarbon INFO @ 14:30:52] Energy consumed for all CPUs : 0.069581 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:30:52] 0.181235 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 46% 317/685 [1:10:53<1:22:30, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:31:07] Energy consumed for RAM : 0.015651 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:31:07] Energy consumed for all GPUs : 0.096309 kWh. Total GPU Power : 63.986000000000004 W\n",
            "[codecarbon INFO @ 14:31:07] Energy consumed for all CPUs : 0.069758 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:31:07] 0.181718 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 46% 318/685 [1:11:07<1:22:16, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:31:22] Energy consumed for RAM : 0.015691 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:31:22] Energy consumed for all GPUs : 0.096597 kWh. Total GPU Power : 69.24 W\n",
            "[codecarbon INFO @ 14:31:22] Energy consumed for all CPUs : 0.069935 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:31:22] 0.182223 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 47% 319/685 [1:11:20<1:22:02, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:31:37] Energy consumed for RAM : 0.015730 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:31:37] Energy consumed for all GPUs : 0.096879 kWh. Total GPU Power : 67.816 W\n",
            "[codecarbon INFO @ 14:31:37] Energy consumed for all CPUs : 0.070113 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:31:37] 0.182722 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 47% 320/685 [1:11:34<1:21:49, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:31:52] Energy consumed for RAM : 0.015770 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:31:52] Energy consumed for all GPUs : 0.097161 kWh. Total GPU Power : 67.621 W\n",
            "[codecarbon INFO @ 14:31:52] Energy consumed for all CPUs : 0.070290 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:31:52] 0.183220 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 47% 322/685 [1:12:01<1:21:21, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:32:07] Energy consumed for RAM : 0.015810 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:32:07] Energy consumed for all GPUs : 0.097432 kWh. Total GPU Power : 65.12 W\n",
            "[codecarbon INFO @ 14:32:07] Energy consumed for all CPUs : 0.070467 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:32:07] 0.183708 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 47% 323/685 [1:12:14<1:21:07, 13.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:32:22] Energy consumed for RAM : 0.015849 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:32:22] Energy consumed for all GPUs : 0.097736 kWh. Total GPU Power : 73.101 W\n",
            "[codecarbon INFO @ 14:32:22] Energy consumed for all CPUs : 0.070644 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:32:22] 0.184229 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 47% 324/685 [1:12:27<1:20:54, 13.45s/it]\r                                         \r{'loss': 1.1104, 'learning_rate': 0.00011753246753246753, 'epoch': 2.36}\n",
            "\r 47% 324/685 [1:12:27<1:20:54, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:32:37] Energy consumed for RAM : 0.015889 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:32:37] Energy consumed for all GPUs : 0.098069 kWh. Total GPU Power : 79.88100000000001 W\n",
            "[codecarbon INFO @ 14:32:37] Energy consumed for all CPUs : 0.070821 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:32:37] 0.184778 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 47% 325/685 [1:12:41<1:20:42, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:32:52] Energy consumed for RAM : 0.015929 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:32:52] Energy consumed for all GPUs : 0.098370 kWh. Total GPU Power : 72.32000000000001 W\n",
            "[codecarbon INFO @ 14:32:52] Energy consumed for all CPUs : 0.070998 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:32:52] 0.185296 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 48% 326/685 [1:12:54<1:20:28, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:33:07] Energy consumed for RAM : 0.015969 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:33:07] Energy consumed for all GPUs : 0.098651 kWh. Total GPU Power : 67.621 W\n",
            "[codecarbon INFO @ 14:33:07] Energy consumed for all CPUs : 0.071175 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:33:07] 0.185794 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 48% 327/685 [1:13:08<1:20:13, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:33:22] Energy consumed for RAM : 0.016008 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:33:22] Energy consumed for all GPUs : 0.098917 kWh. Total GPU Power : 63.849000000000004 W\n",
            "[codecarbon INFO @ 14:33:22] Energy consumed for all CPUs : 0.071352 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:33:22] 0.186277 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 48% 328/685 [1:13:21<1:20:00, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:33:37] Energy consumed for RAM : 0.016048 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:33:37] Energy consumed for all GPUs : 0.099205 kWh. Total GPU Power : 69.337 W\n",
            "[codecarbon INFO @ 14:33:37] Energy consumed for all CPUs : 0.071529 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:33:37] 0.186782 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 48% 329/685 [1:13:35<1:19:47, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:33:52] Energy consumed for RAM : 0.016088 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:33:52] Energy consumed for all GPUs : 0.099485 kWh. Total GPU Power : 67.328 W\n",
            "[codecarbon INFO @ 14:33:52] Energy consumed for all CPUs : 0.071706 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:33:52] 0.187279 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 48% 330/685 [1:13:48<1:19:35, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:34:07] Energy consumed for RAM : 0.016128 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:34:07] Energy consumed for all GPUs : 0.099787 kWh. Total GPU Power : 72.515 W\n",
            "[codecarbon INFO @ 14:34:07] Energy consumed for all CPUs : 0.071883 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:34:07] 0.187798 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 48% 332/685 [1:14:15<1:19:10, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:34:22] Energy consumed for RAM : 0.016167 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:34:22] Energy consumed for all GPUs : 0.100106 kWh. Total GPU Power : 76.46900000000001 W\n",
            "[codecarbon INFO @ 14:34:22] Energy consumed for all CPUs : 0.072060 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:34:22] 0.188333 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 49% 333/685 [1:14:29<1:18:55, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:34:37] Energy consumed for RAM : 0.016207 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:34:37] Energy consumed for all GPUs : 0.100396 kWh. Total GPU Power : 69.923 W\n",
            "[codecarbon INFO @ 14:34:37] Energy consumed for all CPUs : 0.072237 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:34:37] 0.188840 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 49% 334/685 [1:14:42<1:18:43, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:34:52] Energy consumed for RAM : 0.016247 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:34:52] Energy consumed for all GPUs : 0.100691 kWh. Total GPU Power : 70.9 W\n",
            "[codecarbon INFO @ 14:34:52] Energy consumed for all CPUs : 0.072414 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:34:52] 0.189352 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 49% 335/685 [1:14:55<1:18:30, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:35:07] Energy consumed for RAM : 0.016286 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:35:07] Energy consumed for all GPUs : 0.100957 kWh. Total GPU Power : 63.888 W\n",
            "[codecarbon INFO @ 14:35:07] Energy consumed for all CPUs : 0.072591 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:35:07] 0.189835 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 49% 336/685 [1:15:09<1:18:15, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:35:22] Energy consumed for RAM : 0.016326 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:35:22] Energy consumed for all GPUs : 0.101257 kWh. Total GPU Power : 71.876 W\n",
            "[codecarbon INFO @ 14:35:22] Energy consumed for all CPUs : 0.072768 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:35:22] 0.190351 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 49% 337/685 [1:15:22<1:18:02, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:35:37] Energy consumed for RAM : 0.016366 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:35:37] Energy consumed for all GPUs : 0.101556 kWh. Total GPU Power : 71.876 W\n",
            "[codecarbon INFO @ 14:35:37] Energy consumed for all CPUs : 0.072945 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:35:37] 0.190867 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 49% 338/685 [1:15:36<1:17:48, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:35:52] Energy consumed for RAM : 0.016405 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:35:52] Energy consumed for all GPUs : 0.101866 kWh. Total GPU Power : 74.519 W\n",
            "[codecarbon INFO @ 14:35:52] Energy consumed for all CPUs : 0.073122 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:35:52] 0.191394 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 49% 339/685 [1:15:49<1:17:34, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:36:07] Energy consumed for RAM : 0.016445 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:36:07] Energy consumed for all GPUs : 0.102172 kWh. Total GPU Power : 73.589 W\n",
            "[codecarbon INFO @ 14:36:07] Energy consumed for all CPUs : 0.073299 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:36:07] 0.191917 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50% 340/685 [1:16:03<1:17:21, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:36:22] Energy consumed for RAM : 0.016485 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:36:22] Energy consumed for all GPUs : 0.102346 kWh. Total GPU Power : 41.749 W\n",
            "[codecarbon INFO @ 14:36:22] Energy consumed for all CPUs : 0.073476 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:36:22] 0.192307 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 50% 342/685 [1:16:30<1:16:55, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:36:37] Energy consumed for RAM : 0.016525 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:36:37] Energy consumed for all GPUs : 0.102638 kWh. Total GPU Power : 70.119 W\n",
            "[codecarbon INFO @ 14:36:37] Energy consumed for all CPUs : 0.073653 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:36:37] 0.192816 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50% 343/685 [1:16:43<1:16:40, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:36:52] Energy consumed for RAM : 0.016564 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:36:52] Energy consumed for all GPUs : 0.102929 kWh. Total GPU Power : 69.923 W\n",
            "[codecarbon INFO @ 14:36:52] Energy consumed for all CPUs : 0.073831 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:36:52] 0.193324 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50% 344/685 [1:16:56<1:16:26, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:37:07] Energy consumed for RAM : 0.016604 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:37:07] Energy consumed for all GPUs : 0.103186 kWh. Total GPU Power : 61.833 W\n",
            "[codecarbon INFO @ 14:37:07] Energy consumed for all CPUs : 0.074008 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:37:07] 0.193798 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 50% 345/685 [1:17:10<1:16:14, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:37:22] Energy consumed for RAM : 0.016644 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:37:22] Energy consumed for all GPUs : 0.103498 kWh. Total GPU Power : 74.909 W\n",
            "[codecarbon INFO @ 14:37:22] Energy consumed for all CPUs : 0.074185 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:37:22] 0.194326 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 51% 346/685 [1:17:23<1:16:00, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:37:37] Energy consumed for RAM : 0.016684 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:37:37] Energy consumed for all GPUs : 0.103785 kWh. Total GPU Power : 68.891 W\n",
            "[codecarbon INFO @ 14:37:37] Energy consumed for all CPUs : 0.074362 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:37:37] 0.194830 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 51% 347/685 [1:17:37<1:15:47, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:37:52] Energy consumed for RAM : 0.016723 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:37:52] Energy consumed for all GPUs : 0.104063 kWh. Total GPU Power : 66.88 W\n",
            "[codecarbon INFO @ 14:37:52] Energy consumed for all CPUs : 0.074539 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:37:52] 0.195325 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 51% 348/685 [1:17:50<1:15:33, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:38:07] Energy consumed for RAM : 0.016763 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:38:07] Energy consumed for all GPUs : 0.104315 kWh. Total GPU Power : 60.5 W\n",
            "[codecarbon INFO @ 14:38:07] Energy consumed for all CPUs : 0.074716 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:38:07] 0.195794 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 51% 349/685 [1:18:04<1:15:19, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:38:22] Energy consumed for RAM : 0.016803 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:38:22] Energy consumed for all GPUs : 0.104604 kWh. Total GPU Power : 69.282 W\n",
            "[codecarbon INFO @ 14:38:22] Energy consumed for all CPUs : 0.074893 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:38:22] 0.196299 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.148, 'learning_rate': 0.00010876623376623376, 'epoch': 2.56}\n",
            " 51% 351/685 [1:18:31<1:14:52, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:38:37] Energy consumed for RAM : 0.016842 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:38:37] Energy consumed for all GPUs : 0.104877 kWh. Total GPU Power : 65.805 W\n",
            "[codecarbon INFO @ 14:38:37] Energy consumed for all CPUs : 0.075070 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:38:37] 0.196790 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 51% 352/685 [1:18:44<1:14:38, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:38:52] Energy consumed for RAM : 0.016882 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:38:52] Energy consumed for all GPUs : 0.105154 kWh. Total GPU Power : 66.391 W\n",
            "[codecarbon INFO @ 14:38:52] Energy consumed for all CPUs : 0.075247 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:38:52] 0.197283 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 52% 353/685 [1:18:58<1:14:24, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:39:07] Energy consumed for RAM : 0.016922 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:39:07] Energy consumed for all GPUs : 0.105433 kWh. Total GPU Power : 67.035 W\n",
            "[codecarbon INFO @ 14:39:07] Energy consumed for all CPUs : 0.075424 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:39:07] 0.197779 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 52% 354/685 [1:19:11<1:14:11, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:39:22] Energy consumed for RAM : 0.016962 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:39:22] Energy consumed for all GPUs : 0.105714 kWh. Total GPU Power : 67.523 W\n",
            "[codecarbon INFO @ 14:39:22] Energy consumed for all CPUs : 0.075601 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:39:22] 0.198276 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 52% 355/685 [1:19:24<1:14:01, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:39:37] Energy consumed for RAM : 0.017001 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:39:37] Energy consumed for all GPUs : 0.106040 kWh. Total GPU Power : 78.46900000000001 W\n",
            "[codecarbon INFO @ 14:39:37] Energy consumed for all CPUs : 0.075778 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:39:37] 0.198820 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 52% 356/685 [1:19:38<1:13:47, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:39:52] Energy consumed for RAM : 0.017041 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:39:52] Energy consumed for all GPUs : 0.106354 kWh. Total GPU Power : 75.443 W\n",
            "[codecarbon INFO @ 14:39:52] Energy consumed for all CPUs : 0.075955 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:39:52] 0.199351 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 52% 357/685 [1:19:51<1:13:32, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:40:07] Energy consumed for RAM : 0.017081 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:40:07] Energy consumed for all GPUs : 0.106613 kWh. Total GPU Power : 62.02900000000001 W\n",
            "[codecarbon INFO @ 14:40:07] Energy consumed for all CPUs : 0.076132 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:40:07] 0.199825 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 52% 358/685 [1:20:05<1:13:18, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:40:22] Energy consumed for RAM : 0.017120 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:40:22] Energy consumed for all GPUs : 0.106918 kWh. Total GPU Power : 73.29600000000002 W\n",
            "[codecarbon INFO @ 14:40:22] Energy consumed for all CPUs : 0.076309 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:40:22] 0.200347 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 52% 359/685 [1:20:18<1:13:05, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:40:37] Energy consumed for RAM : 0.017160 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:40:37] Energy consumed for all GPUs : 0.107208 kWh. Total GPU Power : 69.82600000000001 W\n",
            "[codecarbon INFO @ 14:40:37] Energy consumed for all CPUs : 0.076486 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:40:37] 0.200855 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 53% 361/685 [1:20:45<1:12:38, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:40:52] Energy consumed for RAM : 0.017200 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:40:52] Energy consumed for all GPUs : 0.107492 kWh. Total GPU Power : 68.305 W\n",
            "[codecarbon INFO @ 14:40:52] Energy consumed for all CPUs : 0.076663 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:40:52] 0.201356 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 53% 362/685 [1:20:59<1:12:26, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:41:07] Energy consumed for RAM : 0.017240 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:41:07] Energy consumed for all GPUs : 0.107786 kWh. Total GPU Power : 70.607 W\n",
            "[codecarbon INFO @ 14:41:07] Energy consumed for all CPUs : 0.076840 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:41:07] 0.201866 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 53% 363/685 [1:21:12<1:12:13, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:41:22] Energy consumed for RAM : 0.017279 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:41:22] Energy consumed for all GPUs : 0.108069 kWh. Total GPU Power : 67.816 W\n",
            "[codecarbon INFO @ 14:41:22] Energy consumed for all CPUs : 0.077017 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:41:22] 0.202365 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 53% 364/685 [1:21:26<1:11:58, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:41:37] Energy consumed for RAM : 0.017319 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:41:37] Energy consumed for all GPUs : 0.108339 kWh. Total GPU Power : 64.924 W\n",
            "[codecarbon INFO @ 14:41:37] Energy consumed for all CPUs : 0.077194 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:41:37] 0.202852 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 53% 365/685 [1:21:39<1:11:46, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:41:52] Energy consumed for RAM : 0.017359 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:41:52] Energy consumed for all GPUs : 0.108621 kWh. Total GPU Power : 67.816 W\n",
            "[codecarbon INFO @ 14:41:52] Energy consumed for all CPUs : 0.077371 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:41:52] 0.203351 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 53% 366/685 [1:21:52<1:11:31, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:42:07] Energy consumed for RAM : 0.017398 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:42:07] Energy consumed for all GPUs : 0.108922 kWh. Total GPU Power : 72.462 W\n",
            "[codecarbon INFO @ 14:42:07] Energy consumed for all CPUs : 0.077548 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:42:07] 0.203869 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 54% 367/685 [1:22:06<1:11:17, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:42:22] Energy consumed for RAM : 0.017438 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:42:22] Energy consumed for all GPUs : 0.109212 kWh. Total GPU Power : 69.673 W\n",
            "[codecarbon INFO @ 14:42:22] Energy consumed for all CPUs : 0.077725 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:42:22] 0.204376 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 54% 368/685 [1:22:19<1:11:03, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:42:37] Energy consumed for RAM : 0.017478 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:42:37] Energy consumed for all GPUs : 0.109483 kWh. Total GPU Power : 65.12 W\n",
            "[codecarbon INFO @ 14:42:37] Energy consumed for all CPUs : 0.077902 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:42:37] 0.204864 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 54% 369/685 [1:22:33<1:10:49, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:42:52] Energy consumed for RAM : 0.017518 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:42:52] Energy consumed for all GPUs : 0.109773 kWh. Total GPU Power : 69.43500000000002 W\n",
            "[codecarbon INFO @ 14:42:52] Energy consumed for all CPUs : 0.078080 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:42:52] 0.205370 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 54% 371/685 [1:23:00<1:10:23, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:43:07] Energy consumed for RAM : 0.017557 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:43:07] Energy consumed for all GPUs : 0.110064 kWh. Total GPU Power : 70.06400000000002 W\n",
            "[codecarbon INFO @ 14:43:07] Energy consumed for all CPUs : 0.078256 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:43:07] 0.205878 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 54% 372/685 [1:23:13<1:10:09, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:43:22] Energy consumed for RAM : 0.017597 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:43:22] Energy consumed for all GPUs : 0.110367 kWh. Total GPU Power : 72.808 W\n",
            "[codecarbon INFO @ 14:43:22] Energy consumed for all CPUs : 0.078434 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:43:22] 0.206398 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 54% 373/685 [1:23:27<1:09:55, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:43:37] Energy consumed for RAM : 0.017637 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:43:37] Energy consumed for all GPUs : 0.110656 kWh. Total GPU Power : 69.337 W\n",
            "[codecarbon INFO @ 14:43:37] Energy consumed for all CPUs : 0.078611 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:43:37] 0.206903 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55% 374/685 [1:23:40<1:09:41, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:43:52] Energy consumed for RAM : 0.017676 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:43:52] Energy consumed for all GPUs : 0.110923 kWh. Total GPU Power : 64.24 W\n",
            "[codecarbon INFO @ 14:43:52] Energy consumed for all CPUs : 0.078788 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:43:52] 0.207387 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55% 375/685 [1:23:54<1:09:30, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:44:07] Energy consumed for RAM : 0.017716 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:44:07] Energy consumed for all GPUs : 0.111203 kWh. Total GPU Power : 67.328 W\n",
            "[codecarbon INFO @ 14:44:07] Energy consumed for all CPUs : 0.078965 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:44:07] 0.207884 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55% 376/685 [1:24:07<1:09:16, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:44:22] Energy consumed for RAM : 0.017756 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:44:22] Energy consumed for all GPUs : 0.111527 kWh. Total GPU Power : 77.737 W\n",
            "[codecarbon INFO @ 14:44:22] Energy consumed for all CPUs : 0.079142 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:44:22] 0.208424 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55% 377/685 [1:24:20<1:09:02, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:44:37] Energy consumed for RAM : 0.017796 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:44:37] Energy consumed for all GPUs : 0.111827 kWh. Total GPU Power : 72.22200000000001 W\n",
            "[codecarbon INFO @ 14:44:37] Energy consumed for all CPUs : 0.079319 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:44:37] 0.208942 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 55% 378/685 [1:24:34<1:08:49, 13.45s/it]\r                                         \r{'loss': 1.1244, 'learning_rate': 0.0001, 'epoch': 2.76}\n",
            "\r 55% 378/685 [1:24:34<1:08:49, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:44:52] Energy consumed for RAM : 0.017835 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:44:52] Energy consumed for all GPUs : 0.112154 kWh. Total GPU Power : 78.56600000000002 W\n",
            "[codecarbon INFO @ 14:44:52] Energy consumed for all CPUs : 0.079496 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:44:52] 0.209486 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 55% 380/685 [1:25:01<1:08:22, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:45:07] Energy consumed for RAM : 0.017875 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:45:07] Energy consumed for all GPUs : 0.112446 kWh. Total GPU Power : 70.119 W\n",
            "[codecarbon INFO @ 14:45:07] Energy consumed for all CPUs : 0.079673 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:45:07] 0.209994 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 56% 381/685 [1:25:14<1:08:09, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:45:22] Energy consumed for RAM : 0.017915 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:45:22] Energy consumed for all GPUs : 0.112743 kWh. Total GPU Power : 71.246 W\n",
            "[codecarbon INFO @ 14:45:22] Energy consumed for all CPUs : 0.079850 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:45:22] 0.210508 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 56% 382/685 [1:25:28<1:07:55, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:45:37] Energy consumed for RAM : 0.017955 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:45:37] Energy consumed for all GPUs : 0.113018 kWh. Total GPU Power : 66.057 W\n",
            "[codecarbon INFO @ 14:45:37] Energy consumed for all CPUs : 0.080027 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:45:37] 0.210999 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 56% 383/685 [1:25:41<1:07:41, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:45:52] Energy consumed for RAM : 0.017994 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:45:52] Energy consumed for all GPUs : 0.113345 kWh. Total GPU Power : 78.664 W\n",
            "[codecarbon INFO @ 14:45:52] Energy consumed for all CPUs : 0.080204 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:45:52] 0.211544 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 56% 384/685 [1:25:55<1:07:28, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:46:07] Energy consumed for RAM : 0.018034 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:46:07] Energy consumed for all GPUs : 0.113635 kWh. Total GPU Power : 69.575 W\n",
            "[codecarbon INFO @ 14:46:07] Energy consumed for all CPUs : 0.080381 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:46:07] 0.212050 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 56% 385/685 [1:26:08<1:07:14, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:46:22] Energy consumed for RAM : 0.018074 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:46:22] Energy consumed for all GPUs : 0.113926 kWh. Total GPU Power : 69.923 W\n",
            "[codecarbon INFO @ 14:46:22] Energy consumed for all CPUs : 0.080558 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:46:22] 0.212558 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 56% 386/685 [1:26:21<1:07:01, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:46:37] Energy consumed for RAM : 0.018113 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:46:37] Energy consumed for all GPUs : 0.114212 kWh. Total GPU Power : 68.696 W\n",
            "[codecarbon INFO @ 14:46:37] Energy consumed for all CPUs : 0.080735 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:46:37] 0.213060 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 56% 387/685 [1:26:35<1:06:47, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:46:52] Energy consumed for RAM : 0.018153 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:46:52] Energy consumed for all GPUs : 0.114513 kWh. Total GPU Power : 72.32000000000001 W\n",
            "[codecarbon INFO @ 14:46:52] Energy consumed for all CPUs : 0.080912 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:46:52] 0.213578 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 57% 388/685 [1:26:48<1:06:33, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:47:07] Energy consumed for RAM : 0.018193 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:47:07] Energy consumed for all GPUs : 0.114804 kWh. Total GPU Power : 69.923 W\n",
            "[codecarbon INFO @ 14:47:07] Energy consumed for all CPUs : 0.081089 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:47:07] 0.214086 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 57% 390/685 [1:27:15<1:06:09, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:47:22] Energy consumed for RAM : 0.018233 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:47:22] Energy consumed for all GPUs : 0.115086 kWh. Total GPU Power : 67.816 W\n",
            "[codecarbon INFO @ 14:47:22] Energy consumed for all CPUs : 0.081266 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:47:22] 0.214585 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 57% 391/685 [1:27:29<1:05:53, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:47:37] Energy consumed for RAM : 0.018272 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:47:37] Energy consumed for all GPUs : 0.115384 kWh. Total GPU Power : 71.583 W\n",
            "[codecarbon INFO @ 14:47:37] Energy consumed for all CPUs : 0.081443 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:47:37] 0.215100 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 57% 392/685 [1:27:42<1:05:40, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:47:52] Energy consumed for RAM : 0.018312 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:47:52] Energy consumed for all GPUs : 0.115667 kWh. Total GPU Power : 67.914 W\n",
            "[codecarbon INFO @ 14:47:52] Energy consumed for all CPUs : 0.081620 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:47:52] 0.215599 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 57% 393/685 [1:27:56<1:05:26, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:48:07] Energy consumed for RAM : 0.018352 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:48:07] Energy consumed for all GPUs : 0.115980 kWh. Total GPU Power : 75.15 W\n",
            "[codecarbon INFO @ 14:48:07] Energy consumed for all CPUs : 0.081797 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:48:07] 0.216129 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58% 394/685 [1:28:09<1:05:12, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:48:22] Energy consumed for RAM : 0.018391 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:48:22] Energy consumed for all GPUs : 0.116270 kWh. Total GPU Power : 69.63 W\n",
            "[codecarbon INFO @ 14:48:22] Energy consumed for all CPUs : 0.081974 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:48:22] 0.216636 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58% 395/685 [1:28:22<1:05:00, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:48:37] Energy consumed for RAM : 0.018431 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:48:37] Energy consumed for all GPUs : 0.116561 kWh. Total GPU Power : 69.923 W\n",
            "[codecarbon INFO @ 14:48:37] Energy consumed for all CPUs : 0.082151 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:48:37] 0.217144 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58% 396/685 [1:28:36<1:04:47, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:48:52] Energy consumed for RAM : 0.018471 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:48:52] Energy consumed for all GPUs : 0.116846 kWh. Total GPU Power : 68.403 W\n",
            "[codecarbon INFO @ 14:48:52] Energy consumed for all CPUs : 0.082329 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:48:52] 0.217645 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58% 397/685 [1:28:49<1:04:33, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:49:07] Energy consumed for RAM : 0.018511 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:49:07] Energy consumed for all GPUs : 0.117151 kWh. Total GPU Power : 73.348 W\n",
            "[codecarbon INFO @ 14:49:07] Energy consumed for all CPUs : 0.082506 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:49:07] 0.218167 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 58% 398/685 [1:29:03<1:04:18, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:49:22] Energy consumed for RAM : 0.018550 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:49:22] Energy consumed for all GPUs : 0.117440 kWh. Total GPU Power : 69.43500000000002 W\n",
            "[codecarbon INFO @ 14:49:22] Energy consumed for all CPUs : 0.082683 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:49:22] 0.218672 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 58% 400/685 [1:29:30<1:03:53, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:49:37] Energy consumed for RAM : 0.018590 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:49:37] Energy consumed for all GPUs : 0.117756 kWh. Total GPU Power : 76.07900000000001 W\n",
            "[codecarbon INFO @ 14:49:37] Energy consumed for all CPUs : 0.082860 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:49:37] 0.219206 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 59% 401/685 [1:29:43<1:03:39, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:49:52] Energy consumed for RAM : 0.018630 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:49:52] Energy consumed for all GPUs : 0.118014 kWh. Total GPU Power : 61.931000000000004 W\n",
            "[codecarbon INFO @ 14:49:52] Energy consumed for all CPUs : 0.083037 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:49:52] 0.219680 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 59% 402/685 [1:29:57<1:03:27, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:50:07] Energy consumed for RAM : 0.018669 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:50:07] Energy consumed for all GPUs : 0.118318 kWh. Total GPU Power : 73.101 W\n",
            "[codecarbon INFO @ 14:50:07] Energy consumed for all CPUs : 0.083214 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:50:07] 0.220201 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 59% 403/685 [1:30:10<1:03:12, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:50:22] Energy consumed for RAM : 0.018709 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:50:22] Energy consumed for all GPUs : 0.118576 kWh. Total GPU Power : 61.931000000000004 W\n",
            "[codecarbon INFO @ 14:50:22] Energy consumed for all CPUs : 0.083391 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:50:22] 0.220676 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 59% 404/685 [1:30:24<1:02:58, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:50:37] Energy consumed for RAM : 0.018749 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:50:37] Energy consumed for all GPUs : 0.118881 kWh. Total GPU Power : 73.29600000000002 W\n",
            "[codecarbon INFO @ 14:50:37] Energy consumed for all CPUs : 0.083568 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:50:37] 0.221197 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 59% 405/685 [1:30:37<1:02:46, 13.45s/it]\r                                         \r{'loss': 1.0997, 'learning_rate': 9.123376623376624e-05, 'epoch': 2.96}\n",
            "\r 59% 405/685 [1:30:37<1:02:46, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:50:52] Energy consumed for RAM : 0.018789 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:50:52] Energy consumed for all GPUs : 0.119205 kWh. Total GPU Power : 77.83500000000002 W\n",
            "[codecarbon INFO @ 14:50:52] Energy consumed for all CPUs : 0.083745 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:50:52] 0.221738 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 59% 406/685 [1:30:50<1:02:32, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:51:07] Energy consumed for RAM : 0.018828 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:51:07] Energy consumed for all GPUs : 0.119519 kWh. Total GPU Power : 75.59100000000001 W\n",
            "[codecarbon INFO @ 14:51:07] Energy consumed for all CPUs : 0.083922 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:51:07] 0.222269 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 59% 407/685 [1:31:04<1:02:18, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:51:22] Energy consumed for RAM : 0.018868 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:51:22] Energy consumed for all GPUs : 0.119777 kWh. Total GPU Power : 61.991 W\n",
            "[codecarbon INFO @ 14:51:22] Energy consumed for all CPUs : 0.084099 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:51:22] 0.222744 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 60% 409/685 [1:31:31<1:01:52, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:51:37] Energy consumed for RAM : 0.018908 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:51:37] Energy consumed for all GPUs : 0.120036 kWh. Total GPU Power : 62.22400000000001 W\n",
            "[codecarbon INFO @ 14:51:37] Energy consumed for all CPUs : 0.084276 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:51:37] 0.223220 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60% 410/685 [1:31:44<1:01:41, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:51:52] Energy consumed for RAM : 0.018947 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:51:52] Energy consumed for all GPUs : 0.120322 kWh. Total GPU Power : 68.59800000000001 W\n",
            "[codecarbon INFO @ 14:51:52] Energy consumed for all CPUs : 0.084453 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:51:52] 0.223722 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60% 411/685 [1:31:58<1:01:29, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:52:07] Energy consumed for RAM : 0.018987 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:52:07] Energy consumed for all GPUs : 0.120599 kWh. Total GPU Power : 66.741 W\n",
            "[codecarbon INFO @ 14:52:07] Energy consumed for all CPUs : 0.084630 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:52:07] 0.224216 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60% 412/685 [1:32:12<1:01:59, 13.63s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:52:22] Energy consumed for RAM : 0.019027 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:52:22] Energy consumed for all GPUs : 0.120888 kWh. Total GPU Power : 69.337 W\n",
            "[codecarbon INFO @ 14:52:22] Energy consumed for all CPUs : 0.084807 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:52:22] 0.224722 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60% 413/685 [1:32:25<1:01:31, 13.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:52:37] Energy consumed for RAM : 0.019067 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:52:37] Energy consumed for all GPUs : 0.121179 kWh. Total GPU Power : 69.82600000000001 W\n",
            "[codecarbon INFO @ 14:52:37] Energy consumed for all CPUs : 0.084984 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:52:37] 0.225229 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 60% 414/685 [1:32:39<1:01:07, 13.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:52:52] Energy consumed for RAM : 0.019106 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:52:52] Energy consumed for all GPUs : 0.121506 kWh. Total GPU Power : 78.56600000000002 W\n",
            "[codecarbon INFO @ 14:52:52] Energy consumed for all CPUs : 0.085161 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:52:52] 0.225773 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61% 415/685 [1:32:52<1:00:48, 13.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:53:07] Energy consumed for RAM : 0.019146 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:53:07] Energy consumed for all GPUs : 0.121825 kWh. Total GPU Power : 76.66400000000002 W\n",
            "[codecarbon INFO @ 14:53:07] Energy consumed for all CPUs : 0.085338 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:53:07] 0.226309 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61% 416/685 [1:33:06<1:00:29, 13.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:53:22] Energy consumed for RAM : 0.019186 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:53:22] Energy consumed for all GPUs : 0.122075 kWh. Total GPU Power : 60.10800000000001 W\n",
            "[codecarbon INFO @ 14:53:22] Energy consumed for all CPUs : 0.085515 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:53:22] 0.226776 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61% 417/685 [1:33:19<1:00:13, 13.48s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:53:37] Energy consumed for RAM : 0.019225 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:53:37] Energy consumed for all GPUs : 0.122369 kWh. Total GPU Power : 70.705 W\n",
            "[codecarbon INFO @ 14:53:37] Energy consumed for all CPUs : 0.085692 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:53:37] 0.227287 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61% 418/685 [1:33:32<59:57, 13.47s/it]  "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:53:52] Energy consumed for RAM : 0.019265 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:53:52] Energy consumed for all GPUs : 0.122647 kWh. Total GPU Power : 66.839 W\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61% 419/685 [1:33:46<59:42, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:53:52] Energy consumed for all CPUs : 0.085869 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:53:52] 0.227782 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61% 420/685 [1:33:59<59:28, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:54:07] Energy consumed for RAM : 0.019305 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:54:07] Energy consumed for all GPUs : 0.122928 kWh. Total GPU Power : 67.467 W\n",
            "[codecarbon INFO @ 14:54:07] Energy consumed for all CPUs : 0.086046 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:54:07] 0.228279 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 61% 421/685 [1:34:13<59:13, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:54:22] Energy consumed for RAM : 0.019345 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:54:22] Energy consumed for all GPUs : 0.123217 kWh. Total GPU Power : 69.478 W\n",
            "[codecarbon INFO @ 14:54:22] Energy consumed for all CPUs : 0.086223 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:54:22] 0.228785 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 62% 422/685 [1:34:26<58:59, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:54:37] Energy consumed for RAM : 0.019384 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:54:37] Energy consumed for all GPUs : 0.123502 kWh. Total GPU Power : 68.403 W\n",
            "[codecarbon INFO @ 14:54:37] Energy consumed for all CPUs : 0.086400 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:54:37] 0.229286 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 62% 423/685 [1:34:40<58:44, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:54:52] Energy consumed for RAM : 0.019424 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:54:52] Energy consumed for all GPUs : 0.123791 kWh. Total GPU Power : 69.38 W\n",
            "[codecarbon INFO @ 14:54:52] Energy consumed for all CPUs : 0.086577 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:54:52] 0.229792 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 62% 424/685 [1:34:53<58:31, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:55:07] Energy consumed for RAM : 0.019464 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:55:07] Energy consumed for all GPUs : 0.124046 kWh. Total GPU Power : 61.344 W\n",
            "[codecarbon INFO @ 14:55:07] Energy consumed for all CPUs : 0.086754 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:55:07] 0.230264 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 62% 425/685 [1:35:07<58:18, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:55:22] Energy consumed for RAM : 0.019503 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:55:22] Energy consumed for all GPUs : 0.124352 kWh. Total GPU Power : 73.491 W\n",
            "[codecarbon INFO @ 14:55:22] Energy consumed for all CPUs : 0.086931 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:55:22] 0.230787 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 62% 426/685 [1:35:20<58:04, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:55:37] Energy consumed for RAM : 0.019543 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:55:37] Energy consumed for all GPUs : 0.124641 kWh. Total GPU Power : 69.43500000000002 W\n",
            "[codecarbon INFO @ 14:55:37] Energy consumed for all CPUs : 0.087108 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:55:37] 0.231292 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 62% 427/685 [1:35:34<57:49, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:55:52] Energy consumed for RAM : 0.019583 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:55:52] Energy consumed for all GPUs : 0.124951 kWh. Total GPU Power : 74.519 W\n",
            "[codecarbon INFO @ 14:55:52] Energy consumed for all CPUs : 0.087286 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:55:52] 0.231819 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 63% 429/685 [1:36:00<57:22, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:56:07] Energy consumed for RAM : 0.019623 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:56:07] Energy consumed for all GPUs : 0.125237 kWh. Total GPU Power : 68.696 W\n",
            "[codecarbon INFO @ 14:56:07] Energy consumed for all CPUs : 0.087463 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:56:07] 0.232322 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 63% 430/685 [1:36:14<57:10, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:56:22] Energy consumed for RAM : 0.019662 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:56:22] Energy consumed for all GPUs : 0.125537 kWh. Total GPU Power : 72.027 W\n",
            "[codecarbon INFO @ 14:56:22] Energy consumed for all CPUs : 0.087640 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:56:22] 0.232839 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 63% 431/685 [1:36:27<56:56, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:56:37] Energy consumed for RAM : 0.019702 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:56:37] Energy consumed for all GPUs : 0.125820 kWh. Total GPU Power : 68.012 W\n",
            "[codecarbon INFO @ 14:56:37] Energy consumed for all CPUs : 0.087817 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:56:37] 0.233338 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 63% 432/685 [1:36:41<56:42, 13.45s/it]\r                                       \r{'loss': 1.0676, 'learning_rate': 8.246753246753248e-05, 'epoch': 3.15}\n",
            "\r 63% 432/685 [1:36:41<56:42, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:56:52] Energy consumed for RAM : 0.019742 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:56:52] Energy consumed for all GPUs : 0.126125 kWh. Total GPU Power : 73.244 W\n",
            "[codecarbon INFO @ 14:56:52] Energy consumed for all CPUs : 0.087994 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:56:52] 0.233860 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 63% 433/685 [1:36:54<56:28, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:57:07] Energy consumed for RAM : 0.019781 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:57:07] Energy consumed for all GPUs : 0.126434 kWh. Total GPU Power : 74.42100000000002 W\n",
            "[codecarbon INFO @ 14:57:07] Energy consumed for all CPUs : 0.088171 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:57:07] 0.234386 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 63% 434/685 [1:37:08<56:14, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:57:22] Energy consumed for RAM : 0.019821 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:57:22] Energy consumed for all GPUs : 0.126736 kWh. Total GPU Power : 72.418 W\n",
            "[codecarbon INFO @ 14:57:22] Energy consumed for all CPUs : 0.088348 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:57:22] 0.234905 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 64% 435/685 [1:37:21<56:03, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:57:37] Energy consumed for RAM : 0.019861 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:57:37] Energy consumed for all GPUs : 0.126999 kWh. Total GPU Power : 63.30100000000001 W\n",
            "[codecarbon INFO @ 14:57:37] Energy consumed for all CPUs : 0.088525 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:57:37] 0.235385 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 64% 436/685 [1:37:35<55:50, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:57:52] Energy consumed for RAM : 0.019901 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:57:52] Energy consumed for all GPUs : 0.127285 kWh. Total GPU Power : 68.59800000000001 W\n",
            "[codecarbon INFO @ 14:57:52] Energy consumed for all CPUs : 0.088702 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:57:52] 0.235887 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 64% 437/685 [1:37:48<55:37, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:58:07] Energy consumed for RAM : 0.019940 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:58:07] Energy consumed for all GPUs : 0.127542 kWh. Total GPU Power : 61.833 W\n",
            "[codecarbon INFO @ 14:58:07] Energy consumed for all CPUs : 0.088879 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:58:07] 0.236361 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 64% 439/685 [1:38:15<55:11, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:58:22] Energy consumed for RAM : 0.019980 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:58:22] Energy consumed for all GPUs : 0.127830 kWh. Total GPU Power : 69.18500000000002 W\n",
            "[codecarbon INFO @ 14:58:22] Energy consumed for all CPUs : 0.089056 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:58:22] 0.236866 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 64% 440/685 [1:38:28<54:57, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:58:37] Energy consumed for RAM : 0.020020 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:58:37] Energy consumed for all GPUs : 0.128110 kWh. Total GPU Power : 67.369 W\n",
            "[codecarbon INFO @ 14:58:37] Energy consumed for all CPUs : 0.089233 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:58:37] 0.237363 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 64% 441/685 [1:38:42<54:43, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:58:52] Energy consumed for RAM : 0.020059 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:58:52] Energy consumed for all GPUs : 0.128432 kWh. Total GPU Power : 77.34700000000001 W\n",
            "[codecarbon INFO @ 14:58:52] Energy consumed for all CPUs : 0.089410 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:58:52] 0.237901 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65% 442/685 [1:38:55<54:29, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:59:07] Energy consumed for RAM : 0.020099 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:59:07] Energy consumed for all GPUs : 0.128747 kWh. Total GPU Power : 75.68900000000001 W\n",
            "[codecarbon INFO @ 14:59:07] Energy consumed for all CPUs : 0.089587 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:59:07] 0.238433 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65% 443/685 [1:39:09<54:16, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:59:22] Energy consumed for RAM : 0.020139 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:59:22] Energy consumed for all GPUs : 0.129038 kWh. Total GPU Power : 69.869 W\n",
            "[codecarbon INFO @ 14:59:22] Energy consumed for all CPUs : 0.089764 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:59:22] 0.238941 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65% 444/685 [1:39:22<54:01, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:59:37] Energy consumed for RAM : 0.020179 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:59:37] Energy consumed for all GPUs : 0.129358 kWh. Total GPU Power : 76.95700000000001 W\n",
            "[codecarbon INFO @ 14:59:37] Energy consumed for all CPUs : 0.089941 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:59:37] 0.239478 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65% 445/685 [1:39:36<53:50, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 14:59:52] Energy consumed for RAM : 0.020218 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 14:59:52] Energy consumed for all GPUs : 0.129643 kWh. Total GPU Power : 68.403 W\n",
            "[codecarbon INFO @ 14:59:52] Energy consumed for all CPUs : 0.090118 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 14:59:52] 0.239979 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65% 446/685 [1:39:49<53:38, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:00:07] Energy consumed for RAM : 0.020258 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:00:07] Energy consumed for all GPUs : 0.129922 kWh. Total GPU Power : 67.07600000000001 W\n",
            "[codecarbon INFO @ 15:00:07] Energy consumed for all CPUs : 0.090295 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:00:07] 0.240475 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 65% 447/685 [1:40:03<53:23, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:00:22] Energy consumed for RAM : 0.020298 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:00:22] Energy consumed for all GPUs : 0.130093 kWh. Total GPU Power : 41.085 W\n",
            "[codecarbon INFO @ 15:00:22] Energy consumed for all CPUs : 0.090472 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:00:22] 0.240863 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 66% 449/685 [1:40:30<52:56, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:00:37] Energy consumed for RAM : 0.020337 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:00:37] Energy consumed for all GPUs : 0.130353 kWh. Total GPU Power : 62.458 W\n",
            "[codecarbon INFO @ 15:00:37] Energy consumed for all CPUs : 0.090649 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:00:37] 0.241340 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 66% 450/685 [1:40:43<52:42, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:00:52] Energy consumed for RAM : 0.020377 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:00:52] Energy consumed for all GPUs : 0.130654 kWh. Total GPU Power : 72.365 W\n",
            "[codecarbon INFO @ 15:00:52] Energy consumed for all CPUs : 0.090826 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:00:52] 0.241858 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 66% 451/685 [1:40:56<52:28, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:01:07] Energy consumed for RAM : 0.020417 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:01:07] Energy consumed for all GPUs : 0.130958 kWh. Total GPU Power : 73.048 W\n",
            "[codecarbon INFO @ 15:01:07] Energy consumed for all CPUs : 0.091003 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:01:07] 0.242378 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 66% 452/685 [1:41:10<52:14, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:01:22] Energy consumed for RAM : 0.020457 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:01:22] Energy consumed for all GPUs : 0.131260 kWh. Total GPU Power : 72.56 W\n",
            "[codecarbon INFO @ 15:01:22] Energy consumed for all CPUs : 0.091180 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:01:22] 0.242897 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 66% 453/685 [1:41:23<52:00, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:01:37] Energy consumed for RAM : 0.020496 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:01:37] Energy consumed for all GPUs : 0.131575 kWh. Total GPU Power : 75.494 W\n",
            "[codecarbon INFO @ 15:01:37] Energy consumed for all CPUs : 0.091357 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:01:37] 0.243428 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 66% 454/685 [1:41:37<51:46, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:01:52] Energy consumed for RAM : 0.020536 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:01:52] Energy consumed for all GPUs : 0.131881 kWh. Total GPU Power : 73.634 W\n",
            "[codecarbon INFO @ 15:01:52] Energy consumed for all CPUs : 0.091535 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:01:52] 0.243952 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 66% 455/685 [1:41:50<51:33, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:02:07] Energy consumed for RAM : 0.020576 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:02:07] Energy consumed for all GPUs : 0.132175 kWh. Total GPU Power : 70.607 W\n",
            "[codecarbon INFO @ 15:02:07] Energy consumed for all CPUs : 0.091712 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:02:07] 0.244462 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 67% 456/685 [1:42:04<51:20, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:02:22] Energy consumed for RAM : 0.020615 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:02:22] Energy consumed for all GPUs : 0.132464 kWh. Total GPU Power : 69.478 W\n",
            "[codecarbon INFO @ 15:02:22] Energy consumed for all CPUs : 0.091889 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:02:22] 0.244968 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 67% 458/685 [1:42:31<50:52, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:02:37] Energy consumed for RAM : 0.020655 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:02:37] Energy consumed for all GPUs : 0.132730 kWh. Total GPU Power : 63.986000000000004 W\n",
            "[codecarbon INFO @ 15:02:37] Energy consumed for all CPUs : 0.092066 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:02:37] 0.245451 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 67% 459/685 [1:42:44<50:38, 13.45s/it]\r                                       \r{'loss': 1.0429, 'learning_rate': 7.37012987012987e-05, 'epoch': 3.35}\n",
            "\r 67% 459/685 [1:42:44<50:38, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:02:52] Energy consumed for RAM : 0.020695 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:02:52] Energy consumed for all GPUs : 0.133051 kWh. Total GPU Power : 76.95700000000001 W\n",
            "[codecarbon INFO @ 15:02:52] Energy consumed for all CPUs : 0.092243 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:02:52] 0.245988 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 67% 460/685 [1:42:57<50:26, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:03:07] Energy consumed for RAM : 0.020735 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:03:07] Energy consumed for all GPUs : 0.133342 kWh. Total GPU Power : 70.06400000000002 W\n",
            "[codecarbon INFO @ 15:03:07] Energy consumed for all CPUs : 0.092420 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:03:07] 0.246497 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 67% 461/685 [1:43:11<50:12, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:03:22] Energy consumed for RAM : 0.020774 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:03:22] Energy consumed for all GPUs : 0.133614 kWh. Total GPU Power : 65.316 W\n",
            "[codecarbon INFO @ 15:03:22] Energy consumed for all CPUs : 0.092597 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:03:22] 0.246985 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 67% 462/685 [1:43:24<49:59, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:03:37] Energy consumed for RAM : 0.020814 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:03:37] Energy consumed for all GPUs : 0.133919 kWh. Total GPU Power : 73.244 W\n",
            "[codecarbon INFO @ 15:03:37] Energy consumed for all CPUs : 0.092774 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:03:37] 0.247507 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 68% 463/685 [1:43:38<49:45, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:03:52] Energy consumed for RAM : 0.020854 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:03:52] Energy consumed for all GPUs : 0.134226 kWh. Total GPU Power : 73.738 W\n",
            "[codecarbon INFO @ 15:03:52] Energy consumed for all CPUs : 0.092951 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:03:52] 0.248030 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 68% 464/685 [1:43:51<49:32, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:04:07] Energy consumed for RAM : 0.020893 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:04:07] Energy consumed for all GPUs : 0.134525 kWh. Total GPU Power : 72.027 W\n",
            "[codecarbon INFO @ 15:04:07] Energy consumed for all CPUs : 0.093128 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:04:07] 0.248546 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 68% 465/685 [1:44:05<49:19, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:04:22] Energy consumed for RAM : 0.020933 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:04:22] Energy consumed for all GPUs : 0.134791 kWh. Total GPU Power : 63.849000000000004 W\n",
            "[codecarbon INFO @ 15:04:22] Energy consumed for all CPUs : 0.093305 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:04:22] 0.249029 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 68% 466/685 [1:44:18<49:08, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:04:37] Energy consumed for RAM : 0.020973 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:04:37] Energy consumed for all GPUs : 0.135089 kWh. Total GPU Power : 71.681 W\n",
            "[codecarbon INFO @ 15:04:37] Energy consumed for all CPUs : 0.093482 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:04:37] 0.249544 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 68% 468/685 [1:44:45<48:42, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:04:52] Energy consumed for RAM : 0.021013 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:04:52] Energy consumed for all GPUs : 0.135389 kWh. Total GPU Power : 72.027 W\n",
            "[codecarbon INFO @ 15:04:52] Energy consumed for all CPUs : 0.093659 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:04:52] 0.250061 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 68% 469/685 [1:44:59<48:28, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:05:07] Energy consumed for RAM : 0.021052 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:05:07] Energy consumed for all GPUs : 0.135677 kWh. Total GPU Power : 69.18500000000002 W\n",
            "[codecarbon INFO @ 15:05:07] Energy consumed for all CPUs : 0.093836 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:05:07] 0.250566 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69% 470/685 [1:45:12<48:15, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:05:22] Energy consumed for RAM : 0.021092 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:05:22] Energy consumed for all GPUs : 0.135966 kWh. Total GPU Power : 69.478 W\n",
            "[codecarbon INFO @ 15:05:22] Energy consumed for all CPUs : 0.094013 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:05:22] 0.251072 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69% 471/685 [1:45:26<48:01, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:05:37] Energy consumed for RAM : 0.021132 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:05:37] Energy consumed for all GPUs : 0.136253 kWh. Total GPU Power : 68.947 W\n",
            "[codecarbon INFO @ 15:05:37] Energy consumed for all CPUs : 0.094190 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:05:37] 0.251575 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69% 472/685 [1:45:39<47:46, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:05:52] Energy consumed for RAM : 0.021171 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:05:52] Energy consumed for all GPUs : 0.136503 kWh. Total GPU Power : 60.01 W\n",
            "[codecarbon INFO @ 15:05:52] Energy consumed for all CPUs : 0.094367 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:05:52] 0.252042 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69% 473/685 [1:45:52<47:31, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:06:07] Energy consumed for RAM : 0.021211 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:06:07] Energy consumed for all GPUs : 0.136788 kWh. Total GPU Power : 68.556 W\n",
            "[codecarbon INFO @ 15:06:07] Energy consumed for all CPUs : 0.094544 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:06:07] 0.252544 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69% 474/685 [1:46:06<47:18, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:06:22] Energy consumed for RAM : 0.021251 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:06:22] Energy consumed for all GPUs : 0.137091 kWh. Total GPU Power : 72.763 W\n",
            "[codecarbon INFO @ 15:06:22] Energy consumed for all CPUs : 0.094721 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:06:22] 0.253063 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69% 475/685 [1:46:19<47:05, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:06:37] Energy consumed for RAM : 0.021291 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:06:37] Energy consumed for all GPUs : 0.137394 kWh. Total GPU Power : 72.86 W\n",
            "[codecarbon INFO @ 15:06:37] Energy consumed for all CPUs : 0.094898 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:06:37] 0.253583 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 69% 476/685 [1:46:33<46:52, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:06:52] Energy consumed for RAM : 0.021330 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:06:52] Energy consumed for all GPUs : 0.137675 kWh. Total GPU Power : 67.425 W\n",
            "[codecarbon INFO @ 15:06:52] Energy consumed for all CPUs : 0.095075 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:06:52] 0.254081 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 70% 478/685 [1:47:00<46:24, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:07:07] Energy consumed for RAM : 0.021370 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:07:07] Energy consumed for all GPUs : 0.138010 kWh. Total GPU Power : 80.368 W\n",
            "[codecarbon INFO @ 15:07:07] Energy consumed for all CPUs : 0.095252 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:07:07] 0.254632 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70% 479/685 [1:47:13<46:11, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:07:22] Energy consumed for RAM : 0.021410 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:07:22] Energy consumed for all GPUs : 0.138266 kWh. Total GPU Power : 61.735 W\n",
            "[codecarbon INFO @ 15:07:22] Energy consumed for all CPUs : 0.095429 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:07:22] 0.255106 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70% 480/685 [1:47:27<45:57, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:07:37] Energy consumed for RAM : 0.021449 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:07:37] Energy consumed for all GPUs : 0.138559 kWh. Total GPU Power : 70.412 W\n",
            "[codecarbon INFO @ 15:07:37] Energy consumed for all CPUs : 0.095606 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:07:37] 0.255615 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70% 481/685 [1:47:40<45:44, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:07:52] Energy consumed for RAM : 0.021489 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:07:52] Energy consumed for all GPUs : 0.138862 kWh. Total GPU Power : 72.613 W\n",
            "[codecarbon INFO @ 15:07:52] Energy consumed for all CPUs : 0.095783 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:07:52] 0.256134 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 70% 482/685 [1:47:54<45:30, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:08:07] Energy consumed for RAM : 0.021529 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:08:07] Energy consumed for all GPUs : 0.139162 kWh. Total GPU Power : 72.22200000000001 W\n",
            "[codecarbon INFO @ 15:08:07] Energy consumed for all CPUs : 0.095960 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:08:07] 0.256652 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 71% 483/685 [1:48:07<45:16, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:08:22] Energy consumed for RAM : 0.021569 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:08:22] Energy consumed for all GPUs : 0.139484 kWh. Total GPU Power : 77.25 W\n",
            "[codecarbon INFO @ 15:08:22] Energy consumed for all CPUs : 0.096138 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:08:22] 0.257190 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 71% 484/685 [1:48:20<45:02, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:08:37] Energy consumed for RAM : 0.021608 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:08:37] Energy consumed for all GPUs : 0.139788 kWh. Total GPU Power : 73.101 W\n",
            "[codecarbon INFO @ 15:08:37] Energy consumed for all CPUs : 0.096315 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:08:37] 0.257711 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 71% 485/685 [1:48:34<44:49, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:08:52] Energy consumed for RAM : 0.021648 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:08:52] Energy consumed for all GPUs : 0.140087 kWh. Total GPU Power : 71.78800000000001 W\n",
            "[codecarbon INFO @ 15:08:52] Energy consumed for all CPUs : 0.096492 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:08:52] 0.258227 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.0455, 'learning_rate': 6.493506493506494e-05, 'epoch': 3.55}\n",
            " 71% 487/685 [1:49:01<44:22, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:09:07] Energy consumed for RAM : 0.021688 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:09:07] Energy consumed for all GPUs : 0.140353 kWh. Total GPU Power : 63.946000000000005 W\n",
            "[codecarbon INFO @ 15:09:07] Energy consumed for all CPUs : 0.096669 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:09:07] 0.258709 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 71% 488/685 [1:49:14<44:08, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:09:22] Energy consumed for RAM : 0.021727 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:09:22] Energy consumed for all GPUs : 0.140636 kWh. Total GPU Power : 67.97 W\n",
            "[codecarbon INFO @ 15:09:22] Energy consumed for all CPUs : 0.096846 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:09:22] 0.259209 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 71% 489/685 [1:49:28<43:56, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:09:37] Energy consumed for RAM : 0.021767 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:09:37] Energy consumed for all GPUs : 0.140950 kWh. Total GPU Power : 75.544 W\n",
            "[codecarbon INFO @ 15:09:37] Energy consumed for all CPUs : 0.097023 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:09:37] 0.259740 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 72% 490/685 [1:49:41<43:43, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:09:52] Energy consumed for RAM : 0.021807 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:09:52] Energy consumed for all GPUs : 0.141245 kWh. Total GPU Power : 70.9 W\n",
            "[codecarbon INFO @ 15:09:52] Energy consumed for all CPUs : 0.097200 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:09:52] 0.260252 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 72% 491/685 [1:49:55<43:30, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:10:07] Energy consumed for RAM : 0.021847 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:10:07] Energy consumed for all GPUs : 0.141503 kWh. Total GPU Power : 61.931000000000004 W\n",
            "[codecarbon INFO @ 15:10:07] Energy consumed for all CPUs : 0.097377 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:10:07] 0.260727 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 72% 492/685 [1:50:08<43:15, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:10:22] Energy consumed for RAM : 0.021886 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:10:22] Energy consumed for all GPUs : 0.141786 kWh. Total GPU Power : 67.97 W\n",
            "[codecarbon INFO @ 15:10:22] Energy consumed for all CPUs : 0.097554 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:10:22] 0.261226 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 72% 493/685 [1:50:21<43:02, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:10:37] Energy consumed for RAM : 0.021926 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:10:37] Energy consumed for all GPUs : 0.142095 kWh. Total GPU Power : 74.128 W\n",
            "[codecarbon INFO @ 15:10:37] Energy consumed for all CPUs : 0.097731 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:10:37] 0.261752 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 72% 494/685 [1:50:35<42:48, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:10:52] Energy consumed for RAM : 0.021966 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:10:52] Energy consumed for all GPUs : 0.142394 kWh. Total GPU Power : 72.027 W\n",
            "[codecarbon INFO @ 15:10:52] Energy consumed for all CPUs : 0.097908 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:10:52] 0.262268 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 72% 495/685 [1:50:48<42:35, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:11:07] Energy consumed for RAM : 0.022005 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:11:07] Energy consumed for all GPUs : 0.142657 kWh. Total GPU Power : 63.065999999999995 W\n",
            "[codecarbon INFO @ 15:11:07] Energy consumed for all CPUs : 0.098085 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:11:07] 0.262747 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 73% 497/685 [1:51:15<42:09, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:11:22] Energy consumed for RAM : 0.022045 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:11:22] Energy consumed for all GPUs : 0.142947 kWh. Total GPU Power : 69.782 W\n",
            "[codecarbon INFO @ 15:11:22] Energy consumed for all CPUs : 0.098262 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:11:22] 0.263254 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 73% 498/685 [1:51:29<41:55, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:11:37] Energy consumed for RAM : 0.022085 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:11:37] Energy consumed for all GPUs : 0.143224 kWh. Total GPU Power : 66.644 W\n",
            "[codecarbon INFO @ 15:11:37] Energy consumed for all CPUs : 0.098439 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:11:37] 0.263748 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 73% 499/685 [1:51:42<41:41, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:11:52] Energy consumed for RAM : 0.022125 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:11:52] Energy consumed for all GPUs : 0.143513 kWh. Total GPU Power : 69.43500000000002 W\n",
            "[codecarbon INFO @ 15:11:52] Energy consumed for all CPUs : 0.098616 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:11:52] 0.264254 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 73% 500/685 [1:51:56<41:28, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:12:07] Energy consumed for RAM : 0.022164 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:12:07] Energy consumed for all GPUs : 0.143815 kWh. Total GPU Power : 72.47000000000001 W\n",
            "[codecarbon INFO @ 15:12:07] Energy consumed for all CPUs : 0.098793 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:12:07] 0.264772 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 73% 501/685 [1:52:09<41:14, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:12:22] Energy consumed for RAM : 0.022204 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:12:22] Energy consumed for all GPUs : 0.144087 kWh. Total GPU Power : 65.316 W\n",
            "[codecarbon INFO @ 15:12:22] Energy consumed for all CPUs : 0.098970 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:12:22] 0.265261 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 73% 502/685 [1:52:23<41:01, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:12:37] Energy consumed for RAM : 0.022244 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:12:37] Energy consumed for all GPUs : 0.144353 kWh. Total GPU Power : 64.044 W\n",
            "[codecarbon INFO @ 15:12:37] Energy consumed for all CPUs : 0.099147 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:12:37] 0.265744 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 73% 503/685 [1:52:36<40:47, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:12:52] Energy consumed for RAM : 0.022283 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:12:52] Energy consumed for all GPUs : 0.144645 kWh. Total GPU Power : 70.173 W\n",
            "[codecarbon INFO @ 15:12:52] Energy consumed for all CPUs : 0.099324 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:12:52] 0.266253 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 74% 504/685 [1:52:49<40:33, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:13:07] Energy consumed for RAM : 0.022323 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:13:07] Energy consumed for all GPUs : 0.144963 kWh. Total GPU Power : 76.324 W\n",
            "[codecarbon INFO @ 15:13:07] Energy consumed for all CPUs : 0.099501 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:13:07] 0.266787 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 74% 505/685 [1:53:03<40:21, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:13:22] Energy consumed for RAM : 0.022363 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:13:22] Energy consumed for all GPUs : 0.145268 kWh. Total GPU Power : 73.29600000000002 W\n",
            "[codecarbon INFO @ 15:13:22] Energy consumed for all CPUs : 0.099678 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:13:22] 0.267309 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 74% 507/685 [1:53:30<39:53, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:13:37] Energy consumed for RAM : 0.022403 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:13:37] Energy consumed for all GPUs : 0.145585 kWh. Total GPU Power : 76.177 W\n",
            "[codecarbon INFO @ 15:13:37] Energy consumed for all CPUs : 0.099855 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:13:37] 0.267843 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 74% 508/685 [1:53:43<39:40, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:13:52] Energy consumed for RAM : 0.022442 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:13:52] Energy consumed for all GPUs : 0.145841 kWh. Total GPU Power : 61.63700000000001 W\n",
            "[codecarbon INFO @ 15:13:52] Energy consumed for all CPUs : 0.100032 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:13:52] 0.268316 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 74% 509/685 [1:53:57<39:26, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:14:07] Energy consumed for RAM : 0.022482 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:14:07] Energy consumed for all GPUs : 0.146140 kWh. Total GPU Power : 71.83200000000001 W\n",
            "[codecarbon INFO @ 15:14:07] Energy consumed for all CPUs : 0.100209 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:14:07] 0.268832 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 74% 510/685 [1:54:10<39:13, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:14:22] Energy consumed for RAM : 0.022522 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:14:22] Energy consumed for all GPUs : 0.146450 kWh. Total GPU Power : 74.32300000000001 W\n",
            "[codecarbon INFO @ 15:14:22] Energy consumed for all CPUs : 0.100386 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:14:22] 0.269358 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75% 511/685 [1:54:24<39:00, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:14:37] Energy consumed for RAM : 0.022561 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:14:37] Energy consumed for all GPUs : 0.146751 kWh. Total GPU Power : 72.47000000000001 W\n",
            "[codecarbon INFO @ 15:14:37] Energy consumed for all CPUs : 0.100564 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:14:37] 0.269876 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75% 512/685 [1:54:37<38:46, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:14:52] Energy consumed for RAM : 0.022601 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:14:52] Energy consumed for all GPUs : 0.147057 kWh. Total GPU Power : 73.394 W\n",
            "[codecarbon INFO @ 15:14:52] Energy consumed for all CPUs : 0.100741 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:14:52] 0.270399 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75% 513/685 [1:54:50<38:33, 13.45s/it]\r                                       \r{'loss': 1.0255, 'learning_rate': 5.616883116883117e-05, 'epoch': 3.74}\n",
            "\r 75% 513/685 [1:54:50<38:33, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:15:07] Energy consumed for RAM : 0.022641 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:15:07] Energy consumed for all GPUs : 0.147361 kWh. Total GPU Power : 73.003 W\n",
            "[codecarbon INFO @ 15:15:07] Energy consumed for all CPUs : 0.100918 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:15:07] 0.270919 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75% 514/685 [1:55:04<38:20, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:15:22] Energy consumed for RAM : 0.022681 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:15:22] Energy consumed for all GPUs : 0.147613 kWh. Total GPU Power : 60.659 W\n",
            "[codecarbon INFO @ 15:15:22] Energy consumed for all CPUs : 0.101095 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:15:22] 0.271389 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 75% 516/685 [1:55:31<37:54, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:15:37] Energy consumed for RAM : 0.022720 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:15:37] Energy consumed for all GPUs : 0.147873 kWh. Total GPU Power : 62.42 W\n",
            "[codecarbon INFO @ 15:15:37] Energy consumed for all CPUs : 0.101272 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:15:37] 0.271865 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 75% 517/685 [1:55:44<37:40, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:15:52] Energy consumed for RAM : 0.022760 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:15:52] Energy consumed for all GPUs : 0.148149 kWh. Total GPU Power : 66.35 W\n",
            "[codecarbon INFO @ 15:15:52] Energy consumed for all CPUs : 0.101449 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:15:52] 0.272358 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76% 518/685 [1:55:58<37:27, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:16:07] Energy consumed for RAM : 0.022800 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:16:07] Energy consumed for all GPUs : 0.148428 kWh. Total GPU Power : 66.937 W\n",
            "[codecarbon INFO @ 15:16:07] Energy consumed for all CPUs : 0.101626 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:16:07] 0.272853 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76% 519/685 [1:56:11<37:13, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:16:22] Energy consumed for RAM : 0.022839 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:16:22] Energy consumed for all GPUs : 0.148730 kWh. Total GPU Power : 72.665 W\n",
            "[codecarbon INFO @ 15:16:22] Energy consumed for all CPUs : 0.101803 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:16:22] 0.273372 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76% 520/685 [1:56:25<37:00, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:16:37] Energy consumed for RAM : 0.022879 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:16:37] Energy consumed for all GPUs : 0.149016 kWh. Total GPU Power : 68.556 W\n",
            "[codecarbon INFO @ 15:16:37] Energy consumed for all CPUs : 0.101980 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:16:37] 0.273875 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76% 521/685 [1:56:38<36:46, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:16:52] Energy consumed for RAM : 0.022919 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:16:52] Energy consumed for all GPUs : 0.149334 kWh. Total GPU Power : 76.422 W\n",
            "[codecarbon INFO @ 15:16:52] Energy consumed for all CPUs : 0.102157 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:16:52] 0.274409 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76% 522/685 [1:56:52<36:32, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:17:07] Energy consumed for RAM : 0.022959 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:17:07] Energy consumed for all GPUs : 0.149633 kWh. Total GPU Power : 71.93 W\n",
            "[codecarbon INFO @ 15:17:07] Energy consumed for all CPUs : 0.102334 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:17:07] 0.274926 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76% 523/685 [1:57:05<36:18, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:17:22] Energy consumed for RAM : 0.022998 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:17:22] Energy consumed for all GPUs : 0.149922 kWh. Total GPU Power : 69.43500000000002 W\n",
            "[codecarbon INFO @ 15:17:22] Energy consumed for all CPUs : 0.102511 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:17:22] 0.275432 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 76% 524/685 [1:57:18<36:04, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:17:37] Energy consumed for RAM : 0.023038 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:17:37] Energy consumed for all GPUs : 0.150210 kWh. Total GPU Power : 69.044 W\n",
            "[codecarbon INFO @ 15:17:37] Energy consumed for all CPUs : 0.102688 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:17:37] 0.275936 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 77% 526/685 [1:57:45<35:37, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:17:52] Energy consumed for RAM : 0.023078 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:17:52] Energy consumed for all GPUs : 0.150494 kWh. Total GPU Power : 68.361 W\n",
            "[codecarbon INFO @ 15:17:52] Energy consumed for all CPUs : 0.102865 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:17:52] 0.276437 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 77% 527/685 [1:57:59<35:24, 13.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:18:07] Energy consumed for RAM : 0.023117 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:18:07] Energy consumed for all GPUs : 0.150782 kWh. Total GPU Power : 69.142 W\n",
            "[codecarbon INFO @ 15:18:07] Energy consumed for all CPUs : 0.103042 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:18:07] 0.276942 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 77% 528/685 [1:58:12<35:11, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:18:22] Energy consumed for RAM : 0.023157 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:18:22] Energy consumed for all GPUs : 0.151049 kWh. Total GPU Power : 64.103 W\n",
            "[codecarbon INFO @ 15:18:22] Energy consumed for all CPUs : 0.103219 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:18:22] 0.277425 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 77% 529/685 [1:58:26<34:58, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:18:37] Energy consumed for RAM : 0.023197 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:18:37] Energy consumed for all GPUs : 0.151300 kWh. Total GPU Power : 60.402 W\n",
            "[codecarbon INFO @ 15:18:37] Energy consumed for all CPUs : 0.103396 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:18:37] 0.277893 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 77% 530/685 [1:58:39<34:45, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:18:52] Energy consumed for RAM : 0.023237 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:18:52] Energy consumed for all GPUs : 0.151587 kWh. Total GPU Power : 68.849 W\n",
            "[codecarbon INFO @ 15:18:52] Energy consumed for all CPUs : 0.103573 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:18:52] 0.278397 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 78% 531/685 [1:58:53<34:32, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:19:07] Energy consumed for RAM : 0.023276 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:19:07] Energy consumed for all GPUs : 0.151883 kWh. Total GPU Power : 71.34400000000001 W\n",
            "[codecarbon INFO @ 15:19:07] Energy consumed for all CPUs : 0.103750 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:19:07] 0.278910 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 78% 532/685 [1:59:06<34:19, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:19:22] Energy consumed for RAM : 0.023316 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:19:22] Energy consumed for all GPUs : 0.152182 kWh. Total GPU Power : 71.734 W\n",
            "[codecarbon INFO @ 15:19:22] Energy consumed for all CPUs : 0.103927 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:19:22] 0.279425 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 78% 533/685 [1:59:20<34:04, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:19:37] Energy consumed for RAM : 0.023356 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:19:37] Energy consumed for all GPUs : 0.152478 kWh. Total GPU Power : 71.149 W\n",
            "[codecarbon INFO @ 15:19:37] Energy consumed for all CPUs : 0.104104 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:19:37] 0.279938 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 78% 534/685 [1:59:33<33:51, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:19:52] Energy consumed for RAM : 0.023396 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:19:52] Energy consumed for all GPUs : 0.152772 kWh. Total GPU Power : 70.46600000000001 W\n",
            "[codecarbon INFO @ 15:19:52] Energy consumed for all CPUs : 0.104282 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:19:52] 0.280449 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 78% 536/685 [2:00:00<33:25, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:20:07] Energy consumed for RAM : 0.023435 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:20:07] Energy consumed for all GPUs : 0.153078 kWh. Total GPU Power : 73.543 W\n",
            "[codecarbon INFO @ 15:20:07] Energy consumed for all CPUs : 0.104459 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:20:07] 0.280971 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 78% 537/685 [2:00:13<33:12, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:20:22] Energy consumed for RAM : 0.023475 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:20:22] Energy consumed for all GPUs : 0.153337 kWh. Total GPU Power : 62.22400000000001 W\n",
            "[codecarbon INFO @ 15:20:22] Energy consumed for all CPUs : 0.104636 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:20:22] 0.281447 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 79% 538/685 [2:00:27<32:58, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:20:37] Energy consumed for RAM : 0.023515 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:20:37] Energy consumed for all GPUs : 0.153628 kWh. Total GPU Power : 69.978 W\n",
            "[codecarbon INFO @ 15:20:37] Energy consumed for all CPUs : 0.104813 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:20:37] 0.281955 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 79% 539/685 [2:00:40<32:44, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:20:52] Energy consumed for RAM : 0.023554 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:20:52] Energy consumed for all GPUs : 0.153927 kWh. Total GPU Power : 71.83200000000001 W\n",
            "[codecarbon INFO @ 15:20:52] Energy consumed for all CPUs : 0.104990 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:20:52] 0.282471 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 79% 540/685 [2:00:54<32:30, 13.45s/it]\r                                       \r{'loss': 1.0583, 'learning_rate': 4.740259740259741e-05, 'epoch': 3.94}\n",
            "\r 79% 540/685 [2:00:54<32:30, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:21:07] Energy consumed for RAM : 0.023594 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:21:07] Energy consumed for all GPUs : 0.154185 kWh. Total GPU Power : 62.088 W\n",
            "[codecarbon INFO @ 15:21:07] Energy consumed for all CPUs : 0.105167 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:21:07] 0.282946 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 79% 541/685 [2:01:07<32:17, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:21:22] Energy consumed for RAM : 0.023634 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:21:22] Energy consumed for all GPUs : 0.154482 kWh. Total GPU Power : 71.3 W\n",
            "[codecarbon INFO @ 15:21:22] Energy consumed for all CPUs : 0.105344 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:21:22] 0.283459 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 79% 542/685 [2:01:21<32:03, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:21:37] Energy consumed for RAM : 0.023673 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:21:37] Energy consumed for all GPUs : 0.154775 kWh. Total GPU Power : 70.607 W\n",
            "[codecarbon INFO @ 15:21:37] Energy consumed for all CPUs : 0.105521 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:21:37] 0.283970 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 79% 543/685 [2:01:34<31:50, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:21:52] Energy consumed for RAM : 0.023713 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:21:52] Energy consumed for all GPUs : 0.155070 kWh. Total GPU Power : 70.758 W\n",
            "[codecarbon INFO @ 15:21:52] Energy consumed for all CPUs : 0.105698 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:21:52] 0.284481 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 80% 545/685 [2:02:01<31:24, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:22:07] Energy consumed for RAM : 0.023753 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:22:07] Energy consumed for all GPUs : 0.155332 kWh. Total GPU Power : 62.968999999999994 W\n",
            "[codecarbon INFO @ 15:22:07] Energy consumed for all CPUs : 0.105875 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:22:07] 0.284960 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80% 546/685 [2:02:14<31:10, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:22:22] Energy consumed for RAM : 0.023793 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:22:22] Energy consumed for all GPUs : 0.155622 kWh. Total GPU Power : 69.587 W\n",
            "[codecarbon INFO @ 15:22:22] Energy consumed for all CPUs : 0.106052 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:22:22] 0.285466 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80% 547/685 [2:02:28<30:57, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:22:37] Energy consumed for RAM : 0.023832 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:22:37] Energy consumed for all GPUs : 0.155918 kWh. Total GPU Power : 71.29 W\n",
            "[codecarbon INFO @ 15:22:37] Energy consumed for all CPUs : 0.106229 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:22:37] 0.285980 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80% 548/685 [2:02:41<30:42, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:22:52] Energy consumed for RAM : 0.023872 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:22:52] Energy consumed for all GPUs : 0.156175 kWh. Total GPU Power : 61.63700000000001 W\n",
            "[codecarbon INFO @ 15:22:52] Energy consumed for all CPUs : 0.106406 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:22:52] 0.286453 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80% 549/685 [2:02:55<30:52, 13.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:23:07] Energy consumed for RAM : 0.023912 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:23:07] Energy consumed for all GPUs : 0.156443 kWh. Total GPU Power : 64.533 W\n",
            "[codecarbon INFO @ 15:23:07] Energy consumed for all CPUs : 0.106583 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:23:07] 0.286938 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80% 550/685 [2:03:09<30:32, 13.57s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:23:22] Energy consumed for RAM : 0.023951 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:23:22] Energy consumed for all GPUs : 0.156727 kWh. Total GPU Power : 68.165 W\n",
            "[codecarbon INFO @ 15:23:22] Energy consumed for all CPUs : 0.106760 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:23:22] 0.287439 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 80% 551/685 [2:03:22<30:14, 13.54s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:23:37] Energy consumed for RAM : 0.023991 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:23:37] Energy consumed for all GPUs : 0.157039 kWh. Total GPU Power : 75.053 W\n",
            "[codecarbon INFO @ 15:23:37] Energy consumed for all CPUs : 0.106937 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:23:37] 0.287968 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 81% 552/685 [2:03:36<29:56, 13.51s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:23:52] Energy consumed for RAM : 0.024031 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:23:52] Energy consumed for all GPUs : 0.157338 kWh. Total GPU Power : 71.69 W\n",
            "[codecarbon INFO @ 15:23:52] Energy consumed for all CPUs : 0.107114 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:23:52] 0.288483 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 81% 553/685 [2:03:49<29:41, 13.50s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:24:07] Energy consumed for RAM : 0.024071 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:24:07] Energy consumed for all GPUs : 0.157646 kWh. Total GPU Power : 74.077 W\n",
            "[codecarbon INFO @ 15:24:07] Energy consumed for all CPUs : 0.107291 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:24:07] 0.289008 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 81% 554/685 [2:04:03<29:27, 13.49s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:24:22] Energy consumed for RAM : 0.024110 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:24:22] Energy consumed for all GPUs : 0.157985 kWh. Total GPU Power : 81.291 W\n",
            "[codecarbon INFO @ 15:24:22] Energy consumed for all CPUs : 0.107468 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:24:22] 0.289563 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 81% 556/685 [2:04:30<28:58, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:24:37] Energy consumed for RAM : 0.024150 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:24:37] Energy consumed for all GPUs : 0.158278 kWh. Total GPU Power : 70.412 W\n",
            "[codecarbon INFO @ 15:24:37] Energy consumed for all CPUs : 0.107645 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:24:37] 0.290073 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 81% 557/685 [2:04:43<28:43, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:24:52] Energy consumed for RAM : 0.024190 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:24:52] Energy consumed for all GPUs : 0.158593 kWh. Total GPU Power : 75.786 W\n",
            "[codecarbon INFO @ 15:24:52] Energy consumed for all CPUs : 0.107822 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:24:52] 0.290605 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 81% 558/685 [2:04:56<28:29, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:25:07] Energy consumed for RAM : 0.024229 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:25:07] Energy consumed for all GPUs : 0.158905 kWh. Total GPU Power : 75.006 W\n",
            "[codecarbon INFO @ 15:25:07] Energy consumed for all CPUs : 0.107999 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:25:07] 0.291134 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 82% 559/685 [2:05:10<28:15, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:25:22] Energy consumed for RAM : 0.024269 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:25:22] Energy consumed for all GPUs : 0.159213 kWh. Total GPU Power : 74.03100000000002 W\n",
            "[codecarbon INFO @ 15:25:22] Energy consumed for all CPUs : 0.108177 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:25:22] 0.291659 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 82% 560/685 [2:05:23<28:02, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:25:37] Energy consumed for RAM : 0.024309 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:25:37] Energy consumed for all GPUs : 0.159473 kWh. Total GPU Power : 62.458 W\n",
            "[codecarbon INFO @ 15:25:37] Energy consumed for all CPUs : 0.108354 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:25:37] 0.292136 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 82% 561/685 [2:05:37<27:49, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:25:52] Energy consumed for RAM : 0.024349 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:25:52] Energy consumed for all GPUs : 0.159750 kWh. Total GPU Power : 66.505 W\n",
            "[codecarbon INFO @ 15:25:52] Energy consumed for all CPUs : 0.108531 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:25:52] 0.292629 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 82% 562/685 [2:05:50<27:35, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:26:07] Energy consumed for RAM : 0.024388 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:26:07] Energy consumed for all GPUs : 0.160053 kWh. Total GPU Power : 72.86 W\n",
            "[codecarbon INFO @ 15:26:07] Energy consumed for all CPUs : 0.108708 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:26:07] 0.293149 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 82% 563/685 [2:06:04<27:21, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:26:22] Energy consumed for RAM : 0.024428 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:26:22] Energy consumed for all GPUs : 0.160357 kWh. Total GPU Power : 72.958 W\n",
            "[codecarbon INFO @ 15:26:22] Energy consumed for all CPUs : 0.108885 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:26:22] 0.293670 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 82% 565/685 [2:06:31<26:53, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:26:37] Energy consumed for RAM : 0.024468 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:26:37] Energy consumed for all GPUs : 0.160649 kWh. Total GPU Power : 70.173 W\n",
            "[codecarbon INFO @ 15:26:37] Energy consumed for all CPUs : 0.109062 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:26:37] 0.294178 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 83% 566/685 [2:06:44<26:40, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:26:52] Energy consumed for RAM : 0.024507 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:26:52] Energy consumed for all GPUs : 0.160910 kWh. Total GPU Power : 62.81100000000001 W\n",
            "[codecarbon INFO @ 15:26:52] Energy consumed for all CPUs : 0.109239 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:26:52] 0.294657 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 83% 567/685 [2:06:58<26:27, 13.45s/it]\r                                       \r{'loss': 1.0279, 'learning_rate': 3.8636363636363636e-05, 'epoch': 4.14}\n",
            "\r 83% 567/685 [2:06:58<26:27, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:27:07] Energy consumed for RAM : 0.024547 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:27:07] Energy consumed for all GPUs : 0.161210 kWh. Total GPU Power : 71.983 W\n",
            "[codecarbon INFO @ 15:27:07] Energy consumed for all CPUs : 0.109416 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:27:07] 0.295173 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 83% 568/685 [2:07:11<26:13, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:27:22] Energy consumed for RAM : 0.024587 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:27:22] Energy consumed for all GPUs : 0.161468 kWh. Total GPU Power : 61.931000000000004 W\n",
            "[codecarbon INFO @ 15:27:22] Energy consumed for all CPUs : 0.109593 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:27:22] 0.295648 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 83% 569/685 [2:07:24<26:00, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:27:37] Energy consumed for RAM : 0.024627 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:27:37] Energy consumed for all GPUs : 0.161782 kWh. Total GPU Power : 75.544 W\n",
            "[codecarbon INFO @ 15:27:37] Energy consumed for all CPUs : 0.109770 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:27:37] 0.296179 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 83% 570/685 [2:07:38<25:47, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:27:52] Energy consumed for RAM : 0.024666 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:27:52] Energy consumed for all GPUs : 0.162069 kWh. Total GPU Power : 68.806 W\n",
            "[codecarbon INFO @ 15:27:52] Energy consumed for all CPUs : 0.109947 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:27:52] 0.296682 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 83% 571/685 [2:07:51<25:34, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:28:07] Energy consumed for RAM : 0.024706 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:28:07] Energy consumed for all GPUs : 0.162387 kWh. Total GPU Power : 76.422 W\n",
            "[codecarbon INFO @ 15:28:07] Energy consumed for all CPUs : 0.110124 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:28:07] 0.297217 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 84% 572/685 [2:08:05<25:20, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:28:22] Energy consumed for RAM : 0.024746 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:28:22] Energy consumed for all GPUs : 0.162638 kWh. Total GPU Power : 60.463 W\n",
            "[codecarbon INFO @ 15:28:22] Energy consumed for all CPUs : 0.110301 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:28:22] 0.297685 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 84% 573/685 [2:08:18<25:06, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:28:37] Energy consumed for RAM : 0.024786 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:28:37] Energy consumed for all GPUs : 0.162923 kWh. Total GPU Power : 68.41600000000001 W\n",
            "[codecarbon INFO @ 15:28:37] Energy consumed for all CPUs : 0.110478 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:28:37] 0.298187 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 84% 575/685 [2:08:45<24:39, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:28:52] Energy consumed for RAM : 0.024825 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:28:52] Energy consumed for all GPUs : 0.163232 kWh. Total GPU Power : 74.08200000000001 W\n",
            "[codecarbon INFO @ 15:28:52] Energy consumed for all CPUs : 0.110655 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:28:52] 0.298712 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 84% 576/685 [2:08:59<24:26, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:29:07] Energy consumed for RAM : 0.024865 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:29:07] Energy consumed for all GPUs : 0.163534 kWh. Total GPU Power : 72.568 W\n",
            "[codecarbon INFO @ 15:29:07] Energy consumed for all CPUs : 0.110832 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:29:07] 0.299231 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 84% 577/685 [2:09:12<24:13, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:29:22] Energy consumed for RAM : 0.024905 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:29:22] Energy consumed for all GPUs : 0.163824 kWh. Total GPU Power : 69.685 W\n",
            "[codecarbon INFO @ 15:29:22] Energy consumed for all CPUs : 0.111009 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:29:22] 0.299738 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 84% 578/685 [2:09:26<23:59, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:29:37] Energy consumed for RAM : 0.024944 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:29:37] Energy consumed for all GPUs : 0.164118 kWh. Total GPU Power : 70.715 W\n",
            "[codecarbon INFO @ 15:29:37] Energy consumed for all CPUs : 0.111186 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:29:37] 0.300249 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85% 579/685 [2:09:39<23:46, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:29:52] Energy consumed for RAM : 0.024984 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:29:52] Energy consumed for all GPUs : 0.164443 kWh. Total GPU Power : 77.981 W\n",
            "[codecarbon INFO @ 15:29:52] Energy consumed for all CPUs : 0.111363 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:29:52] 0.300790 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85% 580/685 [2:09:52<23:32, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:30:07] Energy consumed for RAM : 0.025024 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:30:07] Energy consumed for all GPUs : 0.164747 kWh. Total GPU Power : 73.055 W\n",
            "[codecarbon INFO @ 15:30:07] Energy consumed for all CPUs : 0.111540 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:30:07] 0.301311 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85% 581/685 [2:10:06<23:19, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:30:22] Energy consumed for RAM : 0.025064 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:30:22] Energy consumed for all GPUs : 0.165042 kWh. Total GPU Power : 71.051 W\n",
            "[codecarbon INFO @ 15:30:22] Energy consumed for all CPUs : 0.111717 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:30:22] 0.301823 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85% 582/685 [2:10:19<23:05, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:30:37] Energy consumed for RAM : 0.025103 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:30:37] Energy consumed for all GPUs : 0.165348 kWh. Total GPU Power : 73.348 W\n",
            "[codecarbon INFO @ 15:30:37] Energy consumed for all CPUs : 0.111894 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:30:37] 0.302345 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 85% 583/685 [2:10:33<22:52, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:30:52] Energy consumed for RAM : 0.025143 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:30:52] Energy consumed for all GPUs : 0.165641 kWh. Total GPU Power : 70.46600000000001 W\n",
            "[codecarbon INFO @ 15:30:52] Energy consumed for all CPUs : 0.112072 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:30:52] 0.302855 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 85% 585/685 [2:11:00<22:26, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:31:07] Energy consumed for RAM : 0.025183 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:31:07] Energy consumed for all GPUs : 0.165928 kWh. Total GPU Power : 69.099 W\n",
            "[codecarbon INFO @ 15:31:07] Energy consumed for all CPUs : 0.112249 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:31:07] 0.303360 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86% 586/685 [2:11:13<22:13, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:31:22] Energy consumed for RAM : 0.025222 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:31:22] Energy consumed for all GPUs : 0.166209 kWh. Total GPU Power : 67.44 W\n",
            "[codecarbon INFO @ 15:31:22] Energy consumed for all CPUs : 0.112426 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:31:22] 0.303857 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86% 587/685 [2:11:27<21:59, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:31:37] Energy consumed for RAM : 0.025262 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:31:37] Energy consumed for all GPUs : 0.166486 kWh. Total GPU Power : 66.44800000000001 W\n",
            "[codecarbon INFO @ 15:31:37] Energy consumed for all CPUs : 0.112603 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:31:37] 0.304350 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86% 588/685 [2:11:40<21:45, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:31:52] Energy consumed for RAM : 0.025302 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:31:52] Energy consumed for all GPUs : 0.166793 kWh. Total GPU Power : 73.79 W\n",
            "[codecarbon INFO @ 15:31:52] Energy consumed for all CPUs : 0.112780 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:31:52] 0.304874 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86% 589/685 [2:11:54<21:31, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:32:07] Energy consumed for RAM : 0.025342 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:32:07] Energy consumed for all GPUs : 0.167094 kWh. Total GPU Power : 72.328 W\n",
            "[codecarbon INFO @ 15:32:07] Energy consumed for all CPUs : 0.112957 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:32:07] 0.305392 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86% 590/685 [2:12:07<21:18, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:32:22] Energy consumed for RAM : 0.025381 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:32:22] Energy consumed for all GPUs : 0.167383 kWh. Total GPU Power : 69.49 W\n",
            "[codecarbon INFO @ 15:32:22] Energy consumed for all CPUs : 0.113134 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:32:22] 0.305898 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86% 591/685 [2:12:21<21:05, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:32:37] Energy consumed for RAM : 0.025421 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:32:37] Energy consumed for all GPUs : 0.167698 kWh. Total GPU Power : 75.642 W\n",
            "[codecarbon INFO @ 15:32:37] Energy consumed for all CPUs : 0.113311 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:32:37] 0.306429 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 86% 592/685 [2:12:34<20:52, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:32:52] Energy consumed for RAM : 0.025461 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:32:52] Energy consumed for all GPUs : 0.167948 kWh. Total GPU Power : 60.169000000000004 W\n",
            "[codecarbon INFO @ 15:32:52] Energy consumed for all CPUs : 0.113488 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:32:52] 0.306897 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 0.9746, 'learning_rate': 2.9870129870129872e-05, 'epoch': 4.34}\n",
            " 87% 594/685 [2:13:01<20:23, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:33:07] Energy consumed for RAM : 0.025500 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:33:07] Energy consumed for all GPUs : 0.168221 kWh. Total GPU Power : 65.471 W\n",
            "[codecarbon INFO @ 15:33:07] Energy consumed for all CPUs : 0.113665 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:33:07] 0.307386 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 87% 595/685 [2:13:14<20:10, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:33:22] Energy consumed for RAM : 0.025540 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:33:22] Energy consumed for all GPUs : 0.168498 kWh. Total GPU Power : 66.603 W\n",
            "[codecarbon INFO @ 15:33:22] Energy consumed for all CPUs : 0.113842 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:33:22] 0.307880 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 87% 596/685 [2:13:28<19:57, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:33:37] Energy consumed for RAM : 0.025580 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:33:37] Energy consumed for all GPUs : 0.168798 kWh. Total GPU Power : 72.178 W\n",
            "[codecarbon INFO @ 15:33:37] Energy consumed for all CPUs : 0.114019 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:33:37] 0.308397 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 87% 597/685 [2:13:41<19:43, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:33:52] Energy consumed for RAM : 0.025620 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:33:52] Energy consumed for all GPUs : 0.169094 kWh. Total GPU Power : 71.105 W\n",
            "[codecarbon INFO @ 15:33:52] Energy consumed for all CPUs : 0.114196 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:33:52] 0.308910 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 87% 598/685 [2:13:55<19:29, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:34:07] Energy consumed for RAM : 0.025659 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:34:07] Energy consumed for all GPUs : 0.169346 kWh. Total GPU Power : 60.365 W\n",
            "[codecarbon INFO @ 15:34:07] Energy consumed for all CPUs : 0.114373 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:34:07] 0.309378 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 87% 599/685 [2:14:08<19:16, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:34:22] Energy consumed for RAM : 0.025699 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:34:22] Energy consumed for all GPUs : 0.169633 kWh. Total GPU Power : 69.002 W\n",
            "[codecarbon INFO @ 15:34:22] Energy consumed for all CPUs : 0.114550 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:34:22] 0.309882 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 88% 600/685 [2:14:22<19:03, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:34:37] Energy consumed for RAM : 0.025739 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:34:37] Energy consumed for all GPUs : 0.169924 kWh. Total GPU Power : 70.075 W\n",
            "[codecarbon INFO @ 15:34:37] Energy consumed for all CPUs : 0.114727 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:34:37] 0.310390 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 88% 601/685 [2:14:35<18:49, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:34:52] Energy consumed for RAM : 0.025778 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:34:52] Energy consumed for all GPUs : 0.170239 kWh. Total GPU Power : 75.544 W\n",
            "[codecarbon INFO @ 15:34:52] Energy consumed for all CPUs : 0.114904 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:34:52] 0.310922 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 88% 602/685 [2:14:48<18:36, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:35:07] Energy consumed for RAM : 0.025818 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:35:07] Energy consumed for all GPUs : 0.170535 kWh. Total GPU Power : 71.202 W\n",
            "[codecarbon INFO @ 15:35:07] Energy consumed for all CPUs : 0.115081 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:35:07] 0.311434 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 88% 604/685 [2:15:15<18:09, 13.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:35:22] Energy consumed for RAM : 0.025858 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:35:22] Energy consumed for all GPUs : 0.170830 kWh. Total GPU Power : 70.85600000000001 W\n",
            "[codecarbon INFO @ 15:35:22] Energy consumed for all CPUs : 0.115258 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:35:22] 0.311946 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 88% 605/685 [2:15:29<17:55, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:35:37] Energy consumed for RAM : 0.025898 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:35:37] Energy consumed for all GPUs : 0.171090 kWh. Total GPU Power : 62.441 W\n",
            "[codecarbon INFO @ 15:35:37] Energy consumed for all CPUs : 0.115435 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:35:37] 0.312423 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 88% 606/685 [2:15:42<17:42, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:35:52] Energy consumed for RAM : 0.025937 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:35:52] Energy consumed for all GPUs : 0.171375 kWh. Total GPU Power : 68.5 W\n",
            "[codecarbon INFO @ 15:35:52] Energy consumed for all CPUs : 0.115612 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:35:52] 0.312925 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 89% 607/685 [2:15:56<17:29, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:36:07] Energy consumed for RAM : 0.025977 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:36:07] Energy consumed for all GPUs : 0.171672 kWh. Total GPU Power : 71.34400000000001 W\n",
            "[codecarbon INFO @ 15:36:07] Energy consumed for all CPUs : 0.115789 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:36:07] 0.313438 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 89% 608/685 [2:16:09<17:15, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:36:22] Energy consumed for RAM : 0.026017 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:36:22] Energy consumed for all GPUs : 0.171960 kWh. Total GPU Power : 69.24 W\n",
            "[codecarbon INFO @ 15:36:22] Energy consumed for all CPUs : 0.115966 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:36:22] 0.313943 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 89% 609/685 [2:16:23<17:02, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:36:37] Energy consumed for RAM : 0.026056 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:36:37] Energy consumed for all GPUs : 0.172211 kWh. Total GPU Power : 60.365 W\n",
            "[codecarbon INFO @ 15:36:37] Energy consumed for all CPUs : 0.116144 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:36:37] 0.314411 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 89% 610/685 [2:16:36<16:48, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:36:52] Energy consumed for RAM : 0.026096 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:36:52] Energy consumed for all GPUs : 0.172497 kWh. Total GPU Power : 68.654 W\n",
            "[codecarbon INFO @ 15:36:52] Energy consumed for all CPUs : 0.116321 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:36:52] 0.314914 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 89% 611/685 [2:16:50<16:35, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:37:07] Energy consumed for RAM : 0.026136 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:37:07] Energy consumed for all GPUs : 0.172805 kWh. Total GPU Power : 74.08200000000001 W\n",
            "[codecarbon INFO @ 15:37:07] Energy consumed for all CPUs : 0.116498 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:37:07] 0.315439 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 89% 612/685 [2:17:03<16:21, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:37:22] Energy consumed for RAM : 0.026176 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:37:22] Energy consumed for all GPUs : 0.173088 kWh. Total GPU Power : 67.914 W\n",
            "[codecarbon INFO @ 15:37:22] Energy consumed for all CPUs : 0.116675 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:37:22] 0.315938 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 90% 614/685 [2:17:30<15:55, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:37:37] Energy consumed for RAM : 0.026215 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:37:37] Energy consumed for all GPUs : 0.173370 kWh. Total GPU Power : 67.67700000000002 W\n",
            "[codecarbon INFO @ 15:37:37] Energy consumed for all CPUs : 0.116852 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:37:37] 0.316437 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90% 615/685 [2:17:43<15:42, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:37:52] Energy consumed for RAM : 0.026255 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:37:52] Energy consumed for all GPUs : 0.173643 kWh. Total GPU Power : 65.609 W\n",
            "[codecarbon INFO @ 15:37:52] Energy consumed for all CPUs : 0.117029 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:37:52] 0.316927 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90% 616/685 [2:17:57<15:28, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:38:07] Energy consumed for RAM : 0.026295 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:38:07] Energy consumed for all GPUs : 0.173981 kWh. Total GPU Power : 81.291 W\n",
            "[codecarbon INFO @ 15:38:07] Energy consumed for all CPUs : 0.117206 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:38:07] 0.317482 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90% 617/685 [2:18:10<15:15, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:38:22] Energy consumed for RAM : 0.026334 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:38:22] Energy consumed for all GPUs : 0.174266 kWh. Total GPU Power : 68.458 W\n",
            "[codecarbon INFO @ 15:38:22] Energy consumed for all CPUs : 0.117383 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:38:22] 0.317983 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90% 618/685 [2:18:24<15:01, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:38:37] Energy consumed for RAM : 0.026374 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:38:37] Energy consumed for all GPUs : 0.174569 kWh. Total GPU Power : 72.71000000000001 W\n",
            "[codecarbon INFO @ 15:38:37] Energy consumed for all CPUs : 0.117560 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:38:37] 0.318503 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 90% 619/685 [2:18:37<14:48, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:38:52] Energy consumed for RAM : 0.026414 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:38:52] Energy consumed for all GPUs : 0.174865 kWh. Total GPU Power : 71.246 W\n",
            "[codecarbon INFO @ 15:38:52] Energy consumed for all CPUs : 0.117737 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:38:52] 0.319016 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 91% 620/685 [2:18:51<14:34, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:39:07] Energy consumed for RAM : 0.026454 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:39:07] Energy consumed for all GPUs : 0.175156 kWh. Total GPU Power : 69.923 W\n",
            "[codecarbon INFO @ 15:39:07] Energy consumed for all CPUs : 0.117914 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:39:07] 0.319524 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 91% 621/685 [2:19:04<14:21, 13.47s/it]\r                                       \r{'loss': 0.9944, 'learning_rate': 2.1103896103896105e-05, 'epoch': 4.53}\n",
            "\r 91% 621/685 [2:19:04<14:21, 13.47s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:39:22] Energy consumed for RAM : 0.026493 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:39:22] Energy consumed for all GPUs : 0.175453 kWh. Total GPU Power : 71.34400000000001 W\n",
            "[codecarbon INFO @ 15:39:22] Energy consumed for all CPUs : 0.118091 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:39:22] 0.320037 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 91% 622/685 [2:19:18<14:08, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:39:37] Energy consumed for RAM : 0.026533 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:39:37] Energy consumed for all GPUs : 0.175738 kWh. Total GPU Power : 68.5 W\n",
            "[codecarbon INFO @ 15:39:37] Energy consumed for all CPUs : 0.118268 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:39:37] 0.320539 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 91% 624/685 [2:19:45<13:40, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:39:52] Energy consumed for RAM : 0.026573 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:39:52] Energy consumed for all GPUs : 0.176041 kWh. Total GPU Power : 72.763 W\n",
            "[codecarbon INFO @ 15:39:52] Energy consumed for all CPUs : 0.118445 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:39:52] 0.321059 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 91% 625/685 [2:19:58<13:27, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:40:07] Energy consumed for RAM : 0.026612 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:40:07] Energy consumed for all GPUs : 0.176336 kWh. Total GPU Power : 70.95400000000001 W\n",
            "[codecarbon INFO @ 15:40:07] Energy consumed for all CPUs : 0.118622 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:40:07] 0.321571 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 91% 626/685 [2:20:11<13:13, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:40:22] Energy consumed for RAM : 0.026652 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:40:22] Energy consumed for all GPUs : 0.176614 kWh. Total GPU Power : 66.741 W\n",
            "[codecarbon INFO @ 15:40:22] Energy consumed for all CPUs : 0.118799 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:40:22] 0.322065 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 92% 627/685 [2:20:25<13:00, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:40:37] Energy consumed for RAM : 0.026692 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:40:37] Energy consumed for all GPUs : 0.176926 kWh. Total GPU Power : 75.006 W\n",
            "[codecarbon INFO @ 15:40:37] Energy consumed for all CPUs : 0.118976 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:40:37] 0.322594 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 92% 628/685 [2:20:38<12:46, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:40:52] Energy consumed for RAM : 0.026732 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:40:52] Energy consumed for all GPUs : 0.177230 kWh. Total GPU Power : 73.101 W\n",
            "[codecarbon INFO @ 15:40:52] Energy consumed for all CPUs : 0.119153 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:40:52] 0.323115 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 92% 629/685 [2:20:52<12:33, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:41:07] Energy consumed for RAM : 0.026771 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:41:07] Energy consumed for all GPUs : 0.177550 kWh. Total GPU Power : 76.714 W\n",
            "[codecarbon INFO @ 15:41:07] Energy consumed for all CPUs : 0.119330 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:41:07] 0.323651 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 92% 630/685 [2:21:05<12:19, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:41:22] Energy consumed for RAM : 0.026811 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:41:22] Energy consumed for all GPUs : 0.177858 kWh. Total GPU Power : 74.077 W\n",
            "[codecarbon INFO @ 15:41:22] Energy consumed for all CPUs : 0.119507 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:41:22] 0.324176 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 92% 631/685 [2:21:19<12:06, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:41:37] Energy consumed for RAM : 0.026851 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:41:37] Energy consumed for all GPUs : 0.178146 kWh. Total GPU Power : 69.099 W\n",
            "[codecarbon INFO @ 15:41:37] Energy consumed for all CPUs : 0.119684 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:41:37] 0.324681 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 92% 633/685 [2:21:46<11:39, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:41:52] Energy consumed for RAM : 0.026890 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:41:52] Energy consumed for all GPUs : 0.178429 kWh. Total GPU Power : 68.20700000000001 W\n",
            "[codecarbon INFO @ 15:41:52] Energy consumed for all CPUs : 0.119861 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:41:52] 0.325181 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 93% 634/685 [2:21:59<11:25, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:42:07] Energy consumed for RAM : 0.026930 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:42:07] Energy consumed for all GPUs : 0.178689 kWh. Total GPU Power : 62.48000000000001 W\n",
            "[codecarbon INFO @ 15:42:07] Energy consumed for all CPUs : 0.120038 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:42:07] 0.325658 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 93% 635/685 [2:22:12<11:12, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:42:22] Energy consumed for RAM : 0.026970 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:42:22] Energy consumed for all GPUs : 0.179006 kWh. Total GPU Power : 76.129 W\n",
            "[codecarbon INFO @ 15:42:22] Energy consumed for all CPUs : 0.120215 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:42:22] 0.326191 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 93% 636/685 [2:22:26<10:59, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:42:37] Energy consumed for RAM : 0.027010 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:42:37] Energy consumed for all GPUs : 0.179333 kWh. Total GPU Power : 78.51700000000001 W\n",
            "[codecarbon INFO @ 15:42:37] Energy consumed for all CPUs : 0.120392 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:42:37] 0.326735 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 93% 637/685 [2:22:39<10:45, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:42:52] Energy consumed for RAM : 0.027049 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:42:52] Energy consumed for all GPUs : 0.179583 kWh. Total GPU Power : 60.169000000000004 W\n",
            "[codecarbon INFO @ 15:42:52] Energy consumed for all CPUs : 0.120569 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:42:52] 0.327202 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 93% 638/685 [2:22:53<10:32, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:43:07] Energy consumed for RAM : 0.027089 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:43:07] Energy consumed for all GPUs : 0.179867 kWh. Total GPU Power : 68.165 W\n",
            "[codecarbon INFO @ 15:43:07] Energy consumed for all CPUs : 0.120746 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:43:07] 0.327703 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 93% 639/685 [2:23:06<10:18, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:43:22] Energy consumed for RAM : 0.027129 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:43:22] Energy consumed for all GPUs : 0.180161 kWh. Total GPU Power : 70.607 W\n",
            "[codecarbon INFO @ 15:43:22] Energy consumed for all CPUs : 0.120923 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:43:22] 0.328214 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 93% 640/685 [2:23:20<10:05, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:43:37] Energy consumed for RAM : 0.027169 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:43:37] Energy consumed for all GPUs : 0.180494 kWh. Total GPU Power : 79.97800000000001 W\n",
            "[codecarbon INFO @ 15:43:37] Energy consumed for all CPUs : 0.121101 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:43:37] 0.328763 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 94% 641/685 [2:23:33<09:51, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:43:52] Energy consumed for RAM : 0.027208 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:43:52] Energy consumed for all GPUs : 0.180755 kWh. Total GPU Power : 62.57699999999999 W\n",
            "[codecarbon INFO @ 15:43:52] Energy consumed for all CPUs : 0.121278 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:43:52] 0.329241 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 94% 643/685 [2:24:00<09:24, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:44:07] Energy consumed for RAM : 0.027248 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:44:07] Energy consumed for all GPUs : 0.181073 kWh. Total GPU Power : 76.422 W\n",
            "[codecarbon INFO @ 15:44:07] Energy consumed for all CPUs : 0.121455 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:44:07] 0.329775 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 94% 644/685 [2:24:13<09:11, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:44:22] Energy consumed for RAM : 0.027288 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:44:22] Energy consumed for all GPUs : 0.181357 kWh. Total GPU Power : 68.20700000000001 W\n",
            "[codecarbon INFO @ 15:44:22] Energy consumed for all CPUs : 0.121632 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:44:22] 0.330276 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 94% 645/685 [2:24:27<08:57, 13.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:44:37] Energy consumed for RAM : 0.027327 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:44:37] Energy consumed for all GPUs : 0.181694 kWh. Total GPU Power : 81.096 W\n",
            "[codecarbon INFO @ 15:44:37] Energy consumed for all CPUs : 0.121809 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:44:37] 0.330831 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 94% 646/685 [2:24:40<08:44, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:44:52] Energy consumed for RAM : 0.027367 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:44:52] Energy consumed for all GPUs : 0.182008 kWh. Total GPU Power : 75.447 W\n",
            "[codecarbon INFO @ 15:44:52] Energy consumed for all CPUs : 0.121986 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:44:52] 0.331361 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 94% 647/685 [2:24:54<08:31, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:45:07] Energy consumed for RAM : 0.027407 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:45:07] Energy consumed for all GPUs : 0.182287 kWh. Total GPU Power : 66.937 W\n",
            "[codecarbon INFO @ 15:45:07] Energy consumed for all CPUs : 0.122163 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:45:07] 0.331856 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95% 648/685 [2:25:07<08:17, 13.45s/it]\r                                       \r{'loss': 0.9703, 'learning_rate': 1.2337662337662339e-05, 'epoch': 4.73}\n",
            "\r 95% 648/685 [2:25:07<08:17, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:45:22] Energy consumed for RAM : 0.027447 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:45:22] Energy consumed for all GPUs : 0.182597 kWh. Total GPU Power : 74.565 W\n",
            "[codecarbon INFO @ 15:45:22] Energy consumed for all CPUs : 0.122340 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:45:22] 0.332383 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95% 649/685 [2:25:21<08:04, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:45:37] Energy consumed for RAM : 0.027486 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:45:37] Energy consumed for all GPUs : 0.182905 kWh. Total GPU Power : 73.979 W\n",
            "[codecarbon INFO @ 15:45:37] Energy consumed for all CPUs : 0.122517 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:45:37] 0.332908 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95% 650/685 [2:25:34<07:50, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:45:52] Energy consumed for RAM : 0.027526 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:45:52] Energy consumed for all GPUs : 0.183213 kWh. Total GPU Power : 74.128 W\n",
            "[codecarbon INFO @ 15:45:52] Energy consumed for all CPUs : 0.122694 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:45:52] 0.333433 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95% 651/685 [2:25:48<07:37, 13.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:46:07] Energy consumed for RAM : 0.027566 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:46:07] Energy consumed for all GPUs : 0.183535 kWh. Total GPU Power : 77.348 W\n",
            "[codecarbon INFO @ 15:46:07] Energy consumed for all CPUs : 0.122871 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:46:07] 0.333972 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 95% 653/685 [2:26:15<07:10, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:46:22] Energy consumed for RAM : 0.027605 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:46:22] Energy consumed for all GPUs : 0.183828 kWh. Total GPU Power : 70.509 W\n",
            "[codecarbon INFO @ 15:46:22] Energy consumed for all CPUs : 0.123048 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:46:22] 0.334482 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 95% 654/685 [2:26:28<06:57, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:46:37] Energy consumed for RAM : 0.027645 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:46:37] Energy consumed for all GPUs : 0.184085 kWh. Total GPU Power : 61.697 W\n",
            "[codecarbon INFO @ 15:46:37] Energy consumed for all CPUs : 0.123225 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:46:37] 0.334955 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 96% 655/685 [2:26:41<06:43, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:46:52] Energy consumed for RAM : 0.027685 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:46:52] Energy consumed for all GPUs : 0.184386 kWh. Total GPU Power : 72.178 W\n",
            "[codecarbon INFO @ 15:46:52] Energy consumed for all CPUs : 0.123402 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:46:52] 0.335472 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 96% 656/685 [2:26:55<06:30, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:47:07] Energy consumed for RAM : 0.027724 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:47:07] Energy consumed for all GPUs : 0.184676 kWh. Total GPU Power : 69.685 W\n",
            "[codecarbon INFO @ 15:47:07] Energy consumed for all CPUs : 0.123579 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:47:07] 0.335979 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 96% 657/685 [2:27:08<06:16, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:47:22] Energy consumed for RAM : 0.027764 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:47:22] Energy consumed for all GPUs : 0.184975 kWh. Total GPU Power : 71.983 W\n",
            "[codecarbon INFO @ 15:47:22] Energy consumed for all CPUs : 0.123756 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:47:22] 0.336495 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 96% 658/685 [2:27:22<06:02, 13.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:47:37] Energy consumed for RAM : 0.027804 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:47:37] Energy consumed for all GPUs : 0.185263 kWh. Total GPU Power : 69.142 W\n",
            "[codecarbon INFO @ 15:47:37] Energy consumed for all CPUs : 0.123933 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:47:37] 0.336999 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 96% 659/685 [2:27:35<05:49, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:47:52] Energy consumed for RAM : 0.027844 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:47:52] Energy consumed for all GPUs : 0.185571 kWh. Total GPU Power : 74.128 W\n",
            "[codecarbon INFO @ 15:47:52] Energy consumed for all CPUs : 0.124110 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:47:52] 0.337525 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 96% 660/685 [2:27:49<05:36, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:48:07] Energy consumed for RAM : 0.027883 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:48:07] Energy consumed for all GPUs : 0.185886 kWh. Total GPU Power : 75.642 W\n",
            "[codecarbon INFO @ 15:48:07] Energy consumed for all CPUs : 0.124287 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:48:07] 0.338056 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 97% 662/685 [2:28:16<05:09, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:48:22] Energy consumed for RAM : 0.027923 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:48:22] Energy consumed for all GPUs : 0.186187 kWh. Total GPU Power : 72.32000000000001 W\n",
            "[codecarbon INFO @ 15:48:22] Energy consumed for all CPUs : 0.124464 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:48:22] 0.338574 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 97% 663/685 [2:28:29<04:55, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:48:37] Energy consumed for RAM : 0.027963 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:48:37] Energy consumed for all GPUs : 0.186445 kWh. Total GPU Power : 61.991 W\n",
            "[codecarbon INFO @ 15:48:37] Energy consumed for all CPUs : 0.124641 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:48:37] 0.339049 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 97% 664/685 [2:28:42<04:42, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:48:52] Energy consumed for RAM : 0.028002 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:48:52] Energy consumed for all GPUs : 0.186741 kWh. Total GPU Power : 71.051 W\n",
            "[codecarbon INFO @ 15:48:52] Energy consumed for all CPUs : 0.124818 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:48:52] 0.339561 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 97% 665/685 [2:28:56<04:28, 13.44s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:49:07] Energy consumed for RAM : 0.028042 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:49:07] Energy consumed for all GPUs : 0.187010 kWh. Total GPU Power : 64.729 W\n",
            "[codecarbon INFO @ 15:49:07] Energy consumed for all CPUs : 0.124995 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:49:07] 0.340047 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 97% 666/685 [2:29:09<04:15, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:49:22] Energy consumed for RAM : 0.028082 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:49:22] Energy consumed for all GPUs : 0.187300 kWh. Total GPU Power : 69.685 W\n",
            "[codecarbon INFO @ 15:49:22] Energy consumed for all CPUs : 0.125172 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:49:22] 0.340554 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 97% 667/685 [2:29:23<04:02, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:49:37] Energy consumed for RAM : 0.028122 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:49:37] Energy consumed for all GPUs : 0.187599 kWh. Total GPU Power : 71.876 W\n",
            "[codecarbon INFO @ 15:49:37] Energy consumed for all CPUs : 0.125349 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:49:37] 0.341070 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 98% 668/685 [2:29:36<03:48, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:49:52] Energy consumed for RAM : 0.028161 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:49:52] Energy consumed for all GPUs : 0.187899 kWh. Total GPU Power : 72.027 W\n",
            "[codecarbon INFO @ 15:49:52] Energy consumed for all CPUs : 0.125526 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:49:52] 0.341586 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 98% 669/685 [2:29:50<03:35, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:50:07] Energy consumed for RAM : 0.028201 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:50:07] Energy consumed for all GPUs : 0.188221 kWh. Total GPU Power : 77.299 W\n",
            "[codecarbon INFO @ 15:50:07] Energy consumed for all CPUs : 0.125703 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:50:07] 0.342125 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 98% 670/685 [2:30:03<03:21, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:50:22] Energy consumed for RAM : 0.028241 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:50:22] Energy consumed for all GPUs : 0.188535 kWh. Total GPU Power : 75.68900000000001 W\n",
            "[codecarbon INFO @ 15:50:22] Energy consumed for all CPUs : 0.125881 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:50:22] 0.342657 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 98% 672/685 [2:30:30<02:54, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:50:37] Energy consumed for RAM : 0.028280 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:50:37] Energy consumed for all GPUs : 0.188841 kWh. Total GPU Power : 73.446 W\n",
            "[codecarbon INFO @ 15:50:37] Energy consumed for all CPUs : 0.126058 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:50:37] 0.343179 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 98% 673/685 [2:30:44<02:41, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:50:52] Energy consumed for RAM : 0.028320 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:50:52] Energy consumed for all GPUs : 0.189134 kWh. Total GPU Power : 70.412 W\n",
            "[codecarbon INFO @ 15:50:52] Energy consumed for all CPUs : 0.126235 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:50:52] 0.343689 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 98% 674/685 [2:30:57<02:27, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:51:07] Energy consumed for RAM : 0.028360 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:51:07] Energy consumed for all GPUs : 0.189451 kWh. Total GPU Power : 76.227 W\n",
            "[codecarbon INFO @ 15:51:07] Energy consumed for all CPUs : 0.126412 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:51:07] 0.344223 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 99% 675/685 [2:31:10<02:14, 13.45s/it]\r                                       \r{'loss': 0.9644, 'learning_rate': 3.5714285714285714e-06, 'epoch': 4.93}\n",
            "\r 99% 675/685 [2:31:10<02:14, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:51:22] Energy consumed for RAM : 0.028400 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:51:22] Energy consumed for all GPUs : 0.189770 kWh. Total GPU Power : 76.46900000000001 W\n",
            "[codecarbon INFO @ 15:51:22] Energy consumed for all CPUs : 0.126589 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:51:22] 0.344758 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 99% 676/685 [2:31:24<02:01, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:51:37] Energy consumed for RAM : 0.028439 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:51:37] Energy consumed for all GPUs : 0.190093 kWh. Total GPU Power : 77.786 W\n",
            "[codecarbon INFO @ 15:51:37] Energy consumed for all CPUs : 0.126766 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:51:37] 0.345298 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 99% 677/685 [2:31:37<01:47, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:51:52] Energy consumed for RAM : 0.028479 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:51:52] Energy consumed for all GPUs : 0.190352 kWh. Total GPU Power : 62.186 W\n",
            "[codecarbon INFO @ 15:51:52] Energy consumed for all CPUs : 0.126943 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:51:52] 0.345774 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 99% 678/685 [2:31:51<01:34, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:52:07] Energy consumed for RAM : 0.028519 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:52:07] Energy consumed for all GPUs : 0.190649 kWh. Total GPU Power : 71.34400000000001 W\n",
            "[codecarbon INFO @ 15:52:07] Energy consumed for all CPUs : 0.127120 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:52:07] 0.346288 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 99% 679/685 [2:32:04<01:20, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:52:22] Energy consumed for RAM : 0.028558 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:52:22] Energy consumed for all GPUs : 0.190956 kWh. Total GPU Power : 73.836 W\n",
            "[codecarbon INFO @ 15:52:22] Energy consumed for all CPUs : 0.127297 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:52:22] 0.346812 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r 99% 680/685 [2:32:18<01:07, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:52:37] Energy consumed for RAM : 0.028598 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:52:37] Energy consumed for all GPUs : 0.191291 kWh. Total GPU Power : 80.318 W\n",
            "[codecarbon INFO @ 15:52:37] Energy consumed for all CPUs : 0.127474 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:52:37] 0.347363 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100% 682/685 [2:32:45<00:40, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:52:52] Energy consumed for RAM : 0.028638 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:52:52] Energy consumed for all GPUs : 0.191554 kWh. Total GPU Power : 63.262 W\n",
            "[codecarbon INFO @ 15:52:52] Energy consumed for all CPUs : 0.127651 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:52:52] 0.347843 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r100% 683/685 [2:32:58<00:26, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:53:07] Energy consumed for RAM : 0.028678 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:53:07] Energy consumed for all GPUs : 0.191885 kWh. Total GPU Power : 79.394 W\n",
            "[codecarbon INFO @ 15:53:07] Energy consumed for all CPUs : 0.127828 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:53:07] 0.348390 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r100% 684/685 [2:33:12<00:13, 13.45s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:53:22] Energy consumed for RAM : 0.028717 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:53:22] Energy consumed for all GPUs : 0.192158 kWh. Total GPU Power : 65.609 W\n",
            "[codecarbon INFO @ 15:53:22] Energy consumed for all CPUs : 0.128005 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:53:22] 0.348880 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'train_runtime': 9206.0184, 'train_samples_per_second': 0.298, 'train_steps_per_second': 0.074, 'train_loss': 1.136419184886626, 'epoch': 5.0}\n",
            "100% 685/685 [2:33:26<00:00, 13.44s/it]\n",
            "> \u001b[1mINFO    Finished training, saving model...\u001b[0m\n",
            "> \u001b[1mINFO    Merging adapter weights...\u001b[0m\n",
            "> \u001b[1mINFO    Loading adapter...\u001b[0m\n",
            "Loading checkpoint shards:   0% 0/14 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:53:37] Energy consumed for RAM : 0.028757 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:53:37] Energy consumed for all GPUs : 0.192288 kWh. Total GPU Power : 31.301000000000002 W\n",
            "[codecarbon INFO @ 15:53:37] Energy consumed for all CPUs : 0.128182 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:53:37] 0.349227 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  21% 3/14 [00:18<01:07,  6.13s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:53:52] Energy consumed for RAM : 0.028797 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:53:52] Energy consumed for all GPUs : 0.192416 kWh. Total GPU Power : 30.727 W\n",
            "[codecarbon INFO @ 15:53:52] Energy consumed for all CPUs : 0.128359 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:53:52] 0.349571 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  36% 5/14 [00:30<00:55,  6.18s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:54:07] Energy consumed for RAM : 0.028836 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:54:07] Energy consumed for all GPUs : 0.192544 kWh. Total GPU Power : 30.808000000000003 W\n",
            "[codecarbon INFO @ 15:54:07] Energy consumed for all CPUs : 0.128536 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:54:07] 0.349916 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  57% 8/14 [00:49<00:37,  6.29s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:54:22] Energy consumed for RAM : 0.028876 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:54:22] Energy consumed for all GPUs : 0.192672 kWh. Total GPU Power : 30.808000000000003 W\n",
            "[codecarbon INFO @ 15:54:22] Energy consumed for all CPUs : 0.128713 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:54:22] 0.350261 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  71% 10/14 [01:02<00:25,  6.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:54:37] Energy consumed for RAM : 0.028916 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:54:37] Energy consumed for all GPUs : 0.192800 kWh. Total GPU Power : 30.71 W\n",
            "[codecarbon INFO @ 15:54:37] Energy consumed for all CPUs : 0.128890 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:54:37] 0.350606 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards:  86% 12/14 [01:15<00:12,  6.27s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:54:52] Energy consumed for RAM : 0.028956 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:54:52] Energy consumed for all GPUs : 0.192927 kWh. Total GPU Power : 30.513 W\n",
            "[codecarbon INFO @ 15:54:52] Energy consumed for all CPUs : 0.129067 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:54:52] 0.350950 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading checkpoint shards: 100% 14/14 [01:26<00:00,  6.16s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:55:07] Energy consumed for RAM : 0.028995 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:55:07] Energy consumed for all GPUs : 0.193050 kWh. Total GPU Power : 29.445000000000004 W\n",
            "[codecarbon INFO @ 15:55:07] Energy consumed for all CPUs : 0.129244 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:55:07] 0.351289 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:55:22] Energy consumed for RAM : 0.029035 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:55:22] Energy consumed for all GPUs : 0.193170 kWh. Total GPU Power : 29.050000000000004 W\n",
            "[codecarbon INFO @ 15:55:22] Energy consumed for all CPUs : 0.129421 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:55:22] 0.351627 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Saving target model...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:55:37] Energy consumed for RAM : 0.029075 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:55:37] Energy consumed for all GPUs : 0.193292 kWh. Total GPU Power : 29.231000000000005 W\n",
            "[codecarbon INFO @ 15:55:37] Energy consumed for all CPUs : 0.129598 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:55:37] 0.351965 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:55:52] Energy consumed for RAM : 0.029114 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:55:52] Energy consumed for all GPUs : 0.193414 kWh. Total GPU Power : 29.330000000000002 W\n",
            "[codecarbon INFO @ 15:55:52] Energy consumed for all CPUs : 0.129775 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:55:52] 0.352304 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:56:07] Energy consumed for RAM : 0.029154 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:56:07] Energy consumed for all GPUs : 0.193534 kWh. Total GPU Power : 28.853000000000005 W\n",
            "[codecarbon INFO @ 15:56:07] Energy consumed for all CPUs : 0.129952 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:56:07] 0.352641 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:56:22] Energy consumed for RAM : 0.029194 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:56:22] Energy consumed for all GPUs : 0.193654 kWh. Total GPU Power : 28.853000000000005 W\n",
            "[codecarbon INFO @ 15:56:22] Energy consumed for all CPUs : 0.130130 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:56:22] 0.352978 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:56:37] Energy consumed for RAM : 0.029234 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:56:37] Energy consumed for all GPUs : 0.193775 kWh. Total GPU Power : 29.034000000000002 W\n",
            "[codecarbon INFO @ 15:56:37] Energy consumed for all CPUs : 0.130306 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:56:37] 0.353315 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> \u001b[1mINFO    Pushing model to hub...\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:56:52] Energy consumed for RAM : 0.029273 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:56:52] Energy consumed for all GPUs : 0.193895 kWh. Total GPU Power : 28.64 W\n",
            "[codecarbon INFO @ 15:56:52] Energy consumed for all CPUs : 0.130484 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:56:52] 0.353651 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:57:07] Energy consumed for RAM : 0.029313 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:57:07] Energy consumed for all GPUs : 0.194013 kWh. Total GPU Power : 28.344 W\n",
            "[codecarbon INFO @ 15:57:07] Energy consumed for all CPUs : 0.130661 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:57:07] 0.353986 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:57:22] Energy consumed for RAM : 0.029353 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:57:22] Energy consumed for all GPUs : 0.194129 kWh. Total GPU Power : 27.95 W\n",
            "[codecarbon INFO @ 15:57:22] Energy consumed for all CPUs : 0.130838 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:57:22] 0.354319 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:57:37] Energy consumed for RAM : 0.029393 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:57:37] Energy consumed for all GPUs : 0.194244 kWh. Total GPU Power : 27.753 W\n",
            "[codecarbon INFO @ 15:57:37] Energy consumed for all CPUs : 0.131015 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:57:37] 0.354652 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 15:57:52] Energy consumed for RAM : 0.029432 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:57:52] Energy consumed for all GPUs : 0.194359 kWh. Total GPU Power : 27.571 W\n",
            "[codecarbon INFO @ 15:57:52] Energy consumed for all CPUs : 0.131192 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:57:52] 0.354983 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\radapter_model.bin:   0% 0.00/67.2M [00:00<?, ?B/s]\n",
            "\radapter_model.bin:   0% 0.00/67.2M [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\roptimizer.pt:   0% 0.00/134M [00:00<?, ?B/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\rUpload 13 LFS files:   0% 0/13 [00:00<?, ?it/s]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model.bin:   0% 0.00/443 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "rng_state.pth:   0% 0.00/14.6k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "adapter_model.bin:   0% 8.19k/67.2M [00:00<2:08:49, 8.69kB/s]\n",
            "\n",
            "optimizer.pt:   0% 8.19k/134M [00:00<4:15:42, 8.75kB/s]\u001b[A\u001b[A\n",
            "adapter_model.bin:   0% 8.19k/67.2M [00:00<2:09:50, 8.62kB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model.bin: 100% 443/443 [00:01<00:00, 424B/s]\n",
            "adapter_model.bin:   0% 180k/67.2M [00:01<05:14, 213kB/s]    \n",
            "\n",
            "optimizer.pt:   0% 180k/134M [00:01<10:26, 214kB/s]    \u001b[A\u001b[A\n",
            "rng_state.pth: 100% 14.6k/14.6k [00:01<00:00, 12.3kB/s]\n",
            "\n",
            "adapter_model.bin:   1% 451k/67.2M [00:01<02:08, 521kB/s]\n",
            "\n",
            "optimizer.pt:   0% 516k/134M [00:01<03:39, 609kB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "scheduler.pt:   0% 0.00/627 [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "adapter_model.bin:   3% 1.79M/67.2M [00:01<00:26, 2.45MB/s]\n",
            "\n",
            "optimizer.pt:   2% 2.24M/134M [00:01<00:45, 2.90MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "scheduler.pt: 100% 627/627 [00:00<00:00, 3.96kB/s]\n",
            "\n",
            "\n",
            "optimizer.pt:   4% 5.10M/134M [00:01<00:17, 7.24MB/s]\u001b[A\u001b[A\n",
            "adapter_model.bin:   7% 4.60M/67.2M [00:01<00:10, 5.78MB/s]\n",
            "\n",
            "optimizer.pt:   5% 6.68M/134M [00:01<00:14, 8.88MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "adapter_model.bin:  13% 8.40M/67.2M [00:01<00:05, 11.4MB/s]\n",
            "\n",
            "\n",
            "\n",
            "training_args.bin:   0% 0.00/4.03k [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:   6% 8.12M/134M [00:01<00:12, 10.1MB/s]\u001b[A\u001b[A\n",
            "adapter_model.bin:  11% 7.33M/67.2M [00:01<00:06, 8.86MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "training_args.bin: 100% 4.03k/4.03k [00:00<00:00, 35.1kB/s]\n",
            "\n",
            "adapter_model.bin:  16% 11.0M/67.2M [00:01<00:04, 14.0MB/s]\u001b[A\n",
            "\n",
            "adapter_model.bin:  19% 12.4M/67.2M [00:01<00:03, 15.2MB/s]\n",
            "\n",
            "optimizer.pt:  12% 15.7M/134M [00:02<00:06, 18.3MB/s]\u001b[A\u001b[A\n",
            "adapter_model.bin:  23% 15.3M/67.2M [00:02<00:03, 17.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 0.00/9.98G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:58:07] Energy consumed for RAM : 0.029472 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:58:07] Energy consumed for all GPUs : 0.194474 kWh. Total GPU Power : 27.571 W\n",
            "[codecarbon INFO @ 15:58:07] Energy consumed for all CPUs : 0.131369 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:58:07] 0.355315 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\radapter_model.bin:  24% 16.0M/67.2M [00:02<00:03, 14.9MB/s]\n",
            "\n",
            "\roptimizer.pt:  13% 17.8M/134M [00:02<00:07, 16.4MB/s]\u001b[A\u001b[A\radapter_model.bin:  30% 20.1M/67.2M [00:02<00:02, 19.5MB/s]\n",
            "\radapter_model.bin:  26% 17.4M/67.2M [00:02<00:03, 14.9MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:   0% 180k/9.98G [00:00<2:46:31, 998kB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\roptimizer.pt:  16% 21.9M/134M [00:02<00:05, 21.9MB/s]\u001b[A\u001b[A\radapter_model.bin:  35% 23.8M/67.2M [00:02<00:01, 23.2MB/s]\n",
            "\radapter_model.bin:  30% 20.3M/67.2M [00:02<00:02, 17.7MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 553kB/s]\n",
            "\n",
            "\n",
            "adapter_model.bin:  41% 27.8M/67.2M [00:02<00:01, 26.9MB/s]\n",
            "adapter_model.bin:  37% 24.6M/67.2M [00:02<00:01, 22.6MB/s]\u001b[A\n",
            "\n",
            "optimizer.pt:  21% 28.2M/134M [00:02<00:04, 22.8MB/s]\u001b[A\u001b[A\n",
            "adapter_model.bin:  47% 31.3M/67.2M [00:02<00:01, 26.1MB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 713k/9.98G [00:00<2:06:35, 1.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 0.00/3.50G [00:00<?, ?B/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "adapter_model.bin:  51% 34.3M/67.2M [00:02<00:01, 22.0MB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 967k/9.98G [00:00<2:02:16, 1.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "adapter_model.bin:  57% 38.1M/67.2M [00:02<00:01, 25.4MB/s]\n",
            "\n",
            "adapter_model.bin:  61% 41.1M/67.2M [00:02<00:00, 26.4MB/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 1.22M/9.98G [00:00<1:59:36, 1.39MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "adapter_model.bin:  50% 33.2M/67.2M [00:03<00:02, 15.6MB/s]\u001b[A\n",
            "\n",
            "optimizer.pt:  30% 40.0M/134M [00:03<00:03, 26.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 606k/3.50G [00:00<36:31, 1.60MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "adapter_model.bin:  66% 44.4M/67.2M [00:03<00:00, 24.1MB/s]\n",
            "\n",
            "optimizer.pt:  32% 43.1M/134M [00:03<00:03, 26.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "adapter_model.bin:  71% 47.7M/67.2M [00:03<00:00, 25.7MB/s]\n",
            "\n",
            "optimizer.pt:  35% 46.6M/134M [00:03<00:03, 28.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 868k/3.50G [00:00<38:40, 1.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "adapter_model.bin:  63% 42.1M/67.2M [00:03<00:01, 22.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 1.86M/9.98G [00:01<1:40:41, 1.65MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "adapter_model.bin:  75% 50.4M/67.2M [00:03<00:00, 21.3MB/s]\n",
            "adapter_model.bin:  71% 47.5M/67.2M [00:03<00:00, 25.5MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 2.18M/9.98G [00:01<1:38:33, 1.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "adapter_model.bin:  80% 53.7M/67.2M [00:03<00:00, 23.8MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 1.38M/3.50G [00:00<40:59, 1.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "adapter_model.bin:  85% 56.9M/67.2M [00:03<00:00, 25.8MB/s]\n",
            "adapter_model.bin:  75% 50.3M/67.2M [00:03<00:00, 21.3MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 2.56M/9.98G [00:01<1:33:26, 1.78MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  41% 55.6M/134M [00:03<00:03, 23.5MB/s]\u001b[A\u001b[A\n",
            "adapter_model.bin:  90% 60.4M/67.2M [00:03<00:00, 25.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 1.70M/3.50G [00:01<38:07, 1.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  44% 59.6M/134M [00:03<00:02, 27.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 3.01M/9.98G [00:01<1:23:11, 2.00MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "adapter_model.bin:  85% 56.9M/67.2M [00:03<00:00, 23.6MB/s]\u001b[A\n",
            "\n",
            "optimizer.pt:  47% 63.1M/134M [00:03<00:02, 27.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "adapter_model.bin:  95% 64.0M/67.2M [00:04<00:00, 21.1MB/s]\n",
            "adapter_model.bin:  90% 60.2M/67.2M [00:04<00:00, 24.6MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 3.45M/9.98G [00:02<1:16:30, 2.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "adapter_model.bin:  95% 63.6M/67.2M [00:04<00:00, 26.1MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 2.46M/3.50G [00:01<31:21, 1.86MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  49% 66.1M/134M [00:04<00:03, 21.5MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 3.90M/9.98G [00:02<1:11:33, 2.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  52% 70.0M/134M [00:04<00:02, 25.2MB/s]\u001b[A\u001b[A\n",
            "adapter_model.bin:  99% 66.4M/67.2M [00:04<00:00, 21.8MB/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 2.90M/3.50G [00:01<28:21, 2.06MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "adapter_model.bin: 100% 67.2M/67.2M [00:04<00:00, 15.2MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 4.41M/9.98G [00:02<1:08:44, 2.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 3.35M/3.50G [00:01<26:53, 2.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "adapter_model.bin: 100% 67.2M/67.2M [00:04<00:00, 14.5MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 5.17M/9.98G [00:02<55:53, 2.97MB/s]  \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "events.out.tfevents.1690377605.b2cc94e105c6.30018.0:   0% 0.00/8.71k [00:00<?, ?B/s]\n",
            "\n",
            "\n",
            "\n",
            "events.out.tfevents.1690377605.b2cc94e105c6.30018.0: 100% 8.71k/8.71k [00:00<00:00, 59.0kB/s]\n",
            "\n",
            "\n",
            "optimizer.pt:  60% 80.0M/134M [00:04<00:03, 17.0MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 4.43M/3.50G [00:02<22:11, 2.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "tokenizer.model:   0% 0.00/500k [00:00<?, ?B/s]\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 6.50M/9.98G [00:02<48:37, 3.42MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  62% 83.7M/134M [00:04<00:02, 20.5MB/s]\u001b[A\u001b[A\n",
            "training_args.bin:   0% 0.00/4.03k [00:00<?, ?B/s]\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 5.07M/3.50G [00:02<20:06, 2.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "tokenizer.model: 100% 500k/500k [00:00<00:00, 2.16MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "training_args.bin: 100% 4.03k/4.03k [00:00<00:00, 28.0kB/s]\n",
            "\n",
            "\n",
            "optimizer.pt:  68% 91.9M/134M [00:05<00:01, 28.2MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 5.77M/3.50G [00:02<18:08, 3.21MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 8.29M/9.98G [00:03<38:58, 4.26MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  71% 95.5M/134M [00:05<00:01, 27.1MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 9.18M/9.98G [00:03<32:21, 5.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 6.53M/3.50G [00:02<16:29, 3.53MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  73% 98.6M/134M [00:05<00:01, 21.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 10.1M/9.98G [00:03<31:22, 5.29MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 7.42M/3.50G [00:02<14:36, 3.99MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  76% 102M/134M [00:05<00:01, 24.4MB/s] \u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 11.3M/9.98G [00:03<29:15, 5.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 8.31M/3.50G [00:03<13:30, 4.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  79% 106M/134M [00:05<00:01, 24.7MB/s]\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  82% 110M/134M [00:05<00:00, 28.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 12.6M/9.98G [00:03<26:25, 6.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 9.33M/3.50G [00:03<12:15, 4.74MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 14.1M/9.98G [00:04<24:03, 6.90MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 10.5M/3.50G [00:03<11:19, 5.13MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  85% 114M/134M [00:06<00:00, 22.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  88% 118M/134M [00:06<00:00, 26.9MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 15.7M/9.98G [00:04<22:03, 7.52MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 11.8M/3.50G [00:03<10:12, 5.70MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  91% 122M/134M [00:06<00:00, 25.8MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 13.2M/3.50G [00:03<09:11, 6.32MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  94% 127M/134M [00:06<00:00, 30.3MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 14.6M/3.50G [00:03<08:33, 6.79MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 16.4M/9.98G [00:04<35:53, 4.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt:  97% 130M/134M [00:06<00:00, 23.4MB/s]\u001b[A\u001b[A\n",
            "\n",
            "optimizer.pt: 100% 134M/134M [00:06<00:00, 26.6MB/s]\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 20.0M/9.98G [00:04<19:59, 8.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 21.8M/9.98G [00:05<18:51, 8.80MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   0% 16.0M/3.50G [00:04<12:55, 4.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "optimizer.pt: 100% 134M/134M [00:07<00:00, 18.4MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 20.0M/3.50G [00:04<07:00, 8.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 26.0M/9.98G [00:05<16:01, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 21.8M/3.50G [00:04<06:39, 8.71MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 28.5M/9.98G [00:05<15:09, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "Upload 13 LFS files:  23% 3/13 [00:07<00:22,  2.29s/it]\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 31.4M/9.98G [00:05<11:32, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 23.7M/3.50G [00:05<06:18, 9.17MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 27.2M/3.50G [00:05<05:25, 10.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 33.1M/9.98G [00:05<16:09, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 37.1M/9.98G [00:06<10:56, 15.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 30.9M/3.50G [00:05<04:26, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 39.4M/9.98G [00:06<11:13, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 32.3M/3.50G [00:05<05:41, 10.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 43.3M/9.98G [00:06<10:11, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 36.3M/3.50G [00:05<03:56, 14.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 47.4M/9.98G [00:06<08:59, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 39.4M/3.50G [00:06<03:42, 15.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   0% 49.5M/9.98G [00:06<10:17, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 43.0M/3.50G [00:06<03:24, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 53.6M/9.98G [00:06<07:55, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 45.9M/3.50G [00:06<03:05, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 56.3M/9.98G [00:07<07:26, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 59.8M/9.98G [00:07<07:47, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 48.0M/3.50G [00:06<03:53, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 62.9M/9.98G [00:07<07:04, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   1% 52.4M/3.50G [00:06<02:51, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 56.8M/3.50G [00:06<02:17, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 65.5M/9.98G [00:07<08:49, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 68.4M/9.98G [00:07<07:54, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 59.9M/3.50G [00:06<02:37, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 72.9M/9.98G [00:07<06:15, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 76.3M/9.98G [00:07<06:36, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 64.0M/3.50G [00:07<03:02, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 67.7M/3.50G [00:07<02:35, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 72.8M/3.50G [00:07<02:05, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 76.1M/3.50G [00:07<02:00, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 79.3M/3.50G [00:07<02:05, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 82.4M/3.50G [00:07<02:28, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   2% 85.7M/3.50G [00:08<02:17, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 80.0M/9.98G [00:08<17:02, 9.68MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 88.9M/3.50G [00:08<02:24, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 94.0M/3.50G [00:08<01:58, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 84.1M/9.98G [00:08<13:50, 11.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 87.8M/9.98G [00:09<10:57, 15.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 97.1M/3.50G [00:08<02:42, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 91.7M/9.98G [00:09<10:15, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 101M/3.50G [00:08<02:18, 24.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 95.8M/9.98G [00:09<08:16, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 105M/3.50G [00:08<02:17, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 98.7M/9.98G [00:09<08:55, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 110M/3.50G [00:08<02:00, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 103M/9.98G [00:09<07:15, 22.6MB/s] \u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 106M/9.98G [00:09<07:41, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 113M/3.50G [00:09<02:34, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 110M/9.98G [00:09<06:33, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 118M/3.50G [00:09<02:12, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   3% 121M/3.50G [00:09<02:18, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 113M/9.98G [00:10<08:41, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 124M/3.50G [00:09<02:05, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 116M/9.98G [00:10<07:47, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 128M/3.50G [00:09<02:00, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 120M/9.98G [00:10<06:22, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 131M/3.50G [00:09<02:12, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 134M/3.50G [00:09<02:11, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 124M/9.98G [00:10<06:43, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 127M/9.98G [00:10<06:20, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 137M/3.50G [00:10<02:20, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 141M/3.50G [00:10<02:00, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 130M/9.98G [00:10<07:01, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 133M/9.98G [00:10<06:34, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 137M/9.98G [00:11<05:41, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 144M/3.50G [00:10<02:40, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 148M/3.50G [00:10<02:14, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 141M/9.98G [00:11<06:26, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 153M/3.50G [00:10<01:50, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 144M/9.98G [00:11<06:16, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   4% 156M/3.50G [00:10<01:50, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   1% 147M/9.98G [00:11<07:40, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 160M/3.50G [00:10<01:57, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 163M/3.50G [00:11<02:10, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 151M/9.98G [00:11<07:34, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 166M/3.50G [00:11<02:10, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 154M/9.98G [00:11<06:52, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 169M/3.50G [00:11<01:56, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 158M/9.98G [00:11<05:43, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 172M/3.50G [00:11<02:11, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 176M/3.50G [00:11<02:03, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 162M/9.98G [00:12<07:48, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 165M/9.98G [00:12<06:45, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 179M/3.50G [00:11<02:23, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 170M/9.98G [00:12<05:40, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 182M/3.50G [00:11<02:16, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 173M/9.98G [00:12<06:22, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 185M/3.50G [00:11<02:20, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   5% 190M/3.50G [00:12<01:55, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 176M/9.98G [00:12<08:10, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 180M/9.98G [00:12<07:03, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 193M/3.50G [00:12<02:35, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 184M/9.98G [00:12<05:47, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 197M/3.50G [00:12<02:06, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 188M/9.98G [00:13<05:16, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 201M/3.50G [00:12<02:00, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 192M/9.98G [00:13<06:05, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 204M/3.50G [00:12<02:07, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 195M/9.98G [00:13<06:37, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 198M/9.98G [00:13<06:18, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 208M/3.50G [00:12<02:39, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 212M/3.50G [00:13<02:18, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 202M/9.98G [00:13<06:36, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 216M/3.50G [00:13<01:56, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 207M/9.98G [00:13<06:05, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 220M/3.50G [00:13<02:01, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 209M/9.98G [00:14<08:07, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 213M/9.98G [00:14<06:50, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   6% 224M/3.50G [00:13<02:41, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 218M/9.98G [00:14<05:49, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 228M/3.50G [00:13<02:15, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 233M/3.50G [00:13<01:53, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 221M/9.98G [00:14<06:23, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 236M/3.50G [00:13<01:52, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 240M/3.50G [00:14<01:51, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 224M/9.98G [00:14<08:18, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 243M/3.50G [00:14<01:59, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 228M/9.98G [00:14<06:58, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 246M/3.50G [00:14<01:59, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 231M/9.98G [00:14<06:44, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:58:22] Energy consumed for RAM : 0.029512 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:58:22] Energy consumed for all GPUs : 0.194588 kWh. Total GPU Power : 27.374000000000002 W\n",
            "[codecarbon INFO @ 15:58:22] Energy consumed for all CPUs : 0.131546 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:58:22] 0.355646 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:   2% 235M/9.98G [00:14<05:37, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00002-of-00002.bin:   7% 249M/3.50G [00:14<02:09, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:   2% 239M/9.98G [00:15<05:15, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 254M/3.50G [00:14<01:49, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 243M/9.98G [00:15<06:04, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 257M/3.50G [00:14<02:11, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   2% 247M/9.98G [00:15<05:17, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   7% 262M/3.50G [00:14<01:53, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 250M/9.98G [00:15<06:18, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   8% 266M/3.50G [00:14<01:54, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 254M/9.98G [00:15<05:38, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   8% 271M/3.50G [00:15<01:50, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 257M/9.98G [00:15<07:37, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   8% 274M/3.50G [00:15<02:16, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 262M/9.98G [00:16<06:19, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   8% 278M/3.50G [00:15<02:09, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 265M/9.98G [00:16<06:10, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   8% 282M/3.50G [00:15<02:05, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 268M/9.98G [00:16<06:35, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   8% 287M/3.50G [00:15<01:58, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 272M/9.98G [00:16<07:16, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 276M/9.98G [00:16<06:14, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   8% 290M/3.50G [00:15<02:17, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 280M/9.98G [00:16<05:20, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   8% 294M/3.50G [00:16<02:04, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 284M/9.98G [00:16<05:41, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 298M/3.50G [00:16<02:03, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 303M/3.50G [00:16<01:56, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 288M/9.98G [00:17<08:05, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 292M/9.98G [00:17<06:49, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 296M/9.98G [00:17<05:50, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 306M/3.50G [00:16<02:49, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 300M/9.98G [00:17<05:58, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 310M/3.50G [00:16<02:49, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 314M/3.50G [00:17<02:19, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 304M/9.98G [00:17<07:11, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 317M/3.50G [00:17<02:29, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 308M/9.98G [00:17<06:13, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 313M/9.98G [00:17<05:14, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 320M/3.50G [00:17<02:52, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 316M/9.98G [00:18<05:42, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 324M/3.50G [00:17<02:19, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 329M/3.50G [00:17<01:57, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 320M/9.98G [00:18<06:36, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 324M/9.98G [00:18<05:50, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:   9% 332M/3.50G [00:17<02:03, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 328M/9.98G [00:18<05:05, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 336M/3.50G [00:17<01:52, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 332M/9.98G [00:18<05:29, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 339M/3.50G [00:18<02:15, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 342M/3.50G [00:18<02:12, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 336M/9.98G [00:18<07:17, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 345M/3.50G [00:18<02:16, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 340M/9.98G [00:19<06:18, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 350M/3.50G [00:18<01:52, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 344M/9.98G [00:19<05:24, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   3% 348M/9.98G [00:19<05:45, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 353M/3.50G [00:18<02:31, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 357M/3.50G [00:18<02:03, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 352M/9.98G [00:19<06:37, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 356M/9.98G [00:19<05:50, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 361M/3.50G [00:18<02:08, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 360M/9.98G [00:19<05:05, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  10% 366M/3.50G [00:19<01:48, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 364M/9.98G [00:19<05:29, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 369M/3.50G [00:19<02:26, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 368M/9.98G [00:20<06:50, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 372M/3.50G [00:19<02:13, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 372M/9.98G [00:20<06:08, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 375M/3.50G [00:19<02:09, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 376M/9.98G [00:20<05:15, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 380M/3.50G [00:19<01:54, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 380M/9.98G [00:20<04:58, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 383M/3.50G [00:19<01:51, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 384M/9.98G [00:20<05:31, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 386M/3.50G [00:20<02:15, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 387M/9.98G [00:20<05:43, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 390M/3.50G [00:20<02:03, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 390M/9.98G [00:20<05:39, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 394M/3.50G [00:20<02:00, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 394M/9.98G [00:20<05:57, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 398M/9.98G [00:21<05:26, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 399M/3.50G [00:20<01:53, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 401M/9.98G [00:21<06:24, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  11% 402M/3.50G [00:20<02:09, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 405M/9.98G [00:21<05:37, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 405M/3.50G [00:20<02:08, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 410M/9.98G [00:21<04:54, 32.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 409M/3.50G [00:20<01:51, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 413M/9.98G [00:21<05:28, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 412M/3.50G [00:21<01:59, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 416M/9.98G [00:21<07:26, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 416M/3.50G [00:21<02:32, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 420M/9.98G [00:21<06:20, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 420M/3.50G [00:21<02:05, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 424M/9.98G [00:22<05:40, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 425M/3.50G [00:21<01:47, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 428M/9.98G [00:22<05:48, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 428M/3.50G [00:21<01:50, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 431M/3.50G [00:21<01:50, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 432M/9.98G [00:22<07:16, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  12% 434M/3.50G [00:21<02:08, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 436M/9.98G [00:22<06:14, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 438M/3.50G [00:22<01:58, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 441M/9.98G [00:22<05:18, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 442M/3.50G [00:22<01:57, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 444M/9.98G [00:22<05:43, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 447M/3.50G [00:22<01:38, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   4% 448M/9.98G [00:23<07:49, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 450M/3.50G [00:22<02:14, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 452M/9.98G [00:23<06:37, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 456M/9.98G [00:23<05:39, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 454M/3.50G [00:22<02:19, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 458M/3.50G [00:22<02:01, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 460M/9.98G [00:23<05:51, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 463M/3.50G [00:22<01:53, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 464M/9.98G [00:23<06:57, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 466M/3.50G [00:23<02:11, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 468M/9.98G [00:23<06:01, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 471M/9.98G [00:23<05:49, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  13% 470M/3.50G [00:23<02:09, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 476M/9.98G [00:24<05:01, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 475M/3.50G [00:23<01:45, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 479M/9.98G [00:24<05:00, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 478M/3.50G [00:23<01:53, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 483M/9.98G [00:24<06:45, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 481M/3.50G [00:23<02:24, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 485M/9.98G [00:24<06:30, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 484M/3.50G [00:23<02:16, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 489M/9.98G [00:24<06:31, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 487M/3.50G [00:24<02:01, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 493M/9.98G [00:24<05:30, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 491M/3.50G [00:24<01:53, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 494M/3.50G [00:24<01:46, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 496M/9.98G [00:24<06:42, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 500M/9.98G [00:25<06:06, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 503M/9.98G [00:25<05:36, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 497M/3.50G [00:24<02:28, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 507M/9.98G [00:25<05:12, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 500M/3.50G [00:24<02:18, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 511M/9.98G [00:25<04:42, 33.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  14% 505M/3.50G [00:24<01:58, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 510M/3.50G [00:24<01:43, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 513M/3.50G [00:25<02:27, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 517M/3.50G [00:25<02:02, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 521M/3.50G [00:25<02:04, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 515M/9.98G [00:26<13:01, 12.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 526M/3.50G [00:25<01:44, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 518M/9.98G [00:26<12:21, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 521M/9.98G [00:26<09:59, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 529M/3.50G [00:25<02:15, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 524M/9.98G [00:26<09:35, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 532M/3.50G [00:25<02:07, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 536M/3.50G [00:26<01:53, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  15% 540M/3.50G [00:26<01:49, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 528M/9.98G [00:26<10:02, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 544M/3.50G [00:26<01:43, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 532M/9.98G [00:26<08:18, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 536M/9.98G [00:27<06:29, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 547M/3.50G [00:26<01:53, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 549M/3.50G [00:26<01:51, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 540M/9.98G [00:27<06:34, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 553M/3.50G [00:26<01:47, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 556M/3.50G [00:26<01:42, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 544M/9.98G [00:27<07:48, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 559M/3.50G [00:26<01:48, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   5% 548M/9.98G [00:27<07:04, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 552M/9.98G [00:27<05:59, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 562M/3.50G [00:27<02:14, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 556M/9.98G [00:27<05:14, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 566M/3.50G [00:27<02:02, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 560M/9.98G [00:27<05:42, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 569M/3.50G [00:27<02:05, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 574M/3.50G [00:27<01:42, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 563M/9.98G [00:28<06:44, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 566M/9.98G [00:28<06:24, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  16% 577M/3.50G [00:27<02:00, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 581M/3.50G [00:27<01:43, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 569M/9.98G [00:28<06:44, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 585M/3.50G [00:27<01:41, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 572M/9.98G [00:28<06:33, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 575M/9.98G [00:28<06:00, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 589M/3.50G [00:28<01:41, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 578M/9.98G [00:28<07:29, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 592M/3.50G [00:28<02:09, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 582M/9.98G [00:28<06:21, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 596M/3.50G [00:28<01:53, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 585M/9.98G [00:28<06:20, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 601M/3.50G [00:28<01:38, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 588M/9.98G [00:29<06:07, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 604M/3.50G [00:28<01:51, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 592M/9.98G [00:29<08:04, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 607M/3.50G [00:28<02:08, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 596M/9.98G [00:29<06:42, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 600M/9.98G [00:29<05:36, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  17% 610M/3.50G [00:29<02:42, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 604M/9.98G [00:29<05:30, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:58:37] Energy consumed for RAM : 0.029551 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:58:37] Energy consumed for all GPUs : 0.194702 kWh. Total GPU Power : 27.457 W\n",
            "[codecarbon INFO @ 15:58:37] Energy consumed for all CPUs : 0.131723 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:58:37] 0.355977 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00002-of-00002.bin:  18% 613M/3.50G [00:29<02:32, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 607M/9.98G [00:29<06:00, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 619M/3.50G [00:29<02:12, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 622M/3.50G [00:29<02:02, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 610M/9.98G [00:30<08:56, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 614M/9.98G [00:30<07:14, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 624M/3.50G [00:29<02:45, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 618M/9.98G [00:30<07:04, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 629M/3.50G [00:29<02:06, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 622M/9.98G [00:30<05:42, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 633M/3.50G [00:30<02:06, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 637M/3.50G [00:30<01:55, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 626M/9.98G [00:30<07:05, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 629M/9.98G [00:30<06:43, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 633M/9.98G [00:30<05:31, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 640M/3.50G [00:30<02:40, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 636M/9.98G [00:31<06:04, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  18% 644M/3.50G [00:30<02:09, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  19% 649M/3.50G [00:30<01:59, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 640M/9.98G [00:31<07:52, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  19% 653M/3.50G [00:30<01:50, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   6% 644M/9.98G [00:31<06:36, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 649M/9.98G [00:31<05:31, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 652M/9.98G [00:31<05:17, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  19% 656M/3.50G [00:31<02:16, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  19% 660M/3.50G [00:31<01:52, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 656M/9.98G [00:31<05:37, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  19% 665M/3.50G [00:31<01:50, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 659M/9.98G [00:32<06:14, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  19% 669M/3.50G [00:31<01:39, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 662M/9.98G [00:32<05:52, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 665M/9.98G [00:32<05:45, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  19% 672M/3.50G [00:31<02:07, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 668M/9.98G [00:32<06:04, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  19% 677M/3.50G [00:31<01:45, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 672M/9.98G [00:32<07:04, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  19% 681M/3.50G [00:32<01:48, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 676M/9.98G [00:32<06:11, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 684M/3.50G [00:32<01:45, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 680M/9.98G [00:32<05:33, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 687M/3.50G [00:32<01:41, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 683M/9.98G [00:32<05:21, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 690M/3.50G [00:32<01:46, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 693M/3.50G [00:32<01:40, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 687M/9.98G [00:33<05:26, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 690M/9.98G [00:33<05:49, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 697M/3.50G [00:32<01:51, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 694M/9.98G [00:33<05:12, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 701M/3.50G [00:32<01:33, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 698M/9.98G [00:33<05:28, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 702M/9.98G [00:33<04:55, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 704M/3.50G [00:32<02:15, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 709M/3.50G [00:33<01:49, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 706M/9.98G [00:33<06:39, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  20% 713M/3.50G [00:33<01:49, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 709M/9.98G [00:33<05:53, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 718M/3.50G [00:33<01:32, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 713M/9.98G [00:34<06:01, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 717M/9.98G [00:34<05:23, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 721M/3.50G [00:33<01:59, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 725M/3.50G [00:33<01:48, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 721M/9.98G [00:34<07:29, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 729M/3.50G [00:33<01:51, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 724M/9.98G [00:34<06:25, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 734M/3.50G [00:33<01:34, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 729M/9.98G [00:34<05:18, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 733M/9.98G [00:34<05:43, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 737M/3.50G [00:34<02:16, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 740M/3.50G [00:34<02:04, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 745M/3.50G [00:34<01:54, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 736M/9.98G [00:35<08:35, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 748M/3.50G [00:34<01:44, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 740M/9.98G [00:35<07:22, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   7% 744M/9.98G [00:35<05:56, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 748M/9.98G [00:35<05:21, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  21% 752M/3.50G [00:34<02:03, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  22% 756M/3.50G [00:34<01:43, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 752M/9.98G [00:35<05:41, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  22% 761M/3.50G [00:35<01:42, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 755M/9.98G [00:35<06:19, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  22% 766M/3.50G [00:35<01:31, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 758M/9.98G [00:35<06:47, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 762M/9.98G [00:36<05:43, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  22% 769M/3.50G [00:35<01:52, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 767M/9.98G [00:36<04:57, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  22% 774M/3.50G [00:35<01:38, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  22% 778M/3.50G [00:35<01:39, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 770M/9.98G [00:36<06:48, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  22% 783M/3.50G [00:35<01:27, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 774M/9.98G [00:36<06:39, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  22% 786M/3.50G [00:36<01:41, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 779M/9.98G [00:36<05:27, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 790M/3.50G [00:36<01:36, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 783M/9.98G [00:36<05:22, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 794M/3.50G [00:36<01:37, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 786M/9.98G [00:37<07:08, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 799M/3.50G [00:36<01:34, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 790M/9.98G [00:37<06:08, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 802M/3.50G [00:36<01:43, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 793M/9.98G [00:37<06:27, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 805M/3.50G [00:36<01:43, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 798M/9.98G [00:37<05:23, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 809M/3.50G [00:36<01:33, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 812M/3.50G [00:37<01:37, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 801M/9.98G [00:37<07:12, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 816M/3.50G [00:37<01:43, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 805M/9.98G [00:37<06:10, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 809M/9.98G [00:37<06:08, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 818M/3.50G [00:37<02:14, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 813M/9.98G [00:38<05:18, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  23% 821M/3.50G [00:37<02:01, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 826M/3.50G [00:37<01:52, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 817M/9.98G [00:38<06:45, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 831M/3.50G [00:37<01:33, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 821M/9.98G [00:38<05:47, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 825M/9.98G [00:38<05:49, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 834M/3.50G [00:38<02:10, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 829M/9.98G [00:38<05:11, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 836M/3.50G [00:38<02:04, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 841M/3.50G [00:38<01:44, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 833M/9.98G [00:38<06:28, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 836M/9.98G [00:39<05:41, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 844M/3.50G [00:38<01:46, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 841M/9.98G [00:39<04:53, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 848M/3.50G [00:38<02:02, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 845M/9.98G [00:39<05:32, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 852M/3.50G [00:38<01:44, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   8% 848M/9.98G [00:39<05:27, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  24% 857M/3.50G [00:38<01:26, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 860M/3.50G [00:39<01:36, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 864M/3.50G [00:39<02:04, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 851M/9.98G [00:39<10:51, 14.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 868M/3.50G [00:39<01:49, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 854M/9.98G [00:40<10:29, 14.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 871M/3.50G [00:39<01:38, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 857M/9.98G [00:40<08:28, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 875M/3.50G [00:39<01:35, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 861M/9.98G [00:40<06:46, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 879M/3.50G [00:39<01:33, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 882M/3.50G [00:39<01:46, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 886M/3.50G [00:39<01:35, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  25% 890M/3.50G [00:40<01:36, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 895M/3.50G [00:40<01:30, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 898M/3.50G [00:40<01:42, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 902M/3.50G [00:40<01:38, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 864M/9.98G [00:41<18:31, 8.20MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 906M/3.50G [00:40<01:27, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 909M/3.50G [00:40<01:26, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 912M/3.50G [00:40<01:33, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 868M/9.98G [00:41<16:06, 9.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 871M/9.98G [00:41<12:50, 11.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 915M/3.50G [00:41<01:41, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 876M/9.98G [00:41<09:23, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 918M/3.50G [00:41<01:38, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 879M/9.98G [00:41<08:58, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 922M/3.50G [00:41<01:38, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 882M/9.98G [00:42<09:19, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  26% 927M/3.50G [00:41<01:31, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 885M/9.98G [00:42<07:42, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 888M/9.98G [00:42<07:10, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 930M/3.50G [00:41<01:49, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 933M/3.50G [00:41<01:40, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 892M/9.98G [00:42<06:33, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 895M/9.98G [00:42<06:03, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 937M/3.50G [00:41<01:45, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 942M/3.50G [00:42<01:27, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 898M/9.98G [00:42<07:56, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 901M/9.98G [00:42<07:18, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 945M/3.50G [00:42<01:49, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 948M/3.50G [00:42<01:45, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 905M/9.98G [00:43<06:39, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 951M/3.50G [00:42<01:33, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 909M/9.98G [00:43<05:27, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 956M/3.50G [00:42<01:28, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 913M/9.98G [00:43<07:02, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 916M/9.98G [00:43<06:02, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  27% 960M/3.50G [00:42<01:53, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 921M/9.98G [00:43<05:05, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 964M/3.50G [00:42<01:37, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 969M/3.50G [00:43<01:23, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 924M/9.98G [00:43<05:31, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 972M/3.50G [00:43<01:30, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 928M/9.98G [00:43<06:54, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 932M/9.98G [00:44<05:53, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 976M/3.50G [00:43<02:03, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 936M/9.98G [00:44<05:26, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 980M/3.50G [00:43<01:49, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 940M/9.98G [00:44<05:50, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 985M/3.50G [00:43<01:32, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 944M/9.98G [00:44<05:31, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 988M/3.50G [00:43<01:27, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 991M/3.50G [00:44<01:27, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:   9% 947M/9.98G [00:44<06:34, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 951M/9.98G [00:44<05:39, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  28% 995M/3.50G [00:44<01:39, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:58:52] Energy consumed for RAM : 0.029591 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:58:52] Energy consumed for all GPUs : 0.194816 kWh. Total GPU Power : 27.275000000000006 W\n",
            "[codecarbon INFO @ 15:58:52] Energy consumed for all CPUs : 0.131900 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:58:52] 0.356307 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00002-of-00002.bin:  28% 997M/3.50G [00:44<01:38, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  10% 954M/9.98G [00:44<06:08, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  10% 958M/9.98G [00:45<05:19, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.00G/3.50G [00:44<01:35, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.01G/3.50G [00:44<01:19, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 961M/9.98G [00:45<07:14, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.01G/3.50G [00:44<01:41, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 965M/9.98G [00:45<06:23, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.01G/3.50G [00:44<01:37, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 968M/9.98G [00:45<06:08, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 972M/9.98G [00:45<05:14, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.02G/3.50G [00:45<01:35, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 975M/9.98G [00:45<05:49, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.02G/3.50G [00:45<01:30, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 978M/9.98G [00:45<07:00, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.03G/3.50G [00:45<01:40, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  29% 1.03G/3.50G [00:45<01:40, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 982M/9.98G [00:46<06:47, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.03G/3.50G [00:45<01:27, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 986M/9.98G [00:46<05:47, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.04G/3.50G [00:45<01:33, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 990M/9.98G [00:46<05:17, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.04G/3.50G [00:45<01:50, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 993M/9.98G [00:46<07:11, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.04G/3.50G [00:46<01:33, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 996M/9.98G [00:46<06:44, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.05G/3.50G [00:46<01:21, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.00G/9.98G [00:46<05:28, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.05G/3.50G [00:46<01:27, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.00G/9.98G [00:46<05:41, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.06G/3.50G [00:46<01:23, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.06G/3.50G [00:46<01:34, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.01G/9.98G [00:47<07:23, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.06G/3.50G [00:46<01:32, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.01G/9.98G [00:47<06:15, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.02G/9.98G [00:47<05:17, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  30% 1.06G/3.50G [00:46<01:41, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.07G/3.50G [00:46<01:30, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.02G/9.98G [00:47<05:30, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.07G/3.50G [00:47<01:54, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.02G/9.98G [00:47<06:56, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.08G/3.50G [00:47<01:34, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.03G/9.98G [00:47<05:57, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.08G/3.50G [00:47<01:21, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.03G/9.98G [00:48<04:57, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.08G/3.50G [00:47<01:20, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.04G/9.98G [00:48<05:30, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.09G/3.50G [00:47<01:27, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.09G/3.50G [00:47<01:29, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.09G/3.50G [00:47<01:27, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.04G/9.98G [00:48<06:57, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  10% 1.04G/9.98G [00:48<05:55, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  31% 1.10G/3.50G [00:48<01:27, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.05G/9.98G [00:48<05:04, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.10G/3.50G [00:48<01:23, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.05G/9.98G [00:48<05:24, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.11G/3.50G [00:48<01:40, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.98G [00:49<06:20, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.98G [00:49<05:30, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.11G/3.50G [00:48<01:44, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.06G/9.98G [00:49<04:48, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.11G/3.50G [00:48<01:25, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.07G/9.98G [00:49<05:08, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.12G/3.50G [00:48<01:25, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.12G/3.50G [00:49<01:36, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.07G/9.98G [00:49<06:45, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.13G/3.50G [00:49<01:32, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.08G/9.98G [00:49<05:47, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.13G/3.50G [00:49<01:21, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.08G/9.98G [00:49<05:32, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.13G/3.50G [00:49<01:34, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:50<04:48, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  32% 1.14G/3.50G [00:49<01:56, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:50<06:24, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.14G/3.50G [00:49<01:35, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.09G/9.98G [00:50<05:39, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.14G/3.50G [00:49<01:31, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.10G/9.98G [00:50<05:35, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.15G/3.50G [00:50<01:30, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.10G/9.98G [00:50<05:00, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.15G/3.50G [00:50<01:51, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.11G/9.98G [00:50<06:38, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.16G/3.50G [00:50<01:33, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.11G/9.98G [00:51<05:42, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.16G/3.50G [00:50<01:20, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.16G/3.50G [00:50<01:20, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.11G/9.98G [00:51<05:55, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.98G [00:51<04:56, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.17G/3.50G [00:50<01:24, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  33% 1.17G/3.50G [00:50<01:35, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.12G/9.98G [00:51<06:29, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.17G/3.50G [00:51<01:30, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.13G/9.98G [00:51<05:27, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.18G/3.50G [00:51<01:37, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.13G/9.98G [00:51<05:54, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.18G/3.50G [00:51<01:26, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.13G/9.98G [00:52<05:09, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.18G/3.50G [00:51<01:55, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.14G/9.98G [00:52<06:17, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.19G/3.50G [00:51<01:34, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.14G/9.98G [00:52<06:10, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.19G/3.50G [00:51<01:22, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  11% 1.14G/9.98G [00:52<05:09, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.20G/3.50G [00:51<01:19, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.15G/9.98G [00:52<05:37, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.20G/3.50G [00:52<01:23, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.20G/3.50G [00:52<01:35, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.15G/9.98G [00:52<06:49, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  34% 1.21G/3.50G [00:52<01:28, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.16G/9.98G [00:52<05:58, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.16G/9.98G [00:53<05:06, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.21G/3.50G [00:52<01:33, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.21G/3.50G [00:52<01:17, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.16G/9.98G [00:53<05:16, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.17G/9.98G [00:53<05:02, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.22G/3.50G [00:52<01:34, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.22G/3.50G [00:52<01:21, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.17G/9.98G [00:53<06:22, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.17G/9.98G [00:53<05:35, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.23G/3.50G [00:53<01:25, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.23G/3.50G [00:53<01:10, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.18G/9.98G [00:53<06:05, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.18G/9.98G [00:53<05:15, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.23G/3.50G [00:53<01:25, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.24G/3.50G [00:53<01:21, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.19G/9.98G [00:54<07:09, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  35% 1.24G/3.50G [00:53<01:12, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.19G/9.98G [00:54<06:48, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.25G/3.50G [00:53<01:12, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.19G/9.98G [00:54<05:24, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.20G/9.98G [00:54<05:40, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.25G/3.50G [00:53<01:48, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.20G/9.98G [00:54<05:35, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.25G/3.50G [00:54<01:29, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.26G/3.50G [00:54<01:23, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.20G/9.98G [00:54<06:31, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.20G/9.98G [00:54<06:12, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.26G/3.50G [00:54<01:19, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.21G/9.98G [00:54<05:00, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.26G/3.50G [00:54<01:20, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.21G/9.98G [00:55<05:45, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.27G/3.50G [00:54<01:50, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.27G/3.50G [00:54<01:36, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.22G/9.98G [00:55<07:28, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.22G/9.98G [00:55<06:13, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.27G/3.50G [00:54<01:40, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.22G/9.98G [00:55<05:06, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  36% 1.28G/3.50G [00:55<01:30, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.23G/9.98G [00:55<05:35, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.28G/3.50G [00:55<01:41, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.28G/3.50G [00:55<01:24, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.23G/9.98G [00:56<06:45, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.29G/3.50G [00:55<01:16, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.24G/9.98G [00:56<06:00, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.29G/3.50G [00:55<01:15, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.24G/9.98G [00:56<05:23, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.30G/3.50G [00:55<01:15, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  12% 1.24G/9.98G [00:56<04:43, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.30G/3.50G [00:55<01:29, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.25G/9.98G [00:56<04:59, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.30G/3.50G [00:55<01:24, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.25G/9.98G [00:56<06:16, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.31G/3.50G [00:56<01:28, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.25G/9.98G [00:56<05:23, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  37% 1.31G/3.50G [00:56<01:14, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.26G/9.98G [00:56<05:59, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.26G/9.98G [00:57<05:17, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.31G/3.50G [00:56<01:38, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:56<01:31, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:56<01:13, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.26G/9.98G [00:57<07:09, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.27G/9.98G [00:57<05:50, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.32G/3.50G [00:56<01:23, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.27G/9.98G [00:57<05:59, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.28G/9.98G [00:57<05:03, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.33G/3.50G [00:57<01:50, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.33G/3.50G [00:57<01:30, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.34G/3.50G [00:57<01:15, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.28G/9.98G [00:57<06:42, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.34G/3.50G [00:57<01:15, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.28G/9.98G [00:58<05:56, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.29G/9.98G [00:58<04:58, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.34G/3.50G [00:57<01:17, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.29G/9.98G [00:58<05:26, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  38% 1.35G/3.50G [00:57<01:32, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.35G/3.50G [00:57<01:38, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.30G/9.98G [00:58<07:27, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.36G/3.50G [00:58<01:25, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.30G/9.98G [00:58<06:12, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.30G/9.98G [00:58<05:29, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.36G/3.50G [00:58<01:30, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.31G/9.98G [00:58<04:45, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.31G/9.98G [00:59<05:12, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.36G/3.50G [00:58<01:57, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.36G/3.50G [00:58<01:48, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.32G/9.98G [00:59<06:09, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.32G/9.98G [00:59<05:25, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.37G/3.50G [00:58<01:42, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.37G/3.50G [00:58<01:32, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.32G/9.98G [00:59<05:56, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.33G/9.98G [00:59<05:17, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.37G/3.50G [00:59<01:33, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  39% 1.38G/3.50G [00:59<01:41, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.33G/9.98G [00:59<06:56, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:59:07] Energy consumed for RAM : 0.029631 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:59:07] Energy consumed for all GPUs : 0.194930 kWh. Total GPU Power : 27.457 W\n",
            "[codecarbon INFO @ 15:59:07] Energy consumed for all CPUs : 0.132077 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:59:07] 0.356638 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  13% 1.33G/9.98G [01:00<06:01, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00002-of-00002.bin:  39% 1.38G/3.50G [00:59<01:35, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.34G/9.98G [01:00<04:53, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.39G/3.50G [00:59<01:29, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.34G/9.98G [01:00<05:19, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.39G/3.50G [00:59<01:26, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  13% 1.34G/9.98G [01:00<06:40, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.39G/3.50G [00:59<01:55, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.35G/9.98G [01:00<05:46, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.40G/3.50G [01:00<01:36, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.35G/9.98G [01:00<05:33, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.36G/9.98G [01:00<04:43, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.40G/3.50G [01:00<01:27, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.36G/9.98G [01:00<04:49, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.40G/3.50G [01:00<01:21, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.36G/9.98G [01:01<05:26, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.41G/3.50G [01:00<01:26, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.37G/9.98G [01:01<04:46, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.41G/3.50G [01:00<01:44, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.37G/9.98G [01:01<05:29, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.37G/9.98G [01:01<04:52, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  40% 1.41G/3.50G [01:00<01:42, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.42G/3.50G [01:01<01:31, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.38G/9.98G [01:01<06:07, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.38G/9.98G [01:01<05:17, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.42G/3.50G [01:01<01:26, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.42G/3.50G [01:01<01:37, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.39G/9.98G [01:01<05:23, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.43G/3.50G [01:01<01:26, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.39G/9.98G [01:02<05:05, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.43G/3.50G [01:01<01:11, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.39G/9.98G [01:02<06:16, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.44G/3.50G [01:01<01:18, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.40G/9.98G [01:02<05:25, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.44G/3.50G [01:01<01:24, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.40G/9.98G [01:02<04:30, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.41G/9.98G [01:02<04:58, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.44G/3.50G [01:02<01:46, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.44G/3.50G [01:02<01:33, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.41G/9.98G [01:02<06:14, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.45G/3.50G [01:02<01:18, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.41G/9.98G [01:02<05:45, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  41% 1.45G/3.50G [01:02<01:25, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.42G/9.98G [01:03<04:45, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.45G/3.50G [01:02<01:25, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.42G/9.98G [01:03<05:15, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.46G/3.50G [01:02<01:47, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.42G/9.98G [01:03<06:40, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.46G/3.50G [01:02<01:33, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.43G/9.98G [01:03<05:42, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.47G/3.50G [01:03<01:22, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.43G/9.98G [01:03<04:44, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.47G/3.50G [01:03<01:21, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.44G/9.98G [01:03<05:17, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.47G/3.50G [01:03<01:52, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.44G/9.98G [01:04<06:52, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [01:03<01:28, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  14% 1.44G/9.98G [01:04<05:51, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [01:03<01:23, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.45G/9.98G [01:04<04:47, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.48G/3.50G [01:03<01:28, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.45G/9.98G [01:04<05:18, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  42% 1.49G/3.50G [01:03<01:20, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.49G/3.50G [01:04<01:32, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.46G/9.98G [01:04<07:00, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.46G/9.98G [01:04<05:57, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.49G/3.50G [01:04<01:30, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.46G/9.98G [01:05<04:51, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.50G/3.50G [01:04<01:09, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.50G/3.50G [01:04<01:10, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.47G/9.98G [01:05<05:12, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.51G/3.50G [01:04<01:39, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.47G/9.98G [01:05<06:57, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.48G/9.98G [01:05<06:07, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.51G/3.50G [01:04<01:33, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.48G/9.98G [01:05<05:04, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.51G/3.50G [01:05<01:23, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.48G/9.98G [01:05<05:15, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.52G/3.50G [01:05<01:16, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.49G/9.98G [01:05<05:10, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.49G/9.98G [01:06<06:06, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  43% 1.52G/3.50G [01:05<01:34, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.49G/9.98G [01:06<05:16, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.53G/3.50G [01:05<01:32, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.50G/9.98G [01:06<05:49, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.53G/3.50G [01:05<01:20, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.50G/9.98G [01:06<04:40, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.53G/3.50G [01:05<01:20, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.51G/9.98G [01:06<06:00, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.51G/9.98G [01:06<05:10, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.54G/3.50G [01:06<01:51, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.54G/3.50G [01:06<01:29, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.51G/9.98G [01:07<05:40, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.55G/3.50G [01:06<01:22, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.52G/9.98G [01:07<05:24, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.55G/3.50G [01:06<01:17, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.52G/9.98G [01:07<05:32, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.53G/9.98G [01:07<04:51, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.55G/3.50G [01:06<01:38, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.53G/9.98G [01:07<05:19, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  44% 1.56G/3.50G [01:07<01:20, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.53G/9.98G [01:07<04:22, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.56G/3.50G [01:07<01:19, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.56G/3.50G [01:07<01:13, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.54G/9.98G [01:07<06:05, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.54G/9.98G [01:08<05:51, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  15% 1.55G/9.98G [01:08<05:48, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.55G/9.98G [01:08<04:51, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.57G/3.50G [01:07<02:24, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.57G/3.50G [01:08<03:16, 9.84MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.57G/3.50G [01:08<03:20, 9.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.55G/9.98G [01:09<14:49, 9.47MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.58G/3.50G [01:08<02:50, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.56G/9.98G [01:09<13:52, 10.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.58G/3.50G [01:08<02:00, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.56G/9.98G [01:09<12:00, 11.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.58G/3.50G [01:09<01:49, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.56G/9.98G [01:09<09:02, 15.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.57G/9.98G [01:09<08:26, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.59G/3.50G [01:09<02:01, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.57G/9.98G [01:09<07:55, 17.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  45% 1.59G/3.50G [01:09<01:42, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.59G/3.50G [01:09<01:26, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.57G/9.98G [01:10<08:33, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.60G/3.50G [01:09<01:17, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.57G/9.98G [01:10<07:01, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.58G/9.98G [01:10<06:28, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.60G/3.50G [01:09<01:34, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.58G/9.98G [01:10<05:10, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.61G/3.50G [01:09<01:14, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.61G/3.50G [01:10<01:08, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.59G/9.98G [01:10<06:08, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.59G/9.98G [01:10<05:19, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.61G/3.50G [01:10<01:15, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.59G/9.98G [01:10<04:29, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.60G/9.98G [01:11<04:56, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.62G/3.50G [01:10<01:27, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.62G/3.50G [01:10<01:14, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  46% 1.63G/3.50G [01:10<01:09, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.60G/9.98G [01:11<06:55, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.63G/3.50G [01:10<01:06, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.60G/9.98G [01:11<06:10, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.61G/9.98G [01:11<05:20, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.61G/9.98G [01:11<04:55, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.63G/3.50G [01:11<01:26, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.64G/3.50G [01:11<01:11, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.62G/9.98G [01:11<05:03, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.64G/3.50G [01:11<01:09, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.62G/9.98G [01:11<05:44, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.64G/3.50G [01:11<01:06, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.62G/9.98G [01:12<06:02, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.65G/3.50G [01:11<01:03, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.63G/9.98G [01:12<05:00, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.63G/9.98G [01:12<05:04, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.63G/9.98G [01:12<05:57, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.65G/3.50G [01:12<02:05, 14.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.64G/9.98G [01:12<05:47, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.65G/3.50G [01:12<01:54, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.64G/9.98G [01:12<05:50, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  16% 1.64G/9.98G [01:12<04:48, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.66G/3.50G [01:12<01:42, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.65G/9.98G [01:13<04:36, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  47% 1.66G/3.50G [01:12<01:20, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.65G/9.98G [01:13<05:27, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.66G/3.50G [01:12<01:28, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.65G/9.98G [01:13<04:44, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.67G/3.50G [01:12<01:13, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.67G/3.50G [01:12<01:01, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.66G/9.98G [01:13<05:22, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.68G/3.50G [01:12<01:00, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.66G/9.98G [01:13<04:37, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.67G/9.98G [01:13<06:26, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.68G/3.50G [01:13<01:28, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.67G/9.98G [01:13<05:21, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.68G/3.50G [01:13<01:17, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.69G/3.50G [01:13<01:04, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.67G/9.98G [01:14<05:33, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.68G/9.98G [01:14<04:49, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.69G/3.50G [01:13<01:09, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.68G/9.98G [01:14<05:32, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.69G/9.98G [01:14<05:10, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  48% 1.70G/3.50G [01:13<01:28, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.70G/3.50G [01:13<01:17, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.69G/9.98G [01:14<05:09, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.70G/3.50G [01:14<01:09, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.69G/9.98G [01:14<04:34, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.71G/3.50G [01:14<00:59, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:59:22] Energy consumed for RAM : 0.029671 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:59:22] Energy consumed for all GPUs : 0.195045 kWh. Total GPU Power : 27.654 W\n",
            "[codecarbon INFO @ 15:59:22] Energy consumed for all CPUs : 0.132254 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:59:22] 0.356970 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  17% 1.70G/9.98G [01:15<05:49, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  17% 1.70G/9.98G [01:15<05:09, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00002-of-00002.bin:  49% 1.71G/3.50G [01:14<01:20, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  17% 1.71G/9.98G [01:15<04:20, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.72G/3.50G [01:14<01:07, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.71G/9.98G [01:15<04:48, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.72G/3.50G [01:14<01:06, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.73G/3.50G [01:14<01:02, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.71G/9.98G [01:15<06:23, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  49% 1.73G/3.50G [01:15<01:03, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.72G/9.98G [01:15<05:20, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.73G/3.50G [01:15<01:03, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.72G/9.98G [01:15<05:14, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.74G/3.50G [01:15<01:03, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.72G/9.98G [01:15<05:14, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.74G/3.50G [01:15<00:59, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.73G/9.98G [01:16<06:29, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.75G/3.50G [01:15<01:11, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.73G/9.98G [01:16<05:30, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.75G/3.50G [01:15<01:07, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.74G/9.98G [01:16<05:16, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.74G/9.98G [01:16<04:28, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.75G/3.50G [01:15<01:10, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  17% 1.74G/9.98G [01:16<04:24, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.76G/3.50G [01:16<00:59, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.75G/9.98G [01:16<06:01, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.76G/3.50G [01:16<01:20, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.75G/9.98G [01:17<05:00, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  50% 1.77G/3.50G [01:16<01:07, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.75G/9.98G [01:17<05:33, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.77G/3.50G [01:16<01:09, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.76G/9.98G [01:17<04:46, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.77G/3.50G [01:16<00:58, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.76G/9.98G [01:17<06:03, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.78G/3.50G [01:16<01:11, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.77G/9.98G [01:17<05:00, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.78G/3.50G [01:17<01:01, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.77G/9.98G [01:17<05:27, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.79G/3.50G [01:17<01:02, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.77G/9.98G [01:17<04:46, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.79G/3.50G [01:17<00:58, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.78G/9.98G [01:18<06:18, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.79G/3.50G [01:17<01:07, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.78G/9.98G [01:18<05:22, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.80G/3.50G [01:17<01:04, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.79G/9.98G [01:18<04:41, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  51% 1.80G/3.50G [01:17<01:07, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.79G/9.98G [01:18<05:01, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.81G/3.50G [01:17<01:00, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.79G/9.98G [01:18<06:58, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.81G/3.50G [01:18<01:22, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.80G/9.98G [01:18<05:48, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.81G/3.50G [01:18<01:08, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.80G/9.98G [01:18<04:57, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.82G/3.50G [01:18<00:58, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.82G/3.50G [01:18<00:58, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.80G/9.98G [01:19<05:06, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.82G/3.50G [01:18<01:01, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.83G/3.50G [01:18<01:14, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.81G/9.98G [01:19<07:01, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.83G/3.50G [01:18<01:08, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.81G/9.98G [01:19<06:11, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.83G/3.50G [01:19<00:58, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.82G/9.98G [01:19<05:10, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  52% 1.84G/3.50G [01:19<00:58, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.82G/9.98G [01:19<05:13, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.84G/3.50G [01:19<01:01, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.84G/3.50G [01:19<01:15, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.82G/9.98G [01:20<06:21, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.85G/3.50G [01:19<01:09, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.83G/9.98G [01:20<05:42, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.83G/9.98G [01:20<04:54, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.85G/3.50G [01:19<01:05, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.84G/9.98G [01:20<04:59, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.86G/3.50G [01:19<01:00, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.86G/3.50G [01:20<01:02, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.84G/9.98G [01:20<06:14, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.86G/3.50G [01:20<01:01, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  18% 1.84G/9.98G [01:20<05:35, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.86G/3.50G [01:20<00:57, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.85G/9.98G [01:20<04:58, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.87G/3.50G [01:20<00:54, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.85G/9.98G [01:21<04:21, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  53% 1.87G/3.50G [01:20<00:56, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.86G/9.98G [01:21<04:42, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.87G/3.50G [01:20<01:09, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.86G/9.98G [01:21<04:52, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.88G/3.50G [01:20<01:03, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.86G/9.98G [01:21<04:37, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.88G/3.50G [01:20<01:01, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [01:21<04:58, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [01:21<04:25, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.89G/3.50G [01:21<00:57, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.89G/3.50G [01:21<00:58, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.87G/9.98G [01:21<05:42, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.89G/3.50G [01:21<00:57, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.88G/9.98G [01:21<05:06, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.90G/3.50G [01:21<00:58, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.88G/9.98G [01:22<04:33, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.90G/3.50G [01:21<00:57, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.90G/3.50G [01:21<00:55, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.88G/9.98G [01:22<05:07, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  54% 1.91G/3.50G [01:21<01:07, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.89G/9.98G [01:22<06:35, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.91G/3.50G [01:21<00:59, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.89G/9.98G [01:22<05:46, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.91G/3.50G [01:22<01:02, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.90G/9.98G [01:22<04:56, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.92G/3.50G [01:22<00:52, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.90G/9.98G [01:22<04:52, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.92G/3.50G [01:22<01:13, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.90G/9.98G [01:23<05:40, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.93G/3.50G [01:22<01:00, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.91G/9.98G [01:23<05:05, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.91G/9.98G [01:23<04:21, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.93G/3.50G [01:22<00:59, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.92G/9.98G [01:23<04:35, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.94G/3.50G [01:22<00:55, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.94G/3.50G [01:23<01:00, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.92G/9.98G [01:23<05:49, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  55% 1.94G/3.50G [01:23<00:59, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.92G/9.98G [01:23<05:03, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [01:23<04:22, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.95G/3.50G [01:23<00:57, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.93G/9.98G [01:24<04:41, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.95G/3.50G [01:23<00:55, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.95G/3.50G [01:23<01:00, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.96G/3.50G [01:23<00:56, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.94G/9.98G [01:24<06:21, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.96G/3.50G [01:23<00:54, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.94G/9.98G [01:24<05:36, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.96G/3.50G [01:23<00:51, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  19% 1.94G/9.98G [01:24<04:50, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.97G/3.50G [01:24<00:54, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.95G/9.98G [01:24<04:47, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.97G/3.50G [01:24<01:06, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.95G/9.98G [01:25<06:33, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.97G/3.50G [01:24<01:07, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.96G/9.98G [01:25<05:34, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  56% 1.98G/3.50G [01:24<01:00, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.96G/9.98G [01:25<04:47, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  57% 1.98G/3.50G [01:24<00:56, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.96G/9.98G [01:25<04:54, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  57% 1.99G/3.50G [01:24<01:06, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.97G/9.98G [01:25<06:09, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  57% 1.99G/3.50G [01:25<01:04, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.97G/9.98G [01:25<05:16, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  57% 1.99G/3.50G [01:25<00:53, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.98G/9.98G [01:25<04:29, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.00G/3.50G [01:25<00:55, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.98G/9.98G [01:25<04:47, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.00G/3.50G [01:25<01:06, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.01G/3.50G [01:25<00:55, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.98G/9.98G [01:26<06:04, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.99G/9.98G [01:26<05:12, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  57% 2.01G/3.50G [01:25<00:59, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 1.99G/9.98G [01:26<04:29, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.01G/3.50G [01:25<00:49, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.00G/9.98G [01:26<04:44, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.02G/3.50G [01:26<01:04, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.02G/3.50G [01:26<00:56, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.00G/9.98G [01:26<05:52, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.02G/3.50G [01:26<00:52, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.00G/9.98G [01:26<05:18, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.01G/9.98G [01:27<04:31, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.03G/3.50G [01:26<00:51, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.01G/9.98G [01:27<04:40, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.03G/3.50G [01:26<01:08, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.02G/9.98G [01:27<05:26, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.04G/3.50G [01:26<00:54, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.02G/9.98G [01:27<04:46, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.04G/3.50G [01:26<00:51, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.02G/9.98G [01:27<04:09, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.04G/3.50G [01:27<00:49, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.03G/9.98G [01:27<04:31, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  58% 2.05G/3.50G [01:27<00:53, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.05G/3.50G [01:27<01:01, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.03G/9.98G [01:27<05:28, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.05G/3.50G [01:27<00:57, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.04G/9.98G [01:28<05:03, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.04G/9.98G [01:28<04:29, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.06G/3.50G [01:27<00:59, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  20% 2.04G/9.98G [01:28<04:00, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.06G/3.50G [01:27<00:48, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.05G/9.98G [01:28<04:29, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.07G/3.50G [01:27<01:04, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.05G/9.98G [01:28<05:16, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.07G/3.50G [01:28<00:56, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.06G/9.98G [01:28<05:26, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.07G/3.50G [01:28<00:55, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.06G/9.98G [01:28<04:35, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.08G/3.50G [01:28<00:47, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.06G/9.98G [01:29<04:47, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  59% 2.08G/3.50G [01:28<01:02, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.07G/9.98G [01:29<05:26, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.09G/3.50G [01:28<00:53, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.07G/9.98G [01:29<05:17, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.07G/9.98G [01:29<04:25, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.09G/3.50G [01:28<00:54, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.08G/9.98G [01:29<04:57, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.09G/3.50G [01:29<00:50, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.10G/3.50G [01:29<00:52, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:59:37] Energy consumed for RAM : 0.029710 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:59:37] Energy consumed for all GPUs : 0.195159 kWh. Total GPU Power : 27.359 W\n",
            "[codecarbon INFO @ 15:59:37] Energy consumed for all CPUs : 0.132431 kWh. Total CPU Power : 42.5 W\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  21% 2.08G/9.98G [01:29<06:03, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00002-of-00002.bin:  60% 2.10G/3.50G [01:29<00:48, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  21% 2.08G/9.98G [01:29<05:07, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  21% 2.09G/9.98G [01:30<04:24, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00002-of-00002.bin:  60% 2.11G/3.50G [01:29<00:49, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:59:37] 0.357301 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  21% 2.09G/9.98G [01:30<04:10, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00002-of-00002.bin:  60% 2.11G/3.50G [01:29<00:41, 33.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.10G/9.98G [01:30<04:35, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  60% 2.11G/3.50G [01:29<00:51, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.10G/9.98G [01:30<04:57, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.12G/3.50G [01:29<00:50, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.10G/9.98G [01:30<04:23, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.12G/3.50G [01:29<00:50, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.11G/9.98G [01:30<04:56, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.11G/9.98G [01:30<04:18, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.13G/3.50G [01:30<00:48, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.13G/3.50G [01:30<00:56, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.13G/3.50G [01:30<00:53, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.11G/9.98G [01:31<06:31, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.14G/3.50G [01:30<00:49, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.12G/9.98G [01:31<05:57, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.12G/9.98G [01:31<04:50, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.14G/3.50G [01:30<00:55, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.12G/9.98G [01:31<05:14, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.14G/3.50G [01:30<01:00, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  61% 2.15G/3.50G [01:31<00:49, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.13G/9.98G [01:31<06:31, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.13G/9.98G [01:31<05:26, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.15G/3.50G [01:31<00:48, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.14G/9.98G [01:31<04:31, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.16G/3.50G [01:31<00:43, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.14G/9.98G [01:32<04:47, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.16G/3.50G [01:31<00:54, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.17G/3.50G [01:31<00:48, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  21% 2.14G/9.98G [01:32<06:06, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.15G/9.98G [01:32<05:12, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.17G/3.50G [01:31<00:48, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.15G/9.98G [01:32<04:19, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.18G/3.50G [01:31<00:47, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [01:32<04:26, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [01:32<04:28, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.18G/3.50G [01:32<00:58, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.18G/3.50G [01:32<00:53, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.16G/9.98G [01:32<05:18, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  62% 2.18G/3.50G [01:32<00:50, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.17G/9.98G [01:33<05:11, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.19G/3.50G [01:32<00:51, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.17G/9.98G [01:33<05:13, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.17G/9.98G [01:33<04:30, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.19G/3.50G [01:32<01:02, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.20G/3.50G [01:32<00:49, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.18G/9.98G [01:33<05:52, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.18G/9.98G [01:33<04:57, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.20G/3.50G [01:33<00:49, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.21G/3.50G [01:33<00:42, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.19G/9.98G [01:33<05:11, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.19G/9.98G [01:33<04:29, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.21G/3.50G [01:33<00:59, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.19G/9.98G [01:34<05:53, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.21G/3.50G [01:33<00:53, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.20G/9.98G [01:34<05:31, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.22G/3.50G [01:33<00:48, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.20G/9.98G [01:34<04:55, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  63% 2.22G/3.50G [01:33<00:47, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.20G/9.98G [01:34<04:26, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.22G/3.50G [01:33<00:47, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.21G/9.98G [01:34<04:34, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.23G/3.50G [01:34<00:49, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.23G/3.50G [01:34<00:45, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.21G/9.98G [01:34<05:20, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.21G/9.98G [01:34<04:45, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.23G/3.50G [01:34<00:45, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.22G/9.98G [01:35<05:03, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.24G/3.50G [01:34<00:44, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.22G/9.98G [01:35<04:22, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.24G/3.50G [01:34<00:45, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.25G/3.50G [01:34<00:43, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.25G/3.50G [01:34<00:40, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.23G/9.98G [01:35<05:51, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.25G/3.50G [01:34<00:38, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.23G/9.98G [01:35<05:09, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.23G/9.98G [01:35<04:19, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.24G/9.98G [01:35<04:42, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  64% 2.26G/3.50G [01:35<01:00, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.26G/3.50G [01:35<00:49, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.24G/9.98G [01:36<06:11, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.27G/3.50G [01:35<00:46, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  22% 2.24G/9.98G [01:36<05:35, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.27G/3.50G [01:35<00:41, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.25G/9.98G [01:36<04:45, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.25G/9.98G [01:36<04:09, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.27G/3.50G [01:35<00:53, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.26G/9.98G [01:36<04:32, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.28G/3.50G [01:35<00:46, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.26G/9.98G [01:36<05:07, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.28G/3.50G [01:36<00:48, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.26G/9.98G [01:36<04:48, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.29G/3.50G [01:36<00:43, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.27G/9.98G [01:36<05:08, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.27G/9.98G [01:37<04:22, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.29G/3.50G [01:36<00:54, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  65% 2.29G/3.50G [01:36<00:44, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.30G/3.50G [01:36<00:42, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.27G/9.98G [01:37<05:46, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.28G/9.98G [01:37<05:34, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.30G/3.50G [01:36<00:44, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.28G/9.98G [01:37<04:34, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.30G/3.50G [01:36<00:42, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.28G/9.98G [01:37<04:41, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.31G/3.50G [01:37<00:49, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.31G/3.50G [01:37<00:44, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.29G/9.98G [01:37<06:25, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.31G/3.50G [01:37<00:43, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.29G/9.98G [01:38<05:23, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.30G/9.98G [01:38<04:25, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.32G/3.50G [01:37<00:42, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.30G/9.98G [01:38<04:50, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.32G/3.50G [01:37<00:48, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  66% 2.33G/3.50G [01:37<00:46, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.30G/9.98G [01:38<05:56, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.33G/3.50G [01:37<00:44, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.31G/9.98G [01:38<05:03, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.31G/9.98G [01:38<04:19, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.34G/3.50G [01:38<00:41, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.34G/3.50G [01:38<00:42, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.32G/9.98G [01:38<04:35, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.34G/3.50G [01:38<00:41, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.32G/9.98G [01:39<05:19, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.35G/3.50G [01:38<00:41, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.32G/9.98G [01:39<04:39, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.33G/9.98G [01:39<04:00, 31.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.35G/3.50G [01:38<00:40, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.33G/9.98G [01:39<04:23, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.35G/3.50G [01:38<00:45, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.36G/3.50G [01:38<00:43, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.34G/9.98G [01:39<05:53, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  67% 2.36G/3.50G [01:39<00:42, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.34G/9.98G [01:39<05:11, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.37G/3.50G [01:39<00:40, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  23% 2.34G/9.98G [01:39<04:25, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.35G/9.98G [01:40<04:38, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.37G/3.50G [01:39<00:58, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.37G/3.50G [01:39<00:44, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.35G/9.98G [01:40<05:17, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.38G/3.50G [01:39<00:41, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.36G/9.98G [01:40<04:38, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.38G/3.50G [01:39<00:39, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.36G/9.98G [01:40<04:03, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.38G/3.50G [01:39<00:40, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.36G/9.98G [01:40<04:22, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.39G/3.50G [01:40<00:44, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.39G/3.50G [01:40<00:39, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.37G/9.98G [01:40<05:37, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.39G/3.50G [01:40<00:38, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.37G/9.98G [01:41<05:03, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  68% 2.40G/3.50G [01:40<00:39, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.38G/9.98G [01:41<04:16, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.40G/3.50G [01:40<00:41, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.38G/9.98G [01:41<04:30, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.40G/3.50G [01:40<00:52, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.41G/3.50G [01:40<00:50, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.38G/9.98G [01:41<06:07, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.41G/3.50G [01:41<00:39, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.39G/9.98G [01:41<05:14, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.39G/9.98G [01:41<04:40, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.41G/3.50G [01:41<00:41, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.40G/9.98G [01:41<04:11, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.42G/3.50G [01:41<00:47, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.40G/9.98G [01:42<04:27, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.42G/3.50G [01:41<00:45, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.40G/9.98G [01:42<05:20, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.43G/3.50G [01:41<00:36, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.41G/9.98G [01:42<04:33, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  69% 2.43G/3.50G [01:41<00:38, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.41G/9.98G [01:42<05:03, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.41G/9.98G [01:42<04:22, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.43G/3.50G [01:42<00:45, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.44G/3.50G [01:42<00:47, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.42G/9.98G [01:42<05:54, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.44G/3.50G [01:42<00:38, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.42G/9.98G [01:42<05:03, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.45G/3.50G [01:42<00:37, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.43G/9.98G [01:43<04:58, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.43G/9.98G [01:43<04:43, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.45G/3.50G [01:42<00:43, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.45G/3.50G [01:42<00:42, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.43G/9.98G [01:43<06:22, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.46G/3.50G [01:42<00:42, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.44G/9.98G [01:43<05:18, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.46G/3.50G [01:42<00:39, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  24% 2.44G/9.98G [01:43<04:19, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.44G/9.98G [01:43<04:54, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  70% 2.46G/3.50G [01:43<00:50, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.47G/3.50G [01:43<00:44, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.47G/3.50G [01:43<00:35, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.45G/9.98G [01:44<06:14, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.48G/3.50G [01:43<00:35, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.45G/9.98G [01:44<05:14, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.46G/9.98G [01:44<04:45, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.48G/3.50G [01:43<00:37, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.46G/9.98G [01:44<04:03, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.48G/3.50G [01:43<00:43, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.46G/9.98G [01:44<04:34, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.49G/3.50G [01:44<00:42, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.47G/9.98G [01:44<05:03, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.49G/3.50G [01:44<00:38, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.47G/9.98G [01:44<05:13, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.50G/3.50G [01:44<00:36, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 15:59:52] Energy consumed for RAM : 0.029750 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 15:59:52] Energy consumed for all GPUs : 0.195272 kWh. Total GPU Power : 27.093 W\n",
            "[codecarbon INFO @ 15:59:52] Energy consumed for all CPUs : 0.132608 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 15:59:52] 0.357630 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  25% 2.48G/9.98G [01:45<04:21, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.50G/3.50G [01:44<00:42, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.48G/9.98G [01:45<04:36, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  71% 2.50G/3.50G [01:44<00:38, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.48G/9.98G [01:45<05:20, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.51G/3.50G [01:44<00:40, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.49G/9.98G [01:45<04:32, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.51G/3.50G [01:44<00:33, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.49G/9.98G [01:45<05:00, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.51G/3.50G [01:45<00:43, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.49G/9.98G [01:45<04:20, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.52G/3.50G [01:45<00:36, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.50G/9.98G [01:45<05:05, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.52G/3.50G [01:45<00:37, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.50G/9.98G [01:46<04:44, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.50G/9.98G [01:46<04:16, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.53G/3.50G [01:45<00:34, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.51G/9.98G [01:46<04:03, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.51G/9.98G [01:46<04:23, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.53G/3.50G [01:45<00:42, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.53G/3.50G [01:45<00:37, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  72% 2.54G/3.50G [01:45<00:34, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.51G/9.98G [01:46<05:31, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.52G/9.98G [01:46<05:01, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.54G/3.50G [01:46<00:36, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.54G/3.50G [01:46<00:38, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.52G/9.98G [01:46<05:07, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.53G/9.98G [01:46<04:18, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.55G/3.50G [01:46<00:44, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.55G/3.50G [01:46<00:38, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.53G/9.98G [01:47<06:00, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.55G/3.50G [01:46<00:39, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.53G/9.98G [01:47<04:49, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.56G/3.50G [01:46<00:32, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.54G/9.98G [01:47<05:01, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  25% 2.54G/9.98G [01:47<04:22, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.56G/3.50G [01:47<00:43, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.57G/3.50G [01:47<00:35, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.57G/3.50G [01:47<00:37, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.55G/9.98G [01:47<06:03, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  73% 2.57G/3.50G [01:47<00:34, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.55G/9.98G [01:48<05:40, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.58G/3.50G [01:47<00:32, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.55G/9.98G [01:48<04:49, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.58G/3.50G [01:47<00:34, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.98G [01:48<04:07, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.58G/3.50G [01:47<00:38, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.59G/3.50G [01:47<00:30, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.56G/9.98G [01:48<05:29, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.59G/3.50G [01:48<00:31, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.57G/9.98G [01:48<05:04, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.57G/9.98G [01:48<05:04, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.59G/3.50G [01:48<00:38, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.57G/9.98G [01:48<04:12, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.60G/3.50G [01:48<00:32, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.60G/3.50G [01:48<00:34, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.58G/9.98G [01:49<05:00, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  74% 2.60G/3.50G [01:48<00:32, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.58G/9.98G [01:49<04:50, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.58G/9.98G [01:49<04:09, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.59G/9.98G [01:49<04:24, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.61G/3.50G [01:48<00:43, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.61G/3.50G [01:48<00:35, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.59G/9.98G [01:49<05:49, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.62G/3.50G [01:49<00:33, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.60G/9.98G [01:49<05:00, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.62G/3.50G [01:49<00:32, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.60G/9.98G [01:49<04:26, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.60G/9.98G [01:50<04:23, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.62G/3.50G [01:49<00:41, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.61G/9.98G [01:50<04:15, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.63G/3.50G [01:49<00:33, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.63G/3.50G [01:49<00:29, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.61G/9.98G [01:50<05:01, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.64G/3.50G [01:49<00:30, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.61G/9.98G [01:50<04:31, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.64G/3.50G [01:49<00:30, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.62G/9.98G [01:50<04:39, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.62G/9.98G [01:50<04:06, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  75% 2.64G/3.50G [01:50<00:35, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.65G/3.50G [01:50<00:34, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.63G/9.98G [01:50<05:12, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.65G/3.50G [01:50<00:34, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.63G/9.98G [01:51<04:33, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.65G/3.50G [01:50<00:29, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.63G/9.98G [01:51<03:56, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.64G/9.98G [01:51<04:21, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.66G/3.50G [01:50<00:38, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.66G/3.50G [01:50<00:31, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  26% 2.64G/9.98G [01:51<05:48, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.67G/3.50G [01:51<00:31, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.64G/9.98G [01:51<04:54, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.67G/3.50G [01:51<00:28, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.65G/9.98G [01:51<04:06, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.65G/9.98G [01:51<04:27, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.67G/3.50G [01:51<00:37, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  76% 2.68G/3.50G [01:51<00:31, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.66G/9.98G [01:52<05:48, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.68G/3.50G [01:51<00:29, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.66G/9.98G [01:52<05:06, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.68G/3.50G [01:51<00:31, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.66G/9.98G [01:52<04:22, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.67G/9.98G [01:52<04:21, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.69G/3.50G [01:51<00:37, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.69G/3.50G [01:52<00:31, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.67G/9.98G [01:52<05:29, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.70G/3.50G [01:52<00:29, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.98G [01:52<04:50, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.70G/3.50G [01:52<00:26, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.98G [01:52<04:02, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.68G/9.98G [01:53<04:25, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.71G/3.50G [01:52<00:33, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  77% 2.71G/3.50G [01:52<00:32, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.69G/9.98G [01:53<05:40, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.71G/3.50G [01:52<00:27, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.69G/9.98G [01:53<04:50, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.72G/3.50G [01:52<00:26, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.70G/9.98G [01:53<03:59, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.70G/9.98G [01:53<04:19, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.72G/3.50G [01:53<00:35, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.73G/3.50G [01:53<00:31, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.70G/9.98G [01:54<05:36, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.73G/3.50G [01:53<00:26, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.71G/9.98G [01:54<05:02, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.73G/3.50G [01:53<00:27, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.71G/9.98G [01:54<04:28, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.72G/9.98G [01:54<04:27, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.72G/9.98G [01:54<03:59, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.74G/3.50G [01:54<00:48, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.72G/9.98G [01:54<05:03, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.74G/3.50G [01:54<00:36, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.73G/9.98G [01:54<04:27, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  78% 2.74G/3.50G [01:54<00:31, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.73G/9.98G [01:54<04:52, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.75G/3.50G [01:54<00:34, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.73G/9.98G [01:55<04:11, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.75G/3.50G [01:54<00:50, 14.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.74G/9.98G [01:55<07:10, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.76G/3.50G [01:54<00:41, 17.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  27% 2.74G/9.98G [01:55<06:38, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.74G/9.98G [01:55<05:43, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.76G/3.50G [01:55<00:33, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [01:55<05:10, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.77G/3.50G [01:55<00:30, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [01:55<04:31, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.77G/3.50G [01:55<00:44, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.75G/9.98G [01:56<06:53, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.77G/3.50G [01:55<00:39, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.76G/9.98G [01:56<06:05, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.76G/9.98G [01:56<05:42, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.78G/3.50G [01:55<00:31, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.76G/9.98G [01:56<05:25, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  79% 2.78G/3.50G [01:56<00:28, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.77G/9.98G [01:56<04:51, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.78G/3.50G [01:56<00:34, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.77G/9.98G [01:56<05:32, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.79G/3.50G [01:56<00:29, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.77G/9.98G [01:57<04:38, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.79G/3.50G [01:56<00:26, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.78G/9.98G [01:57<04:52, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.80G/3.50G [01:56<00:24, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.78G/9.98G [01:57<04:17, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.80G/3.50G [01:56<00:31, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.79G/9.98G [01:57<05:34, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.80G/3.50G [01:57<00:28, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.79G/9.98G [01:57<05:23, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.79G/9.98G [01:57<04:41, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.81G/3.50G [01:57<00:27, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.79G/9.98G [01:57<04:22, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.81G/3.50G [01:57<00:23, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.80G/9.98G [01:57<03:47, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.80G/9.98G [01:58<04:22, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  80% 2.82G/3.50G [01:57<00:32, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.98G [01:58<03:52, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.82G/3.50G [01:57<00:25, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.98G [01:58<04:25, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.82G/3.50G [01:57<00:26, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.81G/9.98G [01:58<03:54, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.83G/3.50G [01:57<00:22, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.83G/3.50G [01:58<00:28, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.82G/9.98G [01:58<05:51, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.84G/3.50G [01:58<00:27, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.82G/9.98G [01:58<05:33, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.84G/3.50G [01:58<00:21, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.82G/9.98G [01:58<04:37, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.84G/3.50G [01:58<00:21, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.83G/9.98G [01:59<04:11, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.83G/9.98G [01:59<04:30, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.83G/9.98G [01:59<05:19, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.84G/9.98G [01:59<04:37, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  28% 2.84G/9.98G [01:59<04:48, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.85G/9.98G [01:59<04:11, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:00:07] Energy consumed for RAM : 0.029790 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:00:07] Energy consumed for all GPUs : 0.195385 kWh. Total GPU Power : 27.275000000000006 W\n",
            "[codecarbon INFO @ 16:00:07] Energy consumed for all CPUs : 0.132785 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:00:07] 0.357960 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  29% 2.85G/9.98G [02:00<05:24, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  29% 2.85G/9.98G [02:00<04:35, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.86G/9.98G [02:00<03:57, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.86G/9.98G [02:00<04:18, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.85G/3.50G [01:59<01:26, 7.51MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.86G/9.98G [02:00<05:54, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  81% 2.85G/3.50G [02:00<01:14, 8.72MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.87G/9.98G [02:00<05:08, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.86G/3.50G [02:00<00:56, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.87G/9.98G [02:00<04:44, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.88G/9.98G [02:00<04:04, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.86G/3.50G [02:00<00:47, 13.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.88G/9.98G [02:01<04:12, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.86G/3.50G [02:00<00:42, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.87G/3.50G [02:00<00:32, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.88G/9.98G [02:01<05:41, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.87G/3.50G [02:00<00:26, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.88G/3.50G [02:00<00:24, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.89G/9.98G [02:01<05:35, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.89G/9.98G [02:01<04:40, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.88G/3.50G [02:01<00:25, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.89G/9.98G [02:01<04:07, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.88G/3.50G [02:01<00:26, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  82% 2.89G/3.50G [02:01<00:25, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.98G [02:02<05:30, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.89G/3.50G [02:01<00:24, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.98G [02:02<05:08, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.90G/9.98G [02:02<04:35, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.90G/3.50G [02:01<00:22, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.91G/9.98G [02:02<04:27, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.90G/3.50G [02:01<00:26, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.91G/9.98G [02:02<04:18, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.90G/3.50G [02:01<00:24, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.91G/9.98G [02:02<04:35, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.91G/3.50G [02:02<00:23, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.92G/9.98G [02:02<04:32, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.92G/9.98G [02:02<03:55, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.91G/3.50G [02:02<00:21, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.93G/9.98G [02:02<03:38, 32.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.91G/3.50G [02:02<00:24, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.92G/3.50G [02:02<00:22, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.93G/9.98G [02:03<04:49, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  83% 2.92G/3.50G [02:02<00:22, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.94G/9.98G [02:03<04:48, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  29% 2.94G/9.98G [02:03<04:09, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.93G/3.50G [02:02<00:20, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.94G/9.98G [02:03<04:14, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.93G/3.50G [02:03<00:23, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.95G/9.98G [02:03<04:59, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.93G/3.50G [02:03<00:24, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.95G/9.98G [02:03<04:18, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.94G/3.50G [02:03<00:21, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.95G/9.98G [02:04<04:40, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.94G/3.50G [02:03<00:20, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.96G/9.98G [02:04<04:03, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.95G/3.50G [02:03<00:22, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.95G/3.50G [02:03<00:22, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.96G/9.98G [02:04<04:48, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.96G/9.98G [02:04<04:32, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.95G/3.50G [02:03<00:19, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.97G/9.98G [02:04<04:01, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  84% 2.96G/3.50G [02:03<00:18, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.96G/3.50G [02:04<00:18, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.97G/9.98G [02:04<04:12, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.96G/3.50G [02:04<00:20, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.97G/3.50G [02:04<00:19, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.98G/9.98G [02:04<05:33, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.98G/9.98G [02:05<04:42, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.97G/3.50G [02:04<00:19, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.98G/9.98G [02:05<04:01, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.98G/3.50G [02:04<00:18, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.99G/9.98G [02:05<04:14, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.98G/3.50G [02:04<00:21, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.98G/3.50G [02:04<00:20, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 2.99G/9.98G [02:05<05:41, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.99G/3.50G [02:05<00:19, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.00G/9.98G [02:05<05:00, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.00G/9.98G [02:05<04:19, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  85% 2.99G/3.50G [02:05<00:17, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.00G/9.98G [02:06<04:16, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 2.99G/3.50G [02:05<00:18, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.01G/9.98G [02:06<04:15, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.00G/3.50G [02:05<00:18, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.00G/3.50G [02:05<00:17, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.01G/9.98G [02:06<05:06, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.01G/9.98G [02:06<04:27, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.01G/3.50G [02:05<00:16, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.02G/9.98G [02:06<04:36, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.01G/3.50G [02:06<00:19, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.02G/9.98G [02:06<04:01, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.01G/3.50G [02:06<00:18, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.02G/3.50G [02:06<00:19, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.02G/3.50G [02:06<00:16, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.03G/9.98G [02:07<05:55, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.03G/9.98G [02:07<05:31, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.03G/9.98G [02:07<04:43, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.02G/3.50G [02:06<00:20, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  86% 3.03G/3.50G [02:06<00:19, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.04G/9.98G [02:07<04:30, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.03G/3.50G [02:06<00:14, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.04G/3.50G [02:06<00:16, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  30% 3.04G/9.98G [02:07<05:26, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.04G/9.98G [02:07<04:43, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.04G/3.50G [02:07<00:19, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.05G/9.98G [02:07<04:07, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.04G/3.50G [02:07<00:15, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.05G/9.98G [02:07<03:58, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.05G/3.50G [02:07<00:16, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.98G [02:08<04:11, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.05G/3.50G [02:07<00:14, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.98G [02:08<04:20, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.06G/9.98G [02:08<03:57, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.06G/3.50G [02:07<00:18, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.07G/9.98G [02:08<03:42, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  87% 3.06G/3.50G [02:07<00:17, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.07G/9.98G [02:08<04:06, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.06G/3.50G [02:07<00:14, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.07G/3.50G [02:08<00:14, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.07G/9.98G [02:08<05:17, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.07G/3.50G [02:08<00:14, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.08G/9.98G [02:08<04:40, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.08G/9.98G [02:08<04:02, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.07G/3.50G [02:08<00:17, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.08G/9.98G [02:09<03:32, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.08G/3.50G [02:08<00:17, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.09G/9.98G [02:09<04:03, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.08G/3.50G [02:08<00:16, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.09G/3.50G [02:08<00:13, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.09G/9.98G [02:09<04:40, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.09G/9.98G [02:09<04:26, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.09G/3.50G [02:09<00:18, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.10G/9.98G [02:09<04:31, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  88% 3.09G/3.50G [02:09<00:16, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.10G/9.98G [02:09<03:40, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.10G/3.50G [02:09<00:13, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.11G/9.98G [02:10<04:32, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.10G/3.50G [02:09<00:14, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.11G/9.98G [02:10<03:58, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.11G/9.98G [02:10<04:27, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.10G/3.50G [02:09<00:19, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.12G/9.98G [02:10<03:55, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.11G/3.50G [02:09<00:15, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.11G/3.50G [02:09<00:15, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.12G/9.98G [02:10<04:34, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.12G/3.50G [02:10<00:14, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.13G/9.98G [02:10<04:04, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.13G/9.98G [02:10<03:52, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.13G/9.98G [02:10<04:08, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.12G/3.50G [02:10<00:17, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.12G/3.50G [02:10<00:15, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.14G/9.98G [02:11<04:59, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  89% 3.13G/3.50G [02:10<00:13, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  31% 3.14G/9.98G [02:11<04:17, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.13G/3.50G [02:10<00:12, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.14G/9.98G [02:11<03:47, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.15G/9.98G [02:11<03:35, 31.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.14G/3.50G [02:10<00:15, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.15G/9.98G [02:11<03:54, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.14G/3.50G [02:11<00:13, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.15G/3.50G [02:11<00:13, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.15G/3.50G [02:11<00:12, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.15G/3.50G [02:11<00:14, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.16G/3.50G [02:11<00:13, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.16G/3.50G [02:11<00:13, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  90% 3.17G/3.50G [02:11<00:11, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.15G/9.98G [02:12<13:04, 8.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.16G/9.98G [02:12<12:31, 9.08MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.16G/9.98G [02:12<09:48, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.16G/9.98G [02:13<07:26, 15.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.17G/9.98G [02:13<06:35, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.17G/9.98G [02:13<06:35, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.17G/9.98G [02:13<05:23, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.17G/3.50G [02:12<00:35, 9.25MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.18G/9.98G [02:13<05:09, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.18G/9.98G [02:13<04:20, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.17G/3.50G [02:13<00:33, 9.91MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.17G/3.50G [02:13<00:27, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.98G [02:13<05:26, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.18G/3.50G [02:13<00:24, 13.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.98G [02:14<04:48, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.18G/3.50G [02:13<00:17, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.19G/9.98G [02:14<04:06, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.20G/9.98G [02:14<04:22, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.18G/3.50G [02:13<00:20, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.19G/3.50G [02:13<00:16, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.20G/9.98G [02:14<05:37, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.19G/3.50G [02:14<00:14, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.20G/9.98G [02:14<04:41, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  91% 3.20G/3.50G [02:14<00:12, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.21G/9.98G [02:14<04:05, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:00:22] Energy consumed for RAM : 0.029830 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:00:22] Energy consumed for all GPUs : 0.195500 kWh. Total GPU Power : 27.473000000000003 W\n",
            "[codecarbon INFO @ 16:00:22] Energy consumed for all CPUs : 0.132962 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:00:22] 0.358292 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  32% 3.21G/9.98G [02:14<04:08, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00002-of-00002.bin:  91% 3.20G/3.50G [02:14<00:14, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.20G/3.50G [02:14<00:11, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.21G/3.50G [02:14<00:09, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.22G/9.98G [02:15<05:16, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.21G/3.50G [02:14<00:09, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.22G/9.98G [02:15<04:28, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.22G/9.98G [02:15<03:55, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.22G/3.50G [02:14<00:09, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.23G/9.98G [02:15<04:02, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.22G/3.50G [02:14<00:11, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.22G/3.50G [02:15<00:10, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.23G/9.98G [02:15<05:08, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.23G/3.50G [02:15<00:10, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.24G/9.98G [02:15<04:24, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.23G/3.50G [02:15<00:09, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  32% 3.24G/9.98G [02:16<03:40, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.24G/9.98G [02:16<03:59, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.23G/3.50G [02:15<00:12, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  92% 3.24G/3.50G [02:15<00:10, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.25G/9.98G [02:16<05:14, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.24G/3.50G [02:15<00:10, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.25G/9.98G [02:16<04:25, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.25G/3.50G [02:15<00:08, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.26G/9.98G [02:16<03:45, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.26G/9.98G [02:16<04:01, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.25G/3.50G [02:16<00:11, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.25G/3.50G [02:16<00:09, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.26G/9.98G [02:17<04:57, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.26G/3.50G [02:16<00:08, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.27G/9.98G [02:17<04:27, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.26G/3.50G [02:16<00:08, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.27G/9.98G [02:17<03:46, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.28G/9.98G [02:17<03:56, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.26G/3.50G [02:16<00:10, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.28G/9.98G [02:17<03:44, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  93% 3.27G/3.50G [02:16<00:08, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.27G/3.50G [02:17<00:08, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.28G/9.98G [02:17<04:50, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.28G/3.50G [02:17<00:08, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.29G/9.98G [02:17<04:30, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.29G/9.98G [02:17<03:58, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.28G/3.50G [02:17<00:10, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.29G/9.98G [02:18<04:17, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.28G/3.50G [02:17<00:08, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.30G/9.98G [02:18<04:15, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.29G/3.50G [02:17<00:07, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.30G/9.98G [02:18<05:07, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.29G/3.50G [02:17<00:06, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.30G/9.98G [02:18<04:16, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.31G/9.98G [02:18<04:10, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.30G/3.50G [02:18<00:08, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.31G/9.98G [02:18<04:35, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.30G/3.50G [02:18<00:07, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.31G/9.98G [02:18<05:29, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  94% 3.31G/3.50G [02:18<00:07, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.32G/9.98G [02:19<04:38, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.31G/3.50G [02:18<00:06, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.32G/9.98G [02:19<03:47, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.31G/3.50G [02:18<00:08, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.32G/9.98G [02:19<04:02, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.32G/3.50G [02:18<00:07, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.33G/9.98G [02:19<03:59, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.33G/9.98G [02:19<04:28, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.32G/3.50G [02:18<00:06, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.33G/3.50G [02:19<00:06, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.33G/9.98G [02:19<04:34, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  33% 3.34G/9.98G [02:19<03:35, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.33G/3.50G [02:19<00:07, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.33G/3.50G [02:19<00:06, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.34G/9.98G [02:20<04:02, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.34G/3.50G [02:19<00:05, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.35G/9.98G [02:20<04:33, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  95% 3.34G/3.50G [02:19<00:05, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.35G/9.98G [02:20<04:20, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.35G/9.98G [02:20<04:26, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.34G/3.50G [02:19<00:07, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.36G/9.98G [02:20<03:43, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.35G/3.50G [02:20<00:06, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.35G/3.50G [02:20<00:05, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.36G/9.98G [02:20<04:45, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.36G/3.50G [02:20<00:04, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.36G/9.98G [02:20<04:00, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.36G/3.50G [02:20<00:05, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.37G/9.98G [02:21<03:58, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.37G/9.98G [02:21<03:30, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.36G/3.50G [02:20<00:06, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.36G/3.50G [02:20<00:06, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.38G/9.98G [02:21<04:08, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.38G/9.98G [02:21<04:02, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.37G/3.50G [02:20<00:05, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.38G/9.98G [02:21<03:47, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.37G/3.50G [02:20<00:04, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.39G/9.98G [02:21<03:59, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.39G/9.98G [02:21<03:45, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  96% 3.38G/3.50G [02:21<00:05, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.38G/3.50G [02:21<00:04, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.39G/9.98G [02:21<04:41, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.40G/9.98G [02:22<04:27, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.39G/3.50G [02:21<00:04, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.39G/3.50G [02:21<00:03, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.40G/9.98G [02:22<04:21, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.41G/9.98G [02:22<03:29, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.39G/3.50G [02:21<00:04, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.40G/3.50G [02:21<00:03, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.41G/9.98G [02:22<04:36, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.40G/3.50G [02:22<00:03, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.41G/9.98G [02:22<04:01, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.40G/3.50G [02:22<00:03, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.42G/9.98G [02:22<04:16, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.41G/3.50G [02:22<00:03, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.42G/9.98G [02:22<03:42, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  97% 3.41G/3.50G [02:22<00:03, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.43G/9.98G [02:23<04:41, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.41G/3.50G [02:22<00:04, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.43G/9.98G [02:23<04:06, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.42G/3.50G [02:22<00:03, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.43G/9.98G [02:23<03:44, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.42G/3.50G [02:22<00:02, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.44G/9.98G [02:23<04:04, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.43G/3.50G [02:23<00:02, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.43G/3.50G [02:23<00:02, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.43G/3.50G [02:23<00:02, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  34% 3.44G/9.98G [02:23<05:43, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.44G/9.98G [02:23<04:40, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.44G/3.50G [02:23<00:02, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [02:24<03:47, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.45G/9.98G [02:24<04:07, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.44G/3.50G [02:23<00:02, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  98% 3.44G/3.50G [02:23<00:02, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.46G/9.98G [02:24<05:32, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.45G/3.50G [02:23<00:01, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.46G/9.98G [02:24<04:33, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.45G/3.50G [02:23<00:01, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.46G/9.98G [02:24<03:49, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.47G/9.98G [02:24<04:05, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.46G/3.50G [02:24<00:02, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.46G/3.50G [02:24<00:01, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.46G/3.50G [02:24<00:01, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.47G/9.98G [02:25<05:15, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.47G/3.50G [02:24<00:01, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.48G/9.98G [02:25<04:26, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.48G/9.98G [02:25<03:43, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.47G/3.50G [02:24<00:01, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.48G/9.98G [02:25<03:58, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.47G/3.50G [02:24<00:01, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.48G/3.50G [02:24<00:00, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.49G/9.98G [02:25<05:00, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin:  99% 3.48G/3.50G [02:25<00:00, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.49G/9.98G [02:25<04:15, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.49G/3.50G [02:25<00:00, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.50G/9.98G [02:25<03:39, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.50G/9.98G [02:26<04:04, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.49G/3.50G [02:25<00:00, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.50G/9.98G [02:26<03:53, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.49G/3.50G [02:25<00:00, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [02:25<00:00, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.51G/9.98G [02:26<04:49, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [02:25<00:00, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00002-of-00002.bin: 100% 3.50G/3.50G [02:26<00:00, 24.0MB/s]\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.51G/9.98G [02:26<04:23, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.52G/9.98G [02:26<03:45, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.52G/9.98G [02:27<04:37, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.53G/9.98G [02:27<04:02, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.53G/9.98G [02:27<04:03, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.53G/9.98G [02:27<03:34, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  35% 3.54G/9.98G [02:27<04:36, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.54G/9.98G [02:27<03:58, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.55G/9.98G [02:27<04:04, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.55G/9.98G [02:28<03:35, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.55G/9.98G [02:28<04:50, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.56G/9.98G [02:28<04:05, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.56G/9.98G [02:28<04:11, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.57G/9.98G [02:28<03:40, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.57G/9.98G [02:28<04:35, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.57G/9.98G [02:28<03:58, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.58G/9.98G [02:29<04:03, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.58G/9.98G [02:29<03:33, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.59G/9.98G [02:29<04:12, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.59G/9.98G [02:29<03:42, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.59G/9.98G [02:29<03:22, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.60G/9.98G [02:29<03:41, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:00:37] Energy consumed for RAM : 0.029869 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:00:37] Energy consumed for all GPUs : 0.195614 kWh. Total GPU Power : 27.374000000000002 W\n",
            "[codecarbon INFO @ 16:00:37] Energy consumed for all CPUs : 0.133139 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:00:37] 0.358622 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  36% 3.60G/9.98G [02:30<05:00, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  36% 3.60G/9.98G [02:30<04:14, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.61G/9.98G [02:30<03:39, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.61G/9.98G [02:30<03:54, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.62G/9.98G [02:30<05:01, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.62G/9.98G [02:30<04:14, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.62G/9.98G [02:30<03:40, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.63G/9.98G [02:31<03:49, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.63G/9.98G [02:31<04:54, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.64G/9.98G [02:31<04:11, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  36% 3.64G/9.98G [02:31<03:40, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.64G/9.98G [02:31<03:47, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.65G/9.98G [02:31<05:13, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.65G/9.98G [02:32<04:25, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.98G [02:32<03:47, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.98G [02:32<03:34, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.66G/9.98G [02:32<03:47, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.67G/9.98G [02:32<04:30, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.67G/9.98G [02:32<03:50, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.67G/9.98G [02:32<04:14, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.68G/9.98G [02:32<03:39, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.68G/9.98G [02:33<04:54, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.69G/9.98G [02:33<04:12, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.69G/9.98G [02:33<03:33, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.69G/9.98G [02:33<03:49, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [02:33<05:13, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [02:33<04:24, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.70G/9.98G [02:34<03:46, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.71G/9.98G [02:34<03:56, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.71G/9.98G [02:34<04:46, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.72G/9.98G [02:34<04:05, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.72G/9.98G [02:34<03:32, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.72G/9.98G [02:34<03:41, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.73G/9.98G [02:35<04:37, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.73G/9.98G [02:35<03:56, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.74G/9.98G [02:35<03:26, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  37% 3.74G/9.98G [02:35<03:40, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.74G/9.98G [02:35<04:30, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.75G/9.98G [02:35<03:55, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.75G/9.98G [02:35<03:26, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.76G/9.98G [02:35<03:35, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.76G/9.98G [02:36<05:20, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.76G/9.98G [02:36<04:30, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.77G/9.98G [02:36<03:47, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.77G/9.98G [02:36<03:53, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.78G/9.98G [02:36<04:39, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.78G/9.98G [02:37<03:58, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.78G/9.98G [02:37<03:27, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.79G/9.98G [02:37<03:40, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.79G/9.98G [02:37<05:16, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.80G/9.98G [02:37<04:25, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.80G/9.98G [02:37<03:51, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.80G/9.98G [02:37<03:50, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.81G/9.98G [02:38<04:36, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.81G/9.98G [02:38<03:56, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.82G/9.98G [02:38<03:26, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.82G/9.98G [02:38<03:38, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.82G/9.98G [02:38<04:45, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.83G/9.98G [02:38<04:03, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.83G/9.98G [02:39<03:31, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.84G/9.98G [02:39<03:40, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  38% 3.84G/9.98G [02:39<04:43, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.84G/9.98G [02:39<04:00, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.85G/9.98G [02:39<03:30, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.85G/9.98G [02:39<03:39, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.86G/9.98G [02:40<08:21, 12.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.86G/9.98G [02:40<06:26, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.86G/9.98G [02:40<05:29, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.87G/9.98G [02:40<05:13, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.87G/9.98G [02:41<04:23, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.87G/9.98G [02:41<04:38, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.88G/9.98G [02:41<04:29, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.88G/9.98G [02:41<03:48, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.89G/9.98G [02:41<03:47, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.89G/9.98G [02:41<04:20, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.89G/9.98G [02:41<03:45, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.90G/9.98G [02:42<04:03, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.90G/9.98G [02:42<03:30, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.91G/9.98G [02:42<05:19, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.91G/9.98G [02:42<04:26, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.91G/9.98G [02:42<04:13, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.92G/9.98G [02:42<03:37, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.92G/9.98G [02:43<04:41, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.93G/9.98G [02:43<04:02, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.93G/9.98G [02:43<03:27, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.93G/9.98G [02:43<03:41, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  39% 3.94G/9.98G [02:43<05:21, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.94G/9.98G [02:43<04:20, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.94G/9.98G [02:43<03:48, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.95G/9.98G [02:44<04:07, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.95G/9.98G [02:44<03:41, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.96G/9.98G [02:44<07:09, 14.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.96G/9.98G [02:44<05:44, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:00:52] Energy consumed for RAM : 0.029909 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:00:52] Energy consumed for all GPUs : 0.195728 kWh. Total GPU Power : 27.473000000000003 W\n",
            "[codecarbon INFO @ 16:00:52] Energy consumed for all CPUs : 0.133316 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:00:52] 0.358953 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  40% 3.96G/9.98G [02:45<05:33, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.97G/9.98G [02:45<04:31, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.97G/9.98G [02:45<05:18, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.97G/9.98G [02:45<04:12, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.98G/9.98G [02:45<03:33, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.98G/9.98G [02:45<03:45, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.98G/9.98G [02:45<04:53, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.99G/9.98G [02:46<04:02, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 3.99G/9.98G [02:46<03:35, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.00G/9.98G [02:46<03:47, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.00G/9.98G [02:46<04:39, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.00G/9.98G [02:46<03:56, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.01G/9.98G [02:46<03:25, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.01G/9.98G [02:46<03:33, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.02G/9.98G [02:47<04:27, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.02G/9.98G [02:47<03:47, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.02G/9.98G [02:47<03:18, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.03G/9.98G [02:47<03:31, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.03G/9.98G [02:47<04:33, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.04G/9.98G [02:47<03:54, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  40% 4.04G/9.98G [02:47<03:23, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.04G/9.98G [02:48<03:32, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.05G/9.98G [02:48<04:01, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.05G/9.98G [02:48<03:32, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.06G/9.98G [02:48<03:07, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.06G/9.98G [02:48<03:21, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.06G/9.98G [02:49<04:48, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.07G/9.98G [02:49<04:02, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.07G/9.98G [02:49<03:27, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.08G/9.98G [02:49<03:37, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.08G/9.98G [02:49<04:30, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.08G/9.98G [02:49<03:52, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.09G/9.98G [02:49<03:25, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.09G/9.98G [02:49<03:29, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.10G/9.98G [02:50<04:32, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.10G/9.98G [02:50<03:51, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.10G/9.98G [02:50<03:21, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.11G/9.98G [02:50<03:31, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.11G/9.98G [02:50<04:19, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.12G/9.98G [02:50<03:42, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.12G/9.98G [02:51<03:12, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.12G/9.98G [02:51<03:27, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.13G/9.98G [02:51<03:56, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.13G/9.98G [02:51<03:26, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.14G/9.98G [02:51<03:05, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  41% 4.14G/9.98G [02:51<03:17, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.14G/9.98G [02:51<04:07, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.15G/9.98G [02:52<03:34, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.15G/9.98G [02:52<03:08, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.16G/9.98G [02:52<03:21, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.16G/9.98G [02:52<04:36, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.16G/9.98G [02:52<03:56, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.17G/9.98G [02:52<03:22, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.17G/9.98G [02:52<03:30, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.18G/9.98G [02:53<04:19, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.18G/9.98G [02:53<03:43, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.18G/9.98G [02:53<03:12, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.19G/9.98G [02:53<03:25, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.19G/9.98G [02:53<04:25, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.20G/9.98G [02:53<03:49, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.20G/9.98G [02:54<03:20, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.20G/9.98G [02:54<03:25, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.21G/9.98G [02:54<04:37, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.21G/9.98G [02:54<03:55, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.22G/9.98G [02:54<03:26, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.22G/9.98G [02:54<03:29, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.22G/9.98G [02:55<04:20, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.23G/9.98G [02:55<03:42, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.23G/9.98G [02:55<03:15, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.24G/9.98G [02:55<03:02, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  42% 4.24G/9.98G [02:55<03:17, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.24G/9.98G [02:55<03:55, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.25G/9.98G [02:55<03:58, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.25G/9.98G [02:56<03:22, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.26G/9.98G [02:56<03:03, 31.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.26G/9.98G [02:56<04:09, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.26G/9.98G [02:56<03:40, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.27G/9.98G [02:56<03:53, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.27G/9.98G [02:56<03:19, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.27G/9.98G [02:57<04:48, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.28G/9.98G [02:57<04:05, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.28G/9.98G [02:57<03:54, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.29G/9.98G [02:57<03:21, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.29G/9.98G [02:57<04:35, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.29G/9.98G [02:57<03:54, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.30G/9.98G [02:57<03:51, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.30G/9.98G [02:58<03:22, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.31G/9.98G [02:58<04:39, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.31G/9.98G [02:58<03:56, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.31G/9.98G [02:58<03:25, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.32G/9.98G [02:58<03:36, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.32G/9.98G [02:58<04:46, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.32G/9.98G [02:59<03:55, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.33G/9.98G [02:59<03:20, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.33G/9.98G [02:59<03:29, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  43% 4.34G/9.98G [02:59<04:29, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.34G/9.98G [02:59<03:48, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.34G/9.98G [02:59<03:17, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.35G/9.98G [02:59<03:24, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:01:07] Energy consumed for RAM : 0.029949 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:01:07] Energy consumed for all GPUs : 0.195841 kWh. Total GPU Power : 27.192 W\n",
            "[codecarbon INFO @ 16:01:07] Energy consumed for all CPUs : 0.133493 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:01:07] 0.359283 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  44% 4.35G/9.98G [03:00<04:20, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  44% 4.36G/9.98G [03:00<03:42, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.36G/9.98G [03:00<03:13, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.36G/9.98G [03:00<03:21, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.37G/9.98G [03:00<04:07, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.37G/9.98G [03:00<03:34, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.38G/9.98G [03:01<03:04, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.38G/9.98G [03:01<03:16, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.38G/9.98G [03:01<04:00, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.39G/9.98G [03:01<03:28, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.39G/9.98G [03:01<03:11, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.40G/9.98G [03:01<03:11, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.40G/9.98G [03:02<04:00, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.40G/9.98G [03:02<03:29, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.41G/9.98G [03:02<03:02, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.41G/9.98G [03:02<03:14, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.42G/9.98G [03:02<03:43, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.42G/9.98G [03:02<03:16, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.42G/9.98G [03:02<02:52, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.43G/9.98G [03:02<03:07, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.43G/9.98G [03:03<03:54, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  44% 4.44G/9.98G [03:03<03:25, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.44G/9.98G [03:03<03:02, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.44G/9.98G [03:03<03:09, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.45G/9.98G [03:03<04:09, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.45G/9.98G [03:03<03:34, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.46G/9.98G [03:03<03:08, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.46G/9.98G [03:04<03:15, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.46G/9.98G [03:04<03:03, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.47G/9.98G [03:04<03:39, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.47G/9.98G [03:04<03:46, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.48G/9.98G [03:04<03:15, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.48G/9.98G [03:04<02:55, 31.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.48G/9.98G [03:05<03:46, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.49G/9.98G [03:05<03:47, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.49G/9.98G [03:05<03:17, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.50G/9.98G [03:05<03:15, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.50G/9.98G [03:05<03:52, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.50G/9.98G [03:05<03:19, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.51G/9.98G [03:05<03:38, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.51G/9.98G [03:06<03:08, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.51G/9.98G [03:06<04:12, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.52G/9.98G [03:06<03:23, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.52G/9.98G [03:06<03:14, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.52G/9.98G [03:06<03:26, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.53G/9.98G [03:06<04:25, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.53G/9.98G [03:06<03:41, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  45% 4.54G/9.98G [03:07<03:09, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.54G/9.98G [03:07<03:16, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.54G/9.98G [03:07<04:15, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.55G/9.98G [03:07<03:38, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.55G/9.98G [03:07<03:09, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.56G/9.98G [03:07<03:14, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.56G/9.98G [03:08<04:13, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.56G/9.98G [03:08<03:36, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.57G/9.98G [03:08<03:05, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.57G/9.98G [03:08<03:16, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.58G/9.98G [03:08<03:43, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.58G/9.98G [03:08<03:16, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.58G/9.98G [03:08<02:56, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.59G/9.98G [03:09<03:02, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.59G/9.98G [03:09<04:51, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.60G/9.98G [03:09<04:02, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.60G/9.98G [03:09<03:25, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.60G/9.98G [03:09<03:27, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.61G/9.98G [03:10<10:36, 8.43MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.61G/9.98G [03:11<08:35, 10.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.62G/9.98G [03:11<07:00, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.62G/9.98G [03:11<05:11, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.62G/9.98G [03:11<05:01, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.63G/9.98G [03:11<04:50, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.63G/9.98G [03:11<03:59, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.63G/9.98G [03:11<03:54, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  46% 4.64G/9.98G [03:12<03:19, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.64G/9.98G [03:12<04:29, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.65G/9.98G [03:12<03:42, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.65G/9.98G [03:12<03:41, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.65G/9.98G [03:12<03:09, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.66G/9.98G [03:12<04:00, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.66G/9.98G [03:13<03:29, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.67G/9.98G [03:13<03:06, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.67G/9.98G [03:13<03:18, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.67G/9.98G [03:13<04:15, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.68G/9.98G [03:13<03:34, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.68G/9.98G [03:13<03:01, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.68G/9.98G [03:13<03:11, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.69G/9.98G [03:14<04:01, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.69G/9.98G [03:14<03:25, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.70G/9.98G [03:14<02:55, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.70G/9.98G [03:14<03:08, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.70G/9.98G [03:14<04:07, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.71G/9.98G [03:14<03:30, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:01:22] Energy consumed for RAM : 0.029988 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:01:22] Energy consumed for all GPUs : 0.195955 kWh. Total GPU Power : 27.275000000000006 W\n",
            "[codecarbon INFO @ 16:01:22] Energy consumed for all CPUs : 0.133670 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:01:22] 0.359614 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  47% 4.71G/9.98G [03:14<02:58, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.72G/9.98G [03:15<03:09, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.72G/9.98G [03:15<03:58, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.72G/9.98G [03:15<03:24, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.73G/9.98G [03:15<02:56, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.73G/9.98G [03:15<03:06, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  47% 4.74G/9.98G [03:15<03:55, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.74G/9.98G [03:16<03:22, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.74G/9.98G [03:16<02:57, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.75G/9.98G [03:16<03:04, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.75G/9.98G [03:17<07:02, 12.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.75G/9.98G [03:17<09:34, 9.10MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.76G/9.98G [03:17<08:44, 9.94MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.76G/9.98G [03:17<06:49, 12.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.76G/9.98G [03:17<05:40, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.77G/9.98G [03:18<05:40, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.77G/9.98G [03:18<04:32, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.78G/9.98G [03:18<03:47, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.78G/9.98G [03:18<03:37, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.78G/9.98G [03:18<04:32, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.79G/9.98G [03:19<03:48, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.79G/9.98G [03:19<03:15, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.80G/9.98G [03:19<03:16, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.80G/9.98G [03:19<03:45, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.80G/9.98G [03:19<03:16, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.81G/9.98G [03:19<02:53, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.81G/9.98G [03:19<02:41, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.82G/9.98G [03:19<02:55, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.82G/9.98G [03:20<03:20, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.82G/9.98G [03:20<03:04, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.83G/9.98G [03:20<03:20, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.83G/9.98G [03:20<02:55, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.83G/9.98G [03:20<04:01, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  48% 4.84G/9.98G [03:20<03:27, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.84G/9.98G [03:20<03:00, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.84G/9.98G [03:21<03:13, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.85G/9.98G [03:21<04:26, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.85G/9.98G [03:21<03:41, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.86G/9.98G [03:21<03:09, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.86G/9.98G [03:21<02:49, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.86G/9.98G [03:21<03:02, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.87G/9.98G [03:22<03:52, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.87G/9.98G [03:22<03:17, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.87G/9.98G [03:22<03:37, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.88G/9.98G [03:22<03:06, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.88G/9.98G [03:22<04:02, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.89G/9.98G [03:22<03:26, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.89G/9.98G [03:22<02:57, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.89G/9.98G [03:23<03:12, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.90G/9.98G [03:23<04:15, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.90G/9.98G [03:23<03:32, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.90G/9.98G [03:23<03:02, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.91G/9.98G [03:23<03:07, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.91G/9.98G [03:23<04:03, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.92G/9.98G [03:24<03:27, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.92G/9.98G [03:24<02:58, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.92G/9.98G [03:24<03:04, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.93G/9.98G [03:24<03:53, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.93G/9.98G [03:24<03:20, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  49% 4.94G/9.98G [03:24<02:56, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.94G/9.98G [03:24<03:10, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.94G/9.98G [03:25<02:54, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.95G/9.98G [03:25<05:25, 15.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.95G/9.98G [03:25<04:53, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.96G/9.98G [03:25<03:59, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.96G/9.98G [03:25<03:23, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.96G/9.98G [03:26<03:45, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.97G/9.98G [03:26<03:12, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.97G/9.98G [03:26<03:24, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.97G/9.98G [03:26<02:58, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.98G/9.98G [03:26<03:56, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.98G/9.98G [03:26<03:21, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.99G/9.98G [03:26<02:56, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.99G/9.98G [03:27<03:19, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 4.99G/9.98G [03:27<05:36, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.00G/9.98G [03:27<04:28, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.00G/9.98G [03:27<03:40, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.00G/9.98G [03:27<03:07, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.01G/9.98G [03:27<03:16, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.01G/9.98G [03:28<03:19, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.02G/9.98G [03:28<02:53, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.02G/9.98G [03:28<03:15, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.02G/9.98G [03:28<02:51, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.03G/9.98G [03:28<03:21, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.03G/9.98G [03:28<02:57, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.03G/9.98G [03:28<02:40, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  50% 5.04G/9.98G [03:29<02:56, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.04G/9.98G [03:29<04:06, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.04G/9.98G [03:29<03:27, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.05G/9.98G [03:29<03:01, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.05G/9.98G [03:29<02:41, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.06G/9.98G [03:29<02:55, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:01:37] Energy consumed for RAM : 0.030028 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:01:37] Energy consumed for all GPUs : 0.196069 kWh. Total GPU Power : 27.473000000000003 W\n",
            "[codecarbon INFO @ 16:01:37] Energy consumed for all CPUs : 0.133847 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:01:37] 0.359945 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  51% 5.06G/9.98G [03:29<03:15, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.06G/9.98G [03:29<02:50, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.07G/9.98G [03:30<03:10, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.07G/9.98G [03:30<02:49, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.07G/9.98G [03:30<03:32, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.08G/9.98G [03:30<02:58, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.08G/9.98G [03:30<02:45, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.08G/9.98G [03:30<02:59, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.09G/9.98G [03:31<03:29, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.09G/9.98G [03:31<03:00, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.10G/9.98G [03:31<02:37, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.10G/9.98G [03:31<02:27, 33.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.10G/9.98G [03:31<02:46, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.11G/9.98G [03:31<03:20, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.11G/9.98G [03:31<03:25, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.11G/9.98G [03:31<02:59, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.12G/9.98G [03:32<02:38, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.12G/9.98G [03:32<03:19, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.13G/9.98G [03:32<02:53, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.13G/9.98G [03:32<03:09, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.13G/9.98G [03:32<02:47, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  51% 5.14G/9.98G [03:32<04:04, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.14G/9.98G [03:33<03:29, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.14G/9.98G [03:33<03:08, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.15G/9.98G [03:33<03:11, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.15G/9.98G [03:33<04:02, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.16G/9.98G [03:33<03:28, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.16G/9.98G [03:33<03:00, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.16G/9.98G [03:33<02:38, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.17G/9.98G [03:34<02:55, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.17G/9.98G [03:34<03:48, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.17G/9.98G [03:34<03:11, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.18G/9.98G [03:34<03:24, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.18G/9.98G [03:34<02:55, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.19G/9.98G [03:35<04:43, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.19G/9.98G [03:35<03:48, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.19G/9.98G [03:35<03:46, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.20G/9.98G [03:35<03:11, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.20G/9.98G [03:36<06:21, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.20G/9.98G [03:36<04:55, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.21G/9.98G [03:36<03:58, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.21G/9.98G [03:36<03:52, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.22G/9.98G [03:36<04:25, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.22G/9.98G [03:36<03:40, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.22G/9.98G [03:36<03:09, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.23G/9.98G [03:37<03:05, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.23G/9.98G [03:37<03:53, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  52% 5.24G/9.98G [03:37<03:22, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.24G/9.98G [03:37<02:55, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.24G/9.98G [03:37<02:39, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.25G/9.98G [03:37<02:34, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.25G/9.98G [03:38<03:53, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.25G/9.98G [03:38<03:26, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.26G/9.98G [03:38<03:38, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.26G/9.98G [03:38<03:17, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.26G/9.98G [03:38<03:02, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.27G/9.98G [03:38<03:51, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.27G/9.98G [03:38<03:12, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.27G/9.98G [03:38<03:20, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.28G/9.98G [03:39<02:55, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.28G/9.98G [03:39<03:59, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.29G/9.98G [03:39<03:19, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.29G/9.98G [03:39<02:48, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.29G/9.98G [03:39<03:04, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.30G/9.98G [03:39<04:03, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.30G/9.98G [03:40<03:27, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.30G/9.98G [03:40<03:40, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.31G/9.98G [03:40<03:13, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.31G/9.98G [03:40<03:19, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.31G/9.98G [03:40<03:25, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.31G/9.98G [03:40<04:48, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.32G/9.98G [03:40<03:43, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.32G/9.98G [03:41<03:38, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.33G/9.98G [03:41<02:48, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.33G/9.98G [03:41<03:59, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  53% 5.33G/9.98G [03:41<03:21, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.34G/9.98G [03:41<03:26, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.34G/9.98G [03:41<02:56, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.35G/9.98G [03:42<03:41, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.35G/9.98G [03:42<03:06, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.35G/9.98G [03:42<02:43, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.36G/9.98G [03:42<02:55, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.36G/9.98G [03:42<03:57, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.36G/9.98G [03:42<03:17, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.37G/9.98G [03:43<02:47, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.37G/9.98G [03:43<02:52, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.38G/9.98G [03:43<03:45, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.38G/9.98G [03:43<03:10, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.38G/9.98G [03:43<02:45, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.39G/9.98G [03:43<02:48, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.39G/9.98G [03:44<03:23, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.40G/9.98G [03:44<02:56, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.40G/9.98G [03:44<02:36, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.40G/9.98G [03:44<02:41, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.41G/9.98G [03:44<03:36, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.41G/9.98G [03:44<03:05, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:01:52] Energy consumed for RAM : 0.030068 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:01:52] Energy consumed for all GPUs : 0.196183 kWh. Total GPU Power : 27.29 W\n",
            "[codecarbon INFO @ 16:01:52] Energy consumed for all CPUs : 0.134024 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:01:52] 0.360275 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  54% 5.42G/9.98G [03:44<02:41, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.42G/9.98G [03:45<02:45, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.42G/9.98G [03:45<03:34, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.43G/9.98G [03:45<03:03, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.43G/9.98G [03:45<02:40, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  54% 5.44G/9.98G [03:45<02:44, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.44G/9.98G [03:45<03:24, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.44G/9.98G [03:46<02:56, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.45G/9.98G [03:46<02:40, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.45G/9.98G [03:46<02:39, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.46G/9.98G [03:46<03:28, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.46G/9.98G [03:46<03:00, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.46G/9.98G [03:46<02:36, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.47G/9.98G [03:46<02:42, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.47G/9.98G [03:47<03:30, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.48G/9.98G [03:47<03:01, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.48G/9.98G [03:47<02:37, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.48G/9.98G [03:47<02:25, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.49G/9.98G [03:47<02:47, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.49G/9.98G [03:47<03:06, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.49G/9.98G [03:47<02:47, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.50G/9.98G [03:48<02:57, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.50G/9.98G [03:48<02:34, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.51G/9.98G [03:48<03:03, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.51G/9.98G [03:48<02:41, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.51G/9.98G [03:48<02:26, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.52G/9.98G [03:48<02:41, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.52G/9.98G [03:49<03:46, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.52G/9.98G [03:49<03:08, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.53G/9.98G [03:49<02:42, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.53G/9.98G [03:49<02:25, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  55% 5.54G/9.98G [03:49<02:37, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.54G/9.98G [03:49<03:23, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.54G/9.98G [03:49<03:18, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.55G/9.98G [03:50<02:47, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.55G/9.98G [03:50<02:31, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.55G/9.98G [03:50<03:19, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.56G/9.98G [03:50<02:50, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.56G/9.98G [03:50<02:41, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.56G/9.98G [03:50<02:52, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.57G/9.98G [03:50<03:37, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.57G/9.98G [03:51<03:01, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.58G/9.98G [03:51<02:36, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.58G/9.98G [03:51<02:42, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.58G/9.98G [03:51<04:21, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.59G/9.98G [03:51<03:31, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.59G/9.98G [03:51<03:12, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.60G/9.98G [03:52<03:08, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.60G/9.98G [03:52<02:44, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.60G/9.98G [03:52<03:09, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.61G/9.98G [03:52<02:47, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.61G/9.98G [03:52<02:59, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.61G/9.98G [03:52<02:35, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.62G/9.98G [03:53<03:25, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.62G/9.98G [03:53<02:53, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.63G/9.98G [03:53<02:32, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.63G/9.98G [03:53<02:46, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.63G/9.98G [03:53<03:55, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  56% 5.64G/9.98G [03:53<03:13, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.64G/9.98G [03:53<02:44, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.64G/9.98G [03:54<02:44, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.65G/9.98G [03:54<03:18, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.65G/9.98G [03:54<02:51, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.66G/9.98G [03:54<02:31, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.66G/9.98G [03:54<02:16, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.66G/9.98G [03:54<02:28, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.67G/9.98G [03:54<03:02, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.67G/9.98G [03:55<02:41, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.67G/9.98G [03:55<02:56, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.68G/9.98G [03:55<02:34, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.68G/9.98G [03:55<03:09, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.69G/9.98G [03:55<02:38, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.69G/9.98G [03:55<02:23, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.69G/9.98G [03:55<02:35, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.70G/9.98G [03:56<03:20, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.70G/9.98G [03:56<02:54, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.70G/9.98G [03:56<02:29, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.71G/9.98G [03:56<02:13, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.71G/9.98G [03:56<02:25, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.72G/9.98G [03:56<03:02, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.72G/9.98G [03:56<03:03, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.72G/9.98G [03:57<02:38, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.73G/9.98G [03:57<02:23, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.73G/9.98G [03:57<03:19, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  57% 5.73G/9.98G [03:57<02:52, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.74G/9.98G [03:57<02:54, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.74G/9.98G [03:57<02:31, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.75G/9.98G [03:58<03:21, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.75G/9.98G [03:58<02:51, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.75G/9.98G [03:58<02:32, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.76G/9.98G [03:58<02:42, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.76G/9.98G [03:58<03:22, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.76G/9.98G [03:58<02:52, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.77G/9.98G [03:58<02:30, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.77G/9.98G [03:59<02:31, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.78G/9.98G [03:59<03:14, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.78G/9.98G [03:59<02:46, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.78G/9.98G [03:59<02:23, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.79G/9.98G [03:59<02:16, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.79G/9.98G [03:59<02:27, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:02:07] Energy consumed for RAM : 0.030108 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:02:07] Energy consumed for all GPUs : 0.196297 kWh. Total GPU Power : 27.389 W\n",
            "[codecarbon INFO @ 16:02:07] Energy consumed for all CPUs : 0.134201 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:02:07] 0.360606 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  58% 5.79G/9.98G [03:59<02:53, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  58% 5.80G/9.98G [04:00<02:36, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.80G/9.98G [04:00<02:45, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.81G/9.98G [04:00<02:59, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.81G/9.98G [04:00<04:29, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.81G/9.98G [04:00<03:31, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.82G/9.98G [04:00<02:48, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.82G/9.98G [04:01<03:05, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.82G/9.98G [04:01<02:46, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.83G/9.98G [04:01<03:05, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.83G/9.98G [04:01<02:40, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.83G/9.98G [04:01<02:56, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  58% 5.84G/9.98G [04:01<02:48, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.84G/9.98G [04:01<02:34, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.84G/9.98G [04:02<03:32, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.85G/9.98G [04:02<02:51, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.85G/9.98G [04:02<03:07, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.85G/9.98G [04:02<02:38, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.86G/9.98G [04:02<03:16, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.86G/9.98G [04:02<02:46, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.86G/9.98G [04:02<02:21, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.87G/9.98G [04:03<02:37, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.87G/9.98G [04:03<02:29, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.87G/9.98G [04:03<02:52, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.88G/9.98G [04:03<02:28, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.88G/9.98G [04:03<02:47, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.89G/9.98G [04:03<02:26, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.89G/9.98G [04:03<03:09, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.89G/9.98G [04:04<02:39, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.90G/9.98G [04:04<02:19, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.90G/9.98G [04:04<02:33, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.90G/9.98G [04:04<03:08, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.91G/9.98G [04:04<02:42, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.91G/9.98G [04:04<02:19, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.92G/9.98G [04:04<02:27, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.92G/9.98G [04:05<03:14, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.92G/9.98G [04:05<02:44, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.93G/9.98G [04:05<02:23, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.93G/9.98G [04:05<02:12, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  59% 5.94G/9.98G [04:05<02:27, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.94G/9.98G [04:05<02:59, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.94G/9.98G [04:05<02:42, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.95G/9.98G [04:06<02:48, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.95G/9.98G [04:06<02:28, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.95G/9.98G [04:06<03:20, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.96G/9.98G [04:06<02:46, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.96G/9.98G [04:06<02:32, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.96G/9.98G [04:06<02:13, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.97G/9.98G [04:06<02:30, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.97G/9.98G [04:07<03:12, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.97G/9.98G [04:07<03:15, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.98G/9.98G [04:07<02:40, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.98G/9.98G [04:07<02:58, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.98G/9.98G [04:07<04:18, 15.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.99G/9.98G [04:08<03:20, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 5.99G/9.98G [04:08<03:08, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.00G/9.98G [04:08<03:02, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.00G/9.98G [04:08<04:00, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.00G/9.98G [04:08<03:12, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.01G/9.98G [04:08<02:41, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.01G/9.98G [04:09<02:54, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.01G/9.98G [04:09<03:02, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.02G/9.98G [04:09<03:51, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.02G/9.98G [04:09<03:06, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.02G/9.98G [04:09<03:08, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.03G/9.98G [04:09<03:03, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  60% 6.03G/9.98G [04:10<04:12, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.04G/9.98G [04:10<03:19, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.04G/9.98G [04:10<02:45, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.04G/9.98G [04:10<03:04, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.05G/9.98G [04:10<02:40, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.05G/9.98G [04:11<03:06, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.05G/9.98G [04:11<02:39, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.06G/9.98G [04:11<02:54, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.06G/9.98G [04:11<02:52, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.06G/9.98G [04:11<02:27, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.07G/9.98G [04:11<03:18, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.07G/9.98G [04:11<03:06, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.07G/9.98G [04:12<02:33, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.08G/9.98G [04:12<02:30, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.08G/9.98G [04:12<03:49, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.08G/9.98G [04:12<03:03, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.09G/9.98G [04:12<02:53, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.09G/9.98G [04:12<02:46, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.10G/9.98G [04:12<02:25, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.10G/9.98G [04:13<02:54, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.10G/9.98G [04:13<02:52, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.11G/9.98G [04:13<02:21, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.11G/9.98G [04:13<02:49, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.11G/9.98G [04:14<05:03, 12.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.12G/9.98G [04:14<04:37, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.12G/9.98G [04:14<03:38, 17.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.12G/9.98G [04:14<02:51, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.13G/9.98G [04:14<03:04, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.13G/9.98G [04:14<03:57, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:02:22] Energy consumed for RAM : 0.030147 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:02:22] Energy consumed for all GPUs : 0.196412 kWh. Total GPU Power : 27.670000000000005 W\n",
            "[codecarbon INFO @ 16:02:22] Energy consumed for all CPUs : 0.134379 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:02:22] 0.360938 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  61% 6.13G/9.98G [04:15<03:22, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.14G/9.98G [04:15<03:09, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.14G/9.98G [04:15<03:00, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.14G/9.98G [04:15<02:35, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.15G/9.98G [04:15<03:07, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.15G/9.98G [04:15<02:33, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.15G/9.98G [04:15<02:48, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.16G/9.98G [04:16<02:44, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.16G/9.98G [04:16<02:21, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.16G/9.98G [04:16<03:00, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.17G/9.98G [04:16<02:41, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.17G/9.98G [04:16<02:47, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.17G/9.98G [04:16<02:44, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.18G/9.98G [04:16<02:24, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.18G/9.98G [04:17<03:18, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.18G/9.98G [04:17<02:41, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.19G/9.98G [04:17<02:51, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.19G/9.98G [04:17<02:44, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.19G/9.98G [04:17<02:22, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.19G/9.98G [04:17<03:10, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.20G/9.98G [04:17<02:58, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.20G/9.98G [04:18<02:24, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.21G/9.98G [04:18<02:19, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.21G/9.98G [04:18<03:21, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.21G/9.98G [04:18<02:43, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.22G/9.98G [04:18<02:42, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.22G/9.98G [04:18<02:37, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.22G/9.98G [04:18<02:18, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.23G/9.98G [04:19<03:08, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.23G/9.98G [04:19<02:59, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  62% 6.23G/9.98G [04:19<02:27, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.24G/9.98G [04:19<02:23, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.24G/9.98G [04:19<03:30, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.24G/9.98G [04:19<02:48, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.25G/9.98G [04:20<02:42, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.25G/9.98G [04:20<02:36, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.26G/9.98G [04:20<02:23, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.26G/9.98G [04:20<03:10, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.26G/9.98G [04:20<02:36, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.27G/9.98G [04:20<02:47, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.27G/9.98G [04:20<02:46, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.27G/9.98G [04:21<02:24, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.27G/9.98G [04:21<03:15, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.28G/9.98G [04:21<02:36, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.28G/9.98G [04:21<02:49, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.28G/9.98G [04:21<02:48, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.29G/9.98G [04:21<02:27, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.29G/9.98G [04:21<02:46, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.29G/9.98G [04:22<02:21, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.30G/9.98G [04:22<02:35, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.30G/9.98G [04:22<02:31, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.30G/9.98G [04:22<02:14, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.31G/9.98G [04:22<03:14, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.31G/9.98G [04:22<02:58, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.31G/9.98G [04:22<02:25, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.32G/9.98G [04:23<02:25, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.32G/9.98G [04:23<03:09, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.32G/9.98G [04:23<02:34, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.33G/9.98G [04:23<02:29, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  63% 6.33G/9.98G [04:23<02:26, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.34G/9.98G [04:23<02:14, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.34G/9.98G [04:24<03:35, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.34G/9.98G [04:24<02:48, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.35G/9.98G [04:24<02:57, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.35G/9.98G [04:24<02:48, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.35G/9.98G [04:24<02:25, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.35G/9.98G [04:25<07:38, 7.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.36G/9.98G [04:25<06:01, 10.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.36G/9.98G [04:25<05:39, 10.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.36G/9.98G [04:26<04:10, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.37G/9.98G [04:26<03:35, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.37G/9.98G [04:26<03:38, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.37G/9.98G [04:26<02:52, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.98G [04:26<02:23, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.98G [04:26<02:29, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.38G/9.98G [04:26<03:09, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.39G/9.98G [04:27<02:33, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.39G/9.98G [04:27<02:13, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.40G/9.98G [04:27<02:12, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.40G/9.98G [04:27<02:33, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.40G/9.98G [04:27<02:13, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.41G/9.98G [04:27<01:57, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.41G/9.98G [04:27<02:02, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.42G/9.98G [04:28<02:44, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.42G/9.98G [04:28<02:19, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.42G/9.98G [04:28<01:58, 29.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.43G/9.98G [04:28<02:07, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  64% 6.43G/9.98G [04:28<02:45, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.44G/9.98G [04:28<02:21, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.44G/9.98G [04:28<01:57, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.44G/9.98G [04:29<02:06, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.45G/9.98G [04:29<02:49, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.45G/9.98G [04:29<02:23, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.46G/9.98G [04:29<01:59, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.46G/9.98G [04:29<02:07, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:02:37] Energy consumed for RAM : 0.030187 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:02:37] Energy consumed for all GPUs : 0.196527 kWh. Total GPU Power : 27.654 W\n",
            "[codecarbon INFO @ 16:02:37] Energy consumed for all CPUs : 0.134556 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:02:37] 0.361270 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  65% 6.46G/9.98G [04:29<02:36, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  65% 6.47G/9.98G [04:30<02:15, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.47G/9.98G [04:30<01:54, 30.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.48G/9.98G [04:30<02:09, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.48G/9.98G [04:30<02:00, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.48G/9.98G [04:30<02:18, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.49G/9.98G [04:30<02:26, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.49G/9.98G [04:30<02:02, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.50G/9.98G [04:31<02:05, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.50G/9.98G [04:31<02:38, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.50G/9.98G [04:31<02:14, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.51G/9.98G [04:31<02:24, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.51G/9.98G [04:31<02:02, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.51G/9.98G [04:31<02:30, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.52G/9.98G [04:31<02:08, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.52G/9.98G [04:32<02:10, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.53G/9.98G [04:32<01:54, 30.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.53G/9.98G [04:32<02:28, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  65% 6.53G/9.98G [04:32<02:05, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.54G/9.98G [04:32<02:15, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.54G/9.98G [04:32<01:58, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.55G/9.98G [04:33<02:33, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.55G/9.98G [04:33<02:15, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.55G/9.98G [04:33<01:57, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.56G/9.98G [04:33<02:06, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.56G/9.98G [04:33<02:55, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.56G/9.98G [04:33<02:25, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.57G/9.98G [04:33<02:02, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.57G/9.98G [04:34<02:06, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.58G/9.98G [04:34<02:26, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.58G/9.98G [04:34<02:06, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.58G/9.98G [04:34<01:50, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.59G/9.98G [04:34<01:57, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.59G/9.98G [04:34<02:34, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.60G/9.98G [04:34<02:11, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.60G/9.98G [04:35<01:54, 29.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.60G/9.98G [04:35<02:00, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.61G/9.98G [04:35<02:26, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.61G/9.98G [04:35<02:07, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.62G/9.98G [04:35<01:50, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.62G/9.98G [04:35<01:41, 32.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.62G/9.98G [04:36<02:54, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.63G/9.98G [04:36<02:33, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  66% 6.63G/9.98G [04:36<02:07, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.64G/9.98G [04:36<02:00, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.64G/9.98G [04:36<02:13, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.64G/9.98G [04:36<02:55, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.65G/9.98G [04:37<02:23, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.65G/9.98G [04:37<02:22, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.65G/9.98G [04:37<02:00, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.66G/9.98G [04:37<02:40, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.66G/9.98G [04:37<02:13, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.67G/9.98G [04:37<02:01, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.67G/9.98G [04:37<02:13, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.67G/9.98G [04:38<02:34, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.68G/9.98G [04:38<02:09, 25.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.68G/9.98G [04:38<01:50, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.68G/9.98G [04:38<01:57, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.69G/9.98G [04:38<03:08, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.69G/9.98G [04:38<02:35, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.70G/9.98G [04:39<02:07, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.70G/9.98G [04:39<02:08, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.70G/9.98G [04:39<02:34, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.71G/9.98G [04:39<02:11, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.71G/9.98G [04:39<01:51, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.72G/9.98G [04:39<01:57, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.72G/9.98G [04:40<02:30, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.72G/9.98G [04:40<02:07, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.73G/9.98G [04:40<01:47, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  67% 6.73G/9.98G [04:40<01:57, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.74G/9.98G [04:40<02:25, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.74G/9.98G [04:40<02:03, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.74G/9.98G [04:40<01:48, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.75G/9.98G [04:41<01:54, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.75G/9.98G [04:41<03:12, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.76G/9.98G [04:41<02:37, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.76G/9.98G [04:41<02:16, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.76G/9.98G [04:41<02:08, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.77G/9.98G [04:42<02:31, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.77G/9.98G [04:42<02:07, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.78G/9.98G [04:42<01:45, 30.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.78G/9.98G [04:42<01:56, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.78G/9.98G [04:42<02:39, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.79G/9.98G [04:42<02:12, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.79G/9.98G [04:42<01:50, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.80G/9.98G [04:43<01:58, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.80G/9.98G [04:43<02:39, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.80G/9.98G [04:43<02:13, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.81G/9.98G [04:43<01:50, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.81G/9.98G [04:43<01:57, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.82G/9.98G [04:44<02:38, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.82G/9.98G [04:44<02:11, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.83G/9.98G [04:44<01:47, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.83G/9.98G [04:44<02:02, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  68% 6.83G/9.98G [04:44<02:42, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.84G/9.98G [04:44<02:13, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.84G/9.98G [04:44<01:55, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:02:52] Energy consumed for RAM : 0.030227 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:02:52] Energy consumed for all GPUs : 0.196641 kWh. Total GPU Power : 27.275000000000006 W\n",
            "[codecarbon INFO @ 16:02:52] Energy consumed for all CPUs : 0.134733 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:02:52] 0.361600 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  69% 6.84G/9.98G [04:45<01:58, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.98G [04:45<02:20, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.85G/9.98G [04:45<02:01, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.86G/9.98G [04:45<01:44, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.86G/9.98G [04:45<01:53, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.86G/9.98G [04:45<02:24, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.87G/9.98G [04:46<02:04, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.87G/9.98G [04:46<01:45, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.88G/9.98G [04:46<01:51, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.88G/9.98G [04:46<02:23, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.88G/9.98G [04:46<02:03, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.89G/9.98G [04:46<01:44, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.89G/9.98G [04:46<01:52, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.90G/9.98G [04:47<02:24, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.90G/9.98G [04:47<02:02, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.90G/9.98G [04:47<01:42, 29.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.91G/9.98G [04:47<01:50, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.91G/9.98G [04:47<02:22, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.92G/9.98G [04:47<02:02, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.92G/9.98G [04:48<01:43, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.92G/9.98G [04:48<01:50, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.93G/9.98G [04:48<02:20, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  69% 6.93G/9.98G [04:48<01:59, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.94G/9.98G [04:48<01:38, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.94G/9.98G [04:48<01:48, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.94G/9.98G [04:49<02:12, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.95G/9.98G [04:49<01:53, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.95G/9.98G [04:49<01:36, 31.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.96G/9.98G [04:49<01:46, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.96G/9.98G [04:49<02:07, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.96G/9.98G [04:49<01:50, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.97G/9.98G [04:49<01:33, 32.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.97G/9.98G [04:49<01:43, 29.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.98G/9.98G [04:50<02:13, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.98G/9.98G [04:50<01:54, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.98G/9.98G [04:50<01:36, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.99G/9.98G [04:50<01:45, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 6.99G/9.98G [04:50<02:12, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.00G/9.98G [04:50<01:54, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.00G/9.98G [04:51<01:35, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.00G/9.98G [04:51<01:43, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.01G/9.98G [04:51<02:13, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.01G/9.98G [04:51<01:54, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.02G/9.98G [04:51<01:39, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.02G/9.98G [04:51<01:44, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.02G/9.98G [04:52<02:19, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.03G/9.98G [04:52<01:58, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  70% 7.03G/9.98G [04:52<01:42, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.04G/9.98G [04:52<01:57, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.04G/9.98G [04:52<02:07, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.04G/9.98G [04:52<02:26, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.05G/9.98G [04:52<02:03, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.05G/9.98G [04:53<01:46, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.05G/9.98G [04:53<01:53, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.06G/9.98G [04:53<02:26, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.06G/9.98G [04:53<02:01, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.06G/9.98G [04:53<01:41, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.07G/9.98G [04:53<01:50, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.07G/9.98G [04:54<02:32, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.08G/9.98G [04:54<02:10, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.08G/9.98G [04:54<01:50, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.08G/9.98G [04:54<01:47, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.09G/9.98G [04:54<02:01, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.09G/9.98G [04:54<01:46, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.10G/9.98G [04:54<01:33, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.10G/9.98G [04:55<01:39, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.10G/9.98G [04:55<02:27, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.11G/9.98G [04:55<02:04, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.11G/9.98G [04:55<01:43, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.12G/9.98G [04:55<01:53, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.12G/9.98G [04:56<04:14, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.12G/9.98G [04:56<03:35, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.13G/9.98G [04:56<02:52, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  71% 7.13G/9.98G [04:56<02:30, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.14G/9.98G [04:58<06:09, 7.69MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.14G/9.98G [04:58<04:55, 9.61MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.14G/9.98G [04:58<04:08, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.15G/9.98G [04:58<03:34, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.15G/9.98G [04:58<02:44, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.15G/9.98G [04:59<03:02, 15.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.16G/9.98G [04:59<02:19, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.16G/9.98G [04:59<02:18, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.17G/9.98G [04:59<01:54, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.17G/9.98G [04:59<02:09, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.17G/9.98G [04:59<01:50, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:03:07] Energy consumed for RAM : 0.030267 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:03:07] Energy consumed for all GPUs : 0.196754 kWh. Total GPU Power : 27.275000000000006 W\n",
            "[codecarbon INFO @ 16:03:07] Energy consumed for all CPUs : 0.134910 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:03:07] 0.361931 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  72% 7.18G/9.98G [04:59<01:54, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.18G/9.98G [04:59<01:32, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.19G/9.98G [05:00<02:03, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.19G/9.98G [05:00<01:48, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.19G/9.98G [05:00<01:50, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.20G/9.98G [05:00<01:37, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.20G/9.98G [05:00<02:07, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.21G/9.98G [05:00<01:51, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.21G/9.98G [05:01<01:35, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.21G/9.98G [05:01<01:43, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.22G/9.98G [05:01<02:24, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.22G/9.98G [05:01<02:00, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.22G/9.98G [05:01<01:39, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.23G/9.98G [05:01<01:48, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  72% 7.23G/9.98G [05:01<01:42, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.23G/9.98G [05:02<01:44, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.24G/9.98G [05:02<01:49, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.24G/9.98G [05:02<01:30, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.25G/9.98G [05:02<01:36, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.25G/9.98G [05:02<01:46, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.25G/9.98G [05:02<01:32, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.26G/9.98G [05:02<01:44, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.26G/9.98G [05:03<01:29, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.27G/9.98G [05:04<06:38, 6.81MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.27G/9.98G [05:04<06:15, 7.22MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.27G/9.98G [05:04<04:55, 9.14MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.28G/9.98G [05:05<03:53, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.28G/9.98G [05:05<03:01, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.28G/9.98G [05:05<03:13, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.29G/9.98G [05:05<02:24, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.29G/9.98G [05:05<02:17, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.29G/9.98G [05:05<01:53, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.30G/9.98G [05:06<02:14, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.30G/9.98G [05:06<01:51, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.31G/9.98G [05:06<01:35, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.31G/9.98G [05:06<01:42, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.31G/9.98G [05:06<02:20, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.32G/9.98G [05:06<01:57, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.32G/9.98G [05:06<01:39, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.32G/9.98G [05:07<01:40, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.33G/9.98G [05:07<02:03, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  73% 7.33G/9.98G [05:07<01:46, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.34G/9.98G [05:07<01:31, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.34G/9.98G [05:07<01:34, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.34G/9.98G [05:07<01:48, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.35G/9.98G [05:07<01:34, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.35G/9.98G [05:08<01:24, 31.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.36G/9.98G [05:08<01:16, 34.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.36G/9.98G [05:08<02:08, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.36G/9.98G [05:08<01:48, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.37G/9.98G [05:08<01:32, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.37G/9.98G [05:08<01:37, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.38G/9.98G [05:09<01:53, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.38G/9.98G [05:09<01:38, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.38G/9.98G [05:09<01:25, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.39G/9.98G [05:09<01:30, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.39G/9.98G [05:09<02:41, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.40G/9.98G [05:10<02:11, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.40G/9.98G [05:10<01:48, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.40G/9.98G [05:10<01:49, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.41G/9.98G [05:10<02:10, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.41G/9.98G [05:10<01:49, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.42G/9.98G [05:10<01:30, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.42G/9.98G [05:10<01:37, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.42G/9.98G [05:11<01:58, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  74% 7.43G/9.98G [05:11<01:40, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.43G/9.98G [05:11<01:24, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.44G/9.98G [05:11<01:30, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.44G/9.98G [05:11<01:49, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.44G/9.98G [05:11<01:33, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.45G/9.98G [05:11<01:20, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.45G/9.98G [05:12<01:27, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.46G/9.98G [05:12<01:47, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.46G/9.98G [05:12<01:31, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.47G/9.98G [05:12<01:18, 32.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.47G/9.98G [05:12<01:26, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.47G/9.98G [05:12<01:56, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.48G/9.98G [05:13<01:38, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.48G/9.98G [05:13<01:24, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.48G/9.98G [05:13<01:29, 27.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.49G/9.98G [05:13<01:58, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.49G/9.98G [05:13<01:40, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.50G/9.98G [05:13<01:24, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.50G/9.98G [05:13<01:31, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.50G/9.98G [05:14<02:10, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.51G/9.98G [05:14<01:49, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.51G/9.98G [05:14<01:29, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.52G/9.98G [05:14<01:33, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.52G/9.98G [05:14<01:48, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:03:22] Energy consumed for RAM : 0.030306 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:03:22] Energy consumed for all GPUs : 0.196867 kWh. Total GPU Power : 27.177 W\n",
            "[codecarbon INFO @ 16:03:22] Energy consumed for all CPUs : 0.135087 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:03:22] 0.362261 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  75% 7.52G/9.98G [05:14<01:32, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  75% 7.53G/9.98G [05:15<01:19, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.53G/9.98G [05:15<01:26, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.54G/9.98G [05:15<01:59, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.54G/9.98G [05:15<01:39, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.54G/9.98G [05:15<01:25, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.55G/9.98G [05:15<01:29, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.55G/9.98G [05:16<01:53, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.56G/9.98G [05:16<01:36, 25.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.56G/9.98G [05:16<01:21, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.56G/9.98G [05:16<01:27, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.57G/9.98G [05:16<01:47, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.57G/9.98G [05:16<01:32, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.58G/9.98G [05:16<01:17, 31.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.58G/9.98G [05:17<01:23, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.58G/9.98G [05:17<01:50, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.59G/9.98G [05:17<01:33, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.59G/9.98G [05:17<01:19, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [05:17<01:27, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [05:18<01:55, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.60G/9.98G [05:18<01:36, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.61G/9.98G [05:18<01:20, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.61G/9.98G [05:18<01:28, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.62G/9.98G [05:18<01:56, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.62G/9.98G [05:18<01:37, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.62G/9.98G [05:18<01:22, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.63G/9.98G [05:19<01:31, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  76% 7.63G/9.98G [05:19<01:56, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.64G/9.98G [05:19<01:38, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.64G/9.98G [05:19<01:22, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.64G/9.98G [05:19<01:29, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.65G/9.98G [05:19<01:26, 26.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.65G/9.98G [05:20<02:35, 15.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.65G/9.98G [05:20<02:20, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.66G/9.98G [05:20<01:49, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.66G/9.98G [05:20<01:41, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.66G/9.98G [05:20<02:17, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.67G/9.98G [05:21<01:48, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.67G/9.98G [05:21<01:27, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.68G/9.98G [05:21<01:28, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.68G/9.98G [05:21<01:56, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.68G/9.98G [05:21<01:37, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.69G/9.98G [05:21<01:21, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.69G/9.98G [05:21<01:26, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.70G/9.98G [05:22<01:47, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.70G/9.98G [05:22<01:33, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.70G/9.98G [05:22<01:20, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.71G/9.98G [05:22<01:33, 24.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.71G/9.98G [05:22<01:37, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.71G/9.98G [05:22<01:55, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.72G/9.98G [05:23<01:42, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.72G/9.98G [05:23<01:22, 27.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.72G/9.98G [05:23<01:28, 25.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  77% 7.73G/9.98G [05:23<01:55, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.73G/9.98G [05:23<01:35, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.74G/9.98G [05:23<01:27, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.74G/9.98G [05:23<01:35, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.74G/9.98G [05:24<01:26, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.74G/9.98G [05:24<02:06, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.75G/9.98G [05:24<01:41, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.75G/9.98G [05:24<01:34, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.76G/9.98G [05:24<01:32, 24.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.76G/9.98G [05:24<01:25, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.76G/9.98G [05:25<01:42, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.77G/9.98G [05:25<01:24, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.77G/9.98G [05:25<01:33, 23.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.77G/9.98G [05:25<01:34, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.78G/9.98G [05:25<01:25, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.78G/9.98G [05:25<01:44, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.78G/9.98G [05:25<01:38, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.79G/9.98G [05:25<01:20, 27.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.79G/9.98G [05:26<01:26, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.79G/9.98G [05:26<01:59, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.80G/9.98G [05:26<01:37, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.80G/9.98G [05:26<01:37, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.81G/9.98G [05:26<01:22, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.81G/9.98G [05:27<01:48, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.81G/9.98G [05:27<01:29, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.82G/9.98G [05:27<01:15, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.82G/9.98G [05:27<01:23, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.82G/9.98G [05:27<01:51, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  78% 7.83G/9.98G [05:27<01:31, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.83G/9.98G [05:27<01:16, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.84G/9.98G [05:28<01:22, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.84G/9.98G [05:28<01:32, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.84G/9.98G [05:28<01:19, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.85G/9.98G [05:28<01:08, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.85G/9.98G [05:28<01:15, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.86G/9.98G [05:28<01:33, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.86G/9.98G [05:28<01:20, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.86G/9.98G [05:29<01:13, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.87G/9.98G [05:29<01:05, 32.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.87G/9.98G [05:29<01:13, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.88G/9.98G [05:29<01:28, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.88G/9.98G [05:29<01:29, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.88G/9.98G [05:29<01:14, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.89G/9.98G [05:29<01:18, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:03:37] Energy consumed for RAM : 0.030346 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:03:37] Energy consumed for all GPUs : 0.196981 kWh. Total GPU Power : 27.374000000000002 W\n",
            "[codecarbon INFO @ 16:03:37] Energy consumed for all CPUs : 0.135264 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:03:37] 0.362591 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  79% 7.89G/9.98G [05:30<01:25, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.89G/9.98G [05:30<01:11, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.90G/9.98G [05:30<01:21, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.90G/9.98G [05:30<01:09, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.91G/9.98G [05:30<01:39, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.91G/9.98G [05:30<01:23, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.91G/9.98G [05:31<01:23, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.92G/9.98G [05:31<01:12, 28.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.92G/9.98G [05:31<01:34, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.93G/9.98G [05:31<01:19, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  79% 7.93G/9.98G [05:31<01:11, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.93G/9.98G [05:31<01:16, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.94G/9.98G [05:32<01:41, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.94G/9.98G [05:32<01:24, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.94G/9.98G [05:32<01:12, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [05:32<01:14, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [05:33<02:33, 13.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.95G/9.98G [05:33<03:36, 9.36MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.96G/9.98G [05:33<03:32, 9.49MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.96G/9.98G [05:33<03:34, 9.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.96G/9.98G [05:34<02:26, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.96G/9.98G [05:34<02:26, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.97G/9.98G [05:34<02:06, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.97G/9.98G [05:34<02:36, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.97G/9.98G [05:34<01:56, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.98G/9.98G [05:34<01:24, 23.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.98G/9.98G [05:34<01:28, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.98G/9.98G [05:35<01:55, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.99G/9.98G [05:35<01:32, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 7.99G/9.98G [05:35<01:16, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.00G/9.98G [05:35<01:17, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.00G/9.98G [05:35<01:43, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.00G/9.98G [05:35<01:26, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.01G/9.98G [05:36<01:13, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.01G/9.98G [05:36<01:14, 26.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.02G/9.98G [05:36<01:35, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.02G/9.98G [05:36<01:21, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.02G/9.98G [05:36<01:09, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  80% 8.03G/9.98G [05:36<01:05, 29.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.03G/9.98G [05:36<01:09, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.03G/9.98G [05:37<01:23, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.04G/9.98G [05:37<01:14, 26.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.04G/9.98G [05:37<01:17, 25.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.05G/9.98G [05:37<01:07, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.05G/9.98G [05:37<01:45, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.05G/9.98G [05:37<01:26, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.06G/9.98G [05:38<01:11, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.06G/9.98G [05:38<01:14, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.06G/9.98G [05:38<01:33, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.07G/9.98G [05:38<01:19, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.07G/9.98G [05:38<01:06, 28.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.08G/9.98G [05:38<01:11, 26.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.08G/9.98G [05:39<01:36, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.08G/9.98G [05:39<01:21, 23.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.09G/9.98G [05:39<01:08, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.09G/9.98G [05:39<01:09, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.10G/9.98G [05:39<01:29, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.10G/9.98G [05:39<01:16, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.10G/9.98G [05:39<01:07, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.11G/9.98G [05:40<01:07, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.11G/9.98G [05:40<01:23, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.12G/9.98G [05:40<01:13, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.12G/9.98G [05:40<01:03, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.12G/9.98G [05:40<01:05, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  81% 8.13G/9.98G [05:40<01:23, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.13G/9.98G [05:41<01:11, 25.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.14G/9.98G [05:41<01:02, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.14G/9.98G [05:41<01:05, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.14G/9.98G [05:41<01:22, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.15G/9.98G [05:41<01:10, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.15G/9.98G [05:41<01:00, 30.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.16G/9.98G [05:41<01:04, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.16G/9.98G [05:42<01:21, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.16G/9.98G [05:42<01:09, 25.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.17G/9.98G [05:42<00:58, 30.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.17G/9.98G [05:42<01:04, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.18G/9.98G [05:42<01:25, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.18G/9.98G [05:42<01:12, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.18G/9.98G [05:43<01:01, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.19G/9.98G [05:43<01:05, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.19G/9.98G [05:43<01:14, 24.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.19G/9.98G [05:43<01:38, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.20G/9.98G [05:43<01:31, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.20G/9.98G [05:43<01:12, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.21G/9.98G [05:44<01:18, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.21G/9.98G [05:44<02:05, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.21G/9.98G [05:44<01:35, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.22G/9.98G [05:44<01:39, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:03:52] Energy consumed for RAM : 0.030386 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:03:52] Energy consumed for all GPUs : 0.197095 kWh. Total GPU Power : 27.275000000000006 W\n",
            "[codecarbon INFO @ 16:03:52] Energy consumed for all CPUs : 0.135441 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:03:52] 0.362922 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  82% 8.22G/9.98G [05:44<01:37, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.22G/9.98G [05:45<01:29, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.22G/9.98G [05:45<01:26, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.23G/9.98G [05:45<02:08, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  82% 8.23G/9.98G [05:45<01:51, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.23G/9.98G [05:45<01:43, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.24G/9.98G [05:45<01:42, 17.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.24G/9.98G [05:46<01:37, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.24G/9.98G [05:46<02:03, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.24G/9.98G [05:46<01:30, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.25G/9.98G [05:46<01:34, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.25G/9.98G [05:46<01:33, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.26G/9.98G [05:47<01:29, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.26G/9.98G [05:47<01:55, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.26G/9.98G [05:47<01:29, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.26G/9.98G [05:47<01:34, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.27G/9.98G [05:47<01:31, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.27G/9.98G [05:47<01:15, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.27G/9.98G [05:48<02:01, 14.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.28G/9.98G [05:48<01:45, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.28G/9.98G [05:48<01:36, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.28G/9.98G [05:48<01:33, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.29G/9.98G [05:48<01:19, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.29G/9.98G [05:49<01:52, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.29G/9.98G [05:49<01:36, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.30G/9.98G [05:49<01:29, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.30G/9.98G [05:49<01:27, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.30G/9.98G [05:49<01:17, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.31G/9.98G [05:49<01:54, 14.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.31G/9.98G [05:50<01:24, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.31G/9.98G [05:50<01:29, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.32G/9.98G [05:50<01:30, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.32G/9.98G [05:50<01:18, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.32G/9.98G [05:50<01:47, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.33G/9.98G [05:50<01:21, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  83% 8.33G/9.98G [05:51<01:27, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.33G/9.98G [05:51<01:26, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.34G/9.98G [05:51<01:16, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.34G/9.98G [05:51<01:54, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.34G/9.98G [05:51<01:25, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.34G/9.98G [05:52<01:30, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.35G/9.98G [05:52<01:29, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.35G/9.98G [05:52<01:20, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.35G/9.98G [05:52<01:37, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.36G/9.98G [05:52<01:13, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.36G/9.98G [05:52<01:20, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.36G/9.98G [05:52<01:20, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.37G/9.98G [05:53<01:13, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.37G/9.98G [05:53<01:28, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.37G/9.98G [05:53<01:09, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.38G/9.98G [05:53<01:17, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.38G/9.98G [05:53<01:17, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.38G/9.98G [05:53<01:13, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.39G/9.98G [05:54<01:37, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.39G/9.98G [05:54<01:13, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.39G/9.98G [05:54<01:20, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.40G/9.98G [05:54<01:17, 20.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.40G/9.98G [05:54<01:09, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.40G/9.98G [05:54<01:34, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.41G/9.98G [05:55<01:14, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.41G/9.98G [05:55<01:20, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.41G/9.98G [05:55<01:20, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.41G/9.98G [05:55<01:13, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.42G/9.98G [05:55<01:57, 13.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.42G/9.98G [05:55<01:30, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.42G/9.98G [05:56<01:35, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.43G/9.98G [05:56<01:41, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.43G/9.98G [05:56<01:38, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  84% 8.43G/9.98G [05:56<01:40, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.43G/9.98G [05:56<02:27, 10.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.44G/9.98G [05:57<01:37, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.44G/9.98G [05:57<01:36, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.44G/9.98G [05:57<01:32, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.44G/9.98G [05:57<01:28, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.45G/9.98G [05:57<01:21, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.45G/9.98G [05:57<02:09, 11.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.45G/9.98G [05:58<01:28, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.46G/9.98G [05:58<01:33, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.46G/9.98G [05:58<01:29, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.46G/9.98G [05:58<01:25, 17.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.46G/9.98G [05:58<02:15, 11.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.47G/9.98G [05:59<01:50, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.47G/9.98G [05:59<01:49, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.47G/9.98G [05:59<01:47, 14.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [05:59<01:46, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [05:59<01:39, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [05:59<01:46, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:04:07] Energy consumed for RAM : 0.030425 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:04:07] Energy consumed for all GPUs : 0.197209 kWh. Total GPU Power : 27.29 W\n",
            "[codecarbon INFO @ 16:04:07] Energy consumed for all CPUs : 0.135618 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:04:07] 0.363252 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [06:00<02:17, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.48G/9.98G [06:00<01:56, 12.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.49G/9.98G [06:00<01:49, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.49G/9.98G [06:00<01:45, 14.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.49G/9.98G [06:00<01:30, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.49G/9.98G [06:00<01:39, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.50G/9.98G [06:01<01:39, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.50G/9.98G [06:01<02:20, 10.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.50G/9.98G [06:01<01:30, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.50G/9.98G [06:01<01:37, 15.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.51G/9.98G [06:01<01:45, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.51G/9.98G [06:01<01:27, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.51G/9.98G [06:02<01:37, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.51G/9.98G [06:02<02:37, 9.30MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.52G/9.98G [06:02<01:41, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.52G/9.98G [06:02<01:40, 14.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.52G/9.98G [06:02<01:36, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.52G/9.98G [06:03<01:34, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.53G/9.98G [06:03<01:37, 14.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  85% 8.53G/9.98G [06:03<02:21, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.53G/9.98G [06:03<01:33, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.53G/9.98G [06:03<01:33, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.54G/9.98G [06:04<01:31, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.54G/9.98G [06:04<01:27, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.54G/9.98G [06:04<01:31, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.54G/9.98G [06:04<02:10, 10.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.55G/9.98G [06:04<01:27, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.55G/9.98G [06:04<01:29, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.55G/9.98G [06:05<01:28, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.56G/9.98G [06:05<01:25, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.56G/9.98G [06:05<01:29, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.56G/9.98G [06:05<02:08, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.56G/9.98G [06:05<01:26, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.57G/9.98G [06:06<01:28, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.57G/9.98G [06:06<01:26, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.57G/9.98G [06:06<01:24, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.57G/9.98G [06:06<01:27, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.58G/9.98G [06:06<02:09, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.58G/9.98G [06:06<01:28, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.58G/9.98G [06:07<01:29, 15.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.59G/9.98G [06:07<01:27, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.59G/9.98G [06:07<01:25, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.59G/9.98G [06:07<01:27, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.59G/9.98G [06:07<02:02, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.60G/9.98G [06:07<01:23, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.60G/9.98G [06:08<01:25, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.60G/9.98G [06:08<01:23, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.60G/9.98G [06:08<01:23, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.61G/9.98G [06:08<01:26, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.61G/9.98G [06:08<02:06, 10.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.61G/9.98G [06:09<01:25, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.61G/9.98G [06:09<01:27, 15.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.62G/9.98G [06:09<01:24, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.62G/9.98G [06:09<01:22, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.62G/9.98G [06:09<01:25, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.62G/9.98G [06:10<02:01, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  86% 8.63G/9.98G [06:10<01:22, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.63G/9.98G [06:10<01:25, 15.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.63G/9.98G [06:10<01:22, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.64G/9.98G [06:10<01:20, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.64G/9.98G [06:10<01:23, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.64G/9.98G [06:11<01:57, 11.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.64G/9.98G [06:11<01:20, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.65G/9.98G [06:11<01:23, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.65G/9.98G [06:11<01:20, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.65G/9.98G [06:11<01:19, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.65G/9.98G [06:11<01:22, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.66G/9.98G [06:12<01:59, 11.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.66G/9.98G [06:12<01:21, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.66G/9.98G [06:12<01:23, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.67G/9.98G [06:12<01:20, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.67G/9.98G [06:12<01:18, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.67G/9.98G [06:12<01:20, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.67G/9.98G [06:13<01:58, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.68G/9.98G [06:13<01:21, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.68G/9.98G [06:13<01:23, 15.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.68G/9.98G [06:13<01:19, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.68G/9.98G [06:13<01:17, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.69G/9.98G [06:13<01:19, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.69G/9.98G [06:14<01:49, 11.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.69G/9.98G [06:14<01:14, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [06:14<01:19, 16.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [06:14<01:16, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [06:14<01:14, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.70G/9.98G [06:14<01:05, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:04:22] Energy consumed for RAM : 0.030465 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:04:22] Energy consumed for all GPUs : 0.197323 kWh. Total GPU Power : 27.473000000000003 W\n",
            "[codecarbon INFO @ 16:04:22] Energy consumed for all CPUs : 0.135795 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:04:22] 0.363583 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  87% 8.71G/9.98G [06:15<01:48, 11.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  87% 8.71G/9.98G [06:15<01:18, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.71G/9.98G [06:15<01:22, 15.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.71G/9.98G [06:15<01:17, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.72G/9.98G [06:15<01:14, 17.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.72G/9.98G [06:15<01:07, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.72G/9.98G [06:16<01:44, 12.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.73G/9.98G [06:16<01:12, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  87% 8.73G/9.98G [06:16<01:16, 16.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.73G/9.98G [06:16<01:14, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.73G/9.98G [06:16<01:11, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.74G/9.98G [06:17<01:40, 12.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.74G/9.98G [06:17<01:11, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.74G/9.98G [06:17<01:10, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.75G/9.98G [06:17<01:09, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.75G/9.98G [06:17<01:05, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.75G/9.98G [06:18<01:23, 14.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.76G/9.98G [06:18<01:02, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.76G/9.98G [06:18<01:06, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.76G/9.98G [06:18<00:56, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.77G/9.98G [06:18<01:05, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.77G/9.98G [06:18<01:28, 13.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.77G/9.98G [06:19<01:04, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.78G/9.98G [06:19<01:02, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.78G/9.98G [06:19<01:00, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.78G/9.98G [06:19<00:53, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.79G/9.98G [06:19<01:10, 17.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.79G/9.98G [06:19<01:02, 18.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.79G/9.98G [06:20<00:58, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.80G/9.98G [06:20<00:57, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.80G/9.98G [06:20<00:54, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.80G/9.98G [06:20<01:14, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.81G/9.98G [06:20<00:55, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.81G/9.98G [06:20<00:59, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.81G/9.98G [06:21<00:55, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.82G/9.98G [06:23<04:15, 4.54MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.82G/9.98G [06:23<03:39, 5.28MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.82G/9.98G [06:23<02:53, 6.63MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.83G/9.98G [06:24<02:18, 8.31MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  88% 8.83G/9.98G [06:24<02:13, 8.57MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.83G/9.98G [06:24<02:08, 8.89MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.84G/9.98G [06:24<01:31, 12.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.84G/9.98G [06:24<01:21, 13.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.84G/9.98G [06:25<01:14, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.85G/9.98G [06:25<01:07, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.85G/9.98G [06:25<01:23, 13.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.85G/9.98G [06:25<01:02, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.86G/9.98G [06:25<01:05, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.86G/9.98G [06:25<01:00, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.86G/9.98G [06:26<00:52, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.87G/9.98G [06:26<01:12, 15.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.87G/9.98G [06:26<00:55, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.87G/9.98G [06:26<00:58, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.88G/9.98G [06:26<00:57, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.88G/9.98G [06:26<00:53, 20.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.88G/9.98G [06:27<01:05, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.89G/9.98G [06:27<00:50, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.89G/9.98G [06:27<00:53, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.89G/9.98G [06:27<00:50, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.90G/9.98G [06:27<01:11, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.90G/9.98G [06:28<00:55, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.90G/9.98G [06:28<00:52, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.91G/9.98G [06:28<00:49, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.91G/9.98G [06:28<01:04, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.92G/9.98G [06:28<00:52, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.92G/9.98G [06:29<00:48, 21.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.92G/9.98G [06:29<00:47, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:04:37] Energy consumed for RAM : 0.030505 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:04:37] Energy consumed for all GPUs : 0.197438 kWh. Total GPU Power : 27.670000000000005 W\n",
            "[codecarbon INFO @ 16:04:37] Energy consumed for all CPUs : 0.135972 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:04:37] 0.363915 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  89% 8.93G/9.98G [06:31<03:12, 5.46MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.93G/9.98G [06:31<02:53, 6.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.93G/9.98G [06:31<02:21, 7.35MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.94G/9.98G [06:31<01:55, 9.02MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.94G/9.98G [06:32<01:28, 11.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.94G/9.98G [06:32<01:33, 11.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.95G/9.98G [06:32<01:09, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.95G/9.98G [06:32<01:03, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.96G/9.98G [06:32<00:57, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.96G/9.98G [06:33<01:05, 15.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.96G/9.98G [06:33<00:51, 19.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.97G/9.98G [06:33<00:47, 21.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.97G/9.98G [06:33<00:45, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.98G/9.98G [06:33<00:43, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.98G/9.98G [06:33<00:47, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.98G/9.98G [06:33<00:39, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.99G/9.98G [06:34<00:44, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.99G/9.98G [06:34<00:44, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.99G/9.98G [06:34<00:42, 23.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 8.99G/9.98G [06:34<00:47, 20.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.00G/9.98G [06:34<00:39, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.00G/9.98G [06:34<00:44, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.00G/9.98G [06:34<00:46, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.01G/9.98G [06:35<00:37, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.01G/9.98G [06:35<00:58, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.01G/9.98G [06:35<00:45, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.02G/9.98G [06:35<00:48, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.02G/9.98G [06:35<00:48, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.02G/9.98G [06:35<00:43, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.03G/9.98G [06:36<01:32, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  90% 9.03G/9.98G [06:36<01:31, 10.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.03G/9.98G [06:36<01:12, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.03G/9.98G [06:37<01:05, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.04G/9.98G [06:37<00:47, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.04G/9.98G [06:37<00:59, 15.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [06:37<00:47, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [06:37<00:46, 19.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.05G/9.98G [06:37<00:47, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.06G/9.98G [06:37<00:40, 23.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.06G/9.98G [06:38<00:53, 17.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.06G/9.98G [06:38<00:43, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.06G/9.98G [06:38<00:43, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.07G/9.98G [06:38<00:43, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.07G/9.98G [06:38<00:34, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.07G/9.98G [06:38<00:50, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.08G/9.98G [06:39<00:48, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.08G/9.98G [06:39<00:36, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.09G/9.98G [06:39<00:40, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.09G/9.98G [06:39<00:48, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.09G/9.98G [06:39<00:38, 23.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.10G/9.98G [06:39<00:39, 22.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.10G/9.98G [06:40<00:38, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.10G/9.98G [06:40<00:31, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.11G/9.98G [06:40<00:40, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.11G/9.98G [06:40<00:41, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.12G/9.98G [06:40<00:32, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.12G/9.98G [06:40<00:36, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.12G/9.98G [06:41<00:47, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  91% 9.13G/9.98G [06:41<00:37, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.13G/9.98G [06:41<00:38, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.13G/9.98G [06:41<00:37, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.14G/9.98G [06:41<00:30, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.14G/9.98G [06:41<00:43, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.14G/9.98G [06:42<00:43, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.15G/9.98G [06:42<00:33, 24.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.15G/9.98G [06:42<00:38, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.15G/9.98G [06:42<00:48, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.16G/9.98G [06:42<00:38, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.16G/9.98G [06:42<00:36, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.16G/9.98G [06:42<00:36, 22.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.17G/9.98G [06:43<00:29, 27.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.17G/9.98G [06:43<00:35, 22.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.17G/9.98G [06:43<00:36, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.18G/9.98G [06:43<00:35, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.18G/9.98G [06:43<00:29, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.19G/9.98G [06:43<00:35, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.19G/9.98G [06:44<00:35, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.20G/9.98G [06:44<00:33, 23.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.20G/9.98G [06:44<00:41, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.20G/9.98G [06:44<00:34, 22.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:04:52] Energy consumed for RAM : 0.030545 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:04:52] Energy consumed for all GPUs : 0.197554 kWh. Total GPU Power : 27.867000000000004 W\n",
            "[codecarbon INFO @ 16:04:52] Energy consumed for all CPUs : 0.136149 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:04:52] 0.364248 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  92% 9.21G/9.98G [06:44<00:32, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  92% 9.21G/9.98G [06:45<00:31, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.22G/9.98G [06:45<00:27, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.22G/9.98G [06:45<00:39, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.22G/9.98G [06:45<00:39, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  92% 9.23G/9.98G [06:45<00:35, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.23G/9.98G [06:45<00:30, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.23G/9.98G [06:46<00:36, 20.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.24G/9.98G [06:46<00:35, 20.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.24G/9.98G [06:46<00:32, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.25G/9.98G [06:46<00:27, 26.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.25G/9.98G [06:46<00:37, 19.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.25G/9.98G [06:47<00:36, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.26G/9.98G [06:47<00:32, 21.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.26G/9.98G [06:47<00:28, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.27G/9.98G [06:47<00:32, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.27G/9.98G [06:47<00:31, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.27G/9.98G [06:47<00:34, 20.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.28G/9.98G [06:48<00:32, 21.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.28G/9.98G [06:48<00:29, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.28G/9.98G [06:48<00:46, 15.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.29G/9.98G [06:48<00:34, 19.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.29G/9.98G [06:48<00:36, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.29G/9.98G [06:48<00:38, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.30G/9.98G [06:49<00:32, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.30G/9.98G [06:49<00:42, 15.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.30G/9.98G [06:49<00:33, 20.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.30G/9.98G [06:49<00:36, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.31G/9.98G [06:49<00:34, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.31G/9.98G [06:49<00:31, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.31G/9.98G [06:50<00:48, 13.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.32G/9.98G [06:50<00:40, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.32G/9.98G [06:50<00:39, 16.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.32G/9.98G [06:50<00:40, 16.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  93% 9.33G/9.98G [06:50<00:39, 16.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.33G/9.98G [06:51<00:49, 13.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.33G/9.98G [06:51<00:35, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.34G/9.98G [06:51<00:37, 17.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.34G/9.98G [06:51<00:36, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.34G/9.98G [06:51<00:37, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.34G/9.98G [06:51<00:34, 18.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.34G/9.98G [06:52<00:50, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.35G/9.98G [06:52<00:34, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.35G/9.98G [06:52<00:37, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.35G/9.98G [06:52<00:36, 17.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.36G/9.98G [06:52<00:35, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.36G/9.98G [06:52<00:34, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.36G/9.98G [06:53<00:54, 11.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.37G/9.98G [06:53<00:35, 17.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.37G/9.98G [06:53<00:37, 16.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.37G/9.98G [06:53<00:35, 16.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.37G/9.98G [06:53<00:34, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.38G/9.98G [06:54<00:47, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.38G/9.98G [06:54<00:34, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.38G/9.98G [06:54<00:33, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.39G/9.98G [06:54<00:32, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.39G/9.98G [06:54<00:32, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.39G/9.98G [06:55<00:46, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.40G/9.98G [06:55<00:34, 16.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.40G/9.98G [06:55<00:30, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.40G/9.98G [06:55<00:32, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.40G/9.98G [06:55<00:31, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.41G/9.98G [06:55<00:32, 17.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.41G/9.98G [06:56<00:45, 12.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.41G/9.98G [06:56<00:31, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.42G/9.98G [06:56<00:32, 17.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.42G/9.98G [06:56<00:31, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.42G/9.98G [06:56<00:30, 18.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  94% 9.42G/9.98G [06:57<00:37, 14.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.43G/9.98G [06:57<00:28, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.43G/9.98G [06:57<00:29, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.44G/9.98G [06:57<00:29, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.44G/9.98G [06:57<00:28, 19.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.44G/9.98G [06:57<00:37, 14.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.45G/9.98G [06:58<00:27, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.45G/9.98G [06:58<00:29, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.45G/9.98G [06:58<00:29, 17.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.45G/9.98G [06:58<00:27, 18.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.46G/9.98G [06:58<00:36, 14.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.46G/9.98G [06:58<00:26, 19.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.46G/9.98G [06:59<00:28, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.47G/9.98G [06:59<00:29, 17.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.47G/9.98G [06:59<00:27, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.47G/9.98G [06:59<00:38, 13.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.48G/9.98G [06:59<00:28, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:05:07] Energy consumed for RAM : 0.030584 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:05:07] Energy consumed for all GPUs : 0.197670 kWh. Total GPU Power : 27.867000000000004 W\n",
            "[codecarbon INFO @ 16:05:07] Energy consumed for all CPUs : 0.136326 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:05:07] 0.364581 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  95% 9.48G/9.98G [07:00<00:29, 16.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.48G/9.98G [07:00<00:29, 16.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.49G/9.98G [07:00<00:27, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.49G/9.98G [07:00<00:35, 13.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.49G/9.98G [07:00<00:26, 18.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.50G/9.98G [07:01<00:27, 17.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.50G/9.98G [07:01<00:27, 17.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.50G/9.98G [07:01<00:26, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.50G/9.98G [07:01<00:32, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.51G/9.98G [07:01<00:23, 19.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.51G/9.98G [07:01<00:25, 18.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.52G/9.98G [07:02<00:25, 17.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.52G/9.98G [07:02<00:24, 18.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.52G/9.98G [07:02<00:31, 14.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  95% 9.53G/9.98G [07:02<00:22, 19.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.53G/9.98G [07:02<00:24, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.53G/9.98G [07:03<00:24, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.53G/9.98G [07:03<00:23, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.54G/9.98G [07:03<00:30, 14.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.54G/9.98G [07:03<00:22, 19.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.54G/9.98G [07:03<00:24, 18.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [07:03<00:23, 18.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [07:04<00:22, 18.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [07:05<00:58, 7.23MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.55G/9.98G [07:05<00:56, 7.44MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.56G/9.98G [07:05<00:50, 8.40MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.56G/9.98G [07:05<00:33, 12.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.56G/9.98G [07:05<00:28, 14.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.57G/9.98G [07:05<00:27, 14.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.57G/9.98G [07:06<00:20, 19.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.58G/9.98G [07:06<00:16, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.58G/9.98G [07:06<00:16, 23.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.58G/9.98G [07:06<00:18, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.59G/9.98G [07:06<00:15, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.59G/9.98G [07:06<00:13, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.60G/9.98G [07:06<00:13, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.60G/9.98G [07:07<00:17, 21.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.60G/9.98G [07:07<00:14, 25.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.61G/9.98G [07:07<00:12, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.61G/9.98G [07:07<00:13, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.62G/9.98G [07:07<00:15, 23.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.62G/9.98G [07:07<00:12, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  96% 9.62G/9.98G [07:07<00:11, 31.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.63G/9.98G [07:08<00:12, 29.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.63G/9.98G [07:08<00:15, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.64G/9.98G [07:08<00:12, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.64G/9.98G [07:08<00:11, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.64G/9.98G [07:08<00:11, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.65G/9.98G [07:08<00:15, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.65G/9.98G [07:09<00:12, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.66G/9.98G [07:09<00:10, 30.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.66G/9.98G [07:09<00:11, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.66G/9.98G [07:09<00:14, 22.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.67G/9.98G [07:09<00:11, 26.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.67G/9.98G [07:09<00:10, 30.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.68G/9.98G [07:09<00:11, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.68G/9.98G [07:10<00:14, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.68G/9.98G [07:10<00:12, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.69G/9.98G [07:10<00:10, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.69G/9.98G [07:10<00:10, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.70G/9.98G [07:10<00:13, 21.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.70G/9.98G [07:10<00:11, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.70G/9.98G [07:11<00:09, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.71G/9.98G [07:11<00:09, 27.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.71G/9.98G [07:11<00:12, 21.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.72G/9.98G [07:11<00:10, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.72G/9.98G [07:11<00:08, 28.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  97% 9.72G/9.98G [07:11<00:09, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.73G/9.98G [07:12<00:11, 21.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.73G/9.98G [07:12<00:09, 25.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.74G/9.98G [07:12<00:08, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.74G/9.98G [07:12<00:08, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.74G/9.98G [07:12<00:10, 22.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.75G/9.98G [07:12<00:08, 26.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.75G/9.98G [07:12<00:07, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.76G/9.98G [07:12<00:06, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.76G/9.98G [07:13<00:07, 29.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.76G/9.98G [07:13<00:09, 22.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.77G/9.98G [07:13<00:09, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.77G/9.98G [07:13<00:07, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.78G/9.98G [07:13<00:07, 27.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.78G/9.98G [07:13<00:08, 23.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.78G/9.98G [07:14<00:06, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.79G/9.98G [07:14<00:07, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.79G/9.98G [07:14<00:06, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.79G/9.98G [07:14<00:07, 25.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.80G/9.98G [07:14<00:06, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.80G/9.98G [07:14<00:05, 30.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 16:05:22] Energy consumed for RAM : 0.030624 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 16:05:22] Energy consumed for all GPUs : 0.197787 kWh. Total GPU Power : 28.064000000000004 W\n",
            "[codecarbon INFO @ 16:05:22] Energy consumed for all CPUs : 0.136503 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 16:05:22] 0.364915 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n",
            "\rpytorch_model-00001-of-00002.bin:  98% 9.80G/9.98G [07:14<00:06, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.81G/9.98G [07:15<00:08, 20.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.81G/9.98G [07:15<00:06, 24.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.82G/9.98G [07:15<00:05, 28.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.82G/9.98G [07:15<00:05, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  98% 9.82G/9.98G [07:15<00:06, 22.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.83G/9.98G [07:15<00:05, 26.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.83G/9.98G [07:15<00:04, 30.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [07:16<00:04, 28.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [07:16<00:06, 20.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.84G/9.98G [07:16<00:05, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.85G/9.98G [07:16<00:04, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.85G/9.98G [07:16<00:04, 27.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.86G/9.98G [07:16<00:04, 24.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.86G/9.98G [07:17<00:04, 27.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.86G/9.98G [07:17<00:03, 31.6MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.87G/9.98G [07:17<00:03, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.87G/9.98G [07:17<00:04, 24.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.88G/9.98G [07:17<00:03, 28.1MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.88G/9.98G [07:17<00:02, 32.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.88G/9.98G [07:17<00:03, 29.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.89G/9.98G [07:18<00:04, 21.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.89G/9.98G [07:18<00:03, 25.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.90G/9.98G [07:18<00:02, 29.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.90G/9.98G [07:18<00:02, 27.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.90G/9.98G [07:18<00:03, 22.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.91G/9.98G [07:18<00:02, 26.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.91G/9.98G [07:18<00:02, 30.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.92G/9.98G [07:19<00:02, 28.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.92G/9.98G [07:19<00:02, 24.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin:  99% 9.92G/9.98G [07:19<00:01, 28.2MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.93G/9.98G [07:19<00:01, 31.8MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.93G/9.98G [07:19<00:01, 29.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.94G/9.98G [07:19<00:01, 20.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.94G/9.98G [07:20<00:01, 24.4MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.94G/9.98G [07:20<00:01, 28.0MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.95G/9.98G [07:20<00:01, 26.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.95G/9.98G [07:20<00:01, 21.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.96G/9.98G [07:20<00:00, 24.9MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.96G/9.98G [07:20<00:00, 28.7MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.96G/9.98G [07:20<00:00, 27.5MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.97G/9.98G [07:21<00:00, 22.3MB/s]\u001b[A\u001b[A\u001b[A\u001b[A\n",
            "\n",
            "\n",
            "\n",
            "pytorch_model-00001-of-00002.bin: 100% 9.98G/9.98G [07:21<00:00, 22.6MB/s]\n",
            "\n",
            "\n",
            "\n",
            "Upload 13 LFS files: 100% 13/13 [07:24<00:00, 34.19s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training 10 epochs"
      ],
      "metadata": {
        "id": "x96-SgV6BYJa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!autotrain llm --train --deploy --project_name Llama2-CodeGeneration-PEFT-QLora --model TinyPixel/Llama-2-7B-bf16-sharded --data_path . --use_peft --use_int4 --lora_r 16 --lora_alpha 32 --lora_dropout 0.05 --learning_rate 2e-4 --fp16 --train_batch_size 4 --num_train_epochs 10 --trainer sft --push_to_hub --repo_id AhmedSSoliman/Llama2-CodeGeneration-PEFT-QLora"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2txIn55fjgTY",
        "outputId": "3d7e65fb-d361-4037-db05-1fc5e18bafec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-25 07:56:31.168236: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[32m2023-07-25 07:56:32.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m446\u001b[0m - \u001b[1mRunning LLM\u001b[0m\n",
            "\u001b[32m2023-07-25 07:56:32.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.cli.run_llm\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m447\u001b[0m - \u001b[1mTrain: True\u001b[0m\n",
            "\u001b[32m2023-07-25 07:56:32.519\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.trainers.clm\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m38\u001b[0m - \u001b[1mloading dataset from csv\u001b[0m\n",
            "Using pad_token, but it is not set yet.\n",
            "Loading checkpoint shards: 100% 14/14 [01:18<00:00,  5.60s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/peft/utils/other.py:102: FutureWarning: prepare_model_for_int8_training is deprecated and will be removed in a future version. Use prepare_model_for_kbit_training instead.\n",
            "  warnings.warn(\n",
            "Running tokenizer on train dataset:   0% 0/2000 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (1910 > 1024). Running this sequence through the model will result in indexing errors\n",
            "\u001b[32m2023-07-25 07:58:10.484\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.trainers.clm\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m195\u001b[0m - \u001b[1mcreating trainer\u001b[0m\n",
            "{'loss': 1.549, 'learning_rate': 3.884892086330936e-05, 'epoch': 0.19}\n",
            "{'loss': 1.4963, 'learning_rate': 7.769784172661872e-05, 'epoch': 0.39}\n",
            "{'loss': 1.3328, 'learning_rate': 0.00011654676258992807, 'epoch': 0.58}\n",
            "{'loss': 1.3301, 'learning_rate': 0.00015539568345323743, 'epoch': 0.78}\n",
            "{'loss': 1.2812, 'learning_rate': 0.00019424460431654677, 'epoch': 0.97}\n",
            "{'loss': 1.2482, 'learning_rate': 0.00019632294164668266, 'epoch': 1.17}\n",
            "{'loss': 1.2125, 'learning_rate': 0.00019232613908872902, 'epoch': 1.36}\n",
            "{'loss': 1.2375, 'learning_rate': 0.00018800959232613911, 'epoch': 1.55}\n",
            "{'loss': 1.2194, 'learning_rate': 0.00018369304556354915, 'epoch': 1.75}\n",
            "{'loss': 1.2609, 'learning_rate': 0.00017937649880095925, 'epoch': 1.94}\n",
            "{'loss': 1.1878, 'learning_rate': 0.00017505995203836931, 'epoch': 2.14}\n",
            "{'loss': 1.1476, 'learning_rate': 0.00017074340527577938, 'epoch': 2.33}\n",
            "{'loss': 1.1598, 'learning_rate': 0.00016642685851318948, 'epoch': 2.53}\n",
            "{'loss': 1.173, 'learning_rate': 0.00016211031175059952, 'epoch': 2.72}\n",
            "{'loss': 1.2194, 'learning_rate': 0.00015795363709032774, 'epoch': 2.91}\n",
            "{'loss': 1.1671, 'learning_rate': 0.0001536370903277378, 'epoch': 3.11}\n",
            "{'loss': 1.1033, 'learning_rate': 0.00014948041566746604, 'epoch': 3.3}\n",
            "{'loss': 1.0815, 'learning_rate': 0.0001451638689048761, 'epoch': 3.5}\n",
            "{'loss': 1.101, 'learning_rate': 0.00014084732214228617, 'epoch': 3.69}\n",
            "{'loss': 1.15, 'learning_rate': 0.00013653077537969626, 'epoch': 3.88}\n",
            "{'loss': 1.1112, 'learning_rate': 0.00013221422861710633, 'epoch': 4.08}\n",
            "{'loss': 1.0166, 'learning_rate': 0.00012789768185451637, 'epoch': 4.27}\n",
            "{'loss': 1.065, 'learning_rate': 0.00012358113509192646, 'epoch': 4.47}\n",
            "{'loss': 1.0492, 'learning_rate': 0.00011926458832933653, 'epoch': 4.66}\n",
            "{'loss': 1.0537, 'learning_rate': 0.00011510791366906474, 'epoch': 4.86}\n",
            "{'loss': 1.0318, 'learning_rate': 0.00011079136690647482, 'epoch': 5.05}\n",
            "{'loss': 0.995, 'learning_rate': 0.0001064748201438849, 'epoch': 5.24}\n",
            "{'loss': 0.9672, 'learning_rate': 0.00010215827338129497, 'epoch': 5.44}\n",
            "{'loss': 0.982, 'learning_rate': 9.784172661870504e-05, 'epoch': 5.63}\n",
            "{'loss': 0.9903, 'learning_rate': 9.35251798561151e-05, 'epoch': 5.83}\n",
            "{'loss': 0.9499, 'learning_rate': 8.920863309352519e-05, 'epoch': 6.02}\n",
            "{'loss': 0.9114, 'learning_rate': 8.489208633093527e-05, 'epoch': 6.22}\n",
            "{'loss': 0.8999, 'learning_rate': 8.057553956834533e-05, 'epoch': 6.41}\n",
            "{'loss': 0.9058, 'learning_rate': 7.62589928057554e-05, 'epoch': 6.6}\n",
            "{'loss': 0.9145, 'learning_rate': 7.194244604316547e-05, 'epoch': 6.8}\n",
            "{'loss': 0.916, 'learning_rate': 6.762589928057555e-05, 'epoch': 6.99}\n",
            "{'loss': 0.8342, 'learning_rate': 6.330935251798561e-05, 'epoch': 7.19}\n",
            "{'loss': 0.8306, 'learning_rate': 5.899280575539569e-05, 'epoch': 7.38}\n",
            "{'loss': 0.8498, 'learning_rate': 5.467625899280576e-05, 'epoch': 7.58}\n",
            "{'loss': 0.8586, 'learning_rate': 5.035971223021583e-05, 'epoch': 7.77}\n",
            "{'loss': 0.8446, 'learning_rate': 4.60431654676259e-05, 'epoch': 7.96}\n",
            "{'loss': 0.7874, 'learning_rate': 4.1726618705035975e-05, 'epoch': 8.16}\n",
            "{'loss': 0.7878, 'learning_rate': 3.741007194244605e-05, 'epoch': 8.35}\n",
            "{'loss': 0.7925, 'learning_rate': 3.3093525179856116e-05, 'epoch': 8.55}\n",
            "{'loss': 0.7718, 'learning_rate': 2.8776978417266186e-05, 'epoch': 8.74}\n",
            "{'loss': 0.8144, 'learning_rate': 2.446043165467626e-05, 'epoch': 8.94}\n",
            "{'loss': 0.7823, 'learning_rate': 2.0143884892086333e-05, 'epoch': 9.13}\n",
            "{'loss': 0.7531, 'learning_rate': 1.5827338129496403e-05, 'epoch': 9.32}\n",
            "{'loss': 0.7178, 'learning_rate': 1.1510791366906475e-05, 'epoch': 9.52}\n",
            "{'loss': 0.7573, 'learning_rate': 7.1942446043165465e-06, 'epoch': 9.71}\n",
            "{'loss': 0.7352, 'learning_rate': 2.877697841726619e-06, 'epoch': 9.91}\n",
            "{'train_runtime': 18658.1791, 'train_samples_per_second': 0.298, 'train_steps_per_second': 0.074, 'train_loss': 1.0239761606394815, 'epoch': 10.0}\n",
            "100% 1390/1390 [5:10:58<00:00, 13.42s/it]\n",
            "\u001b[32m2023-07-25 13:09:08.924\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.trainers.clm\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m282\u001b[0m - \u001b[1mFinished training, saving model...\u001b[0m\n",
            "\u001b[32m2023-07-25 13:09:09.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.trainers.clm\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m292\u001b[0m - \u001b[1mMerging adapter weights...\u001b[0m\n",
            "\u001b[32m2023-07-25 13:09:09.046\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.trainers.utils\u001b[0m:\u001b[36mmerge_adapter\u001b[0m:\u001b[36m137\u001b[0m - \u001b[1mLoading adapter...\u001b[0m\n",
            "Loading checkpoint shards: 100% 14/14 [01:18<00:00,  5.59s/it]\n",
            "\u001b[32m2023-07-25 13:10:59.700\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.trainers.utils\u001b[0m:\u001b[36mmerge_adapter\u001b[0m:\u001b[36m153\u001b[0m - \u001b[1mSaving target model...\u001b[0m\n",
            "\u001b[32m2023-07-25 13:12:13.250\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mautotrain.trainers.clm\u001b[0m:\u001b[36mtrain\u001b[0m:\u001b[36m300\u001b[0m - \u001b[1mPushing model to hub...\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "dYTEuOoBZUgw"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clwHjcaiZUgx"
      },
      "source": [
        "## Load adapters from the Hub\n",
        "\n",
        "You can also directly load adapters from the Hub using the commands below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669,
          "referenced_widgets": [
            "28a3a95470574580b6e74f025d4eb595",
            "90087e4446cc44318f7caa41e7f1f171",
            "efd4197b467d436e8d0b084d5823d045",
            "0e8918d7a2ba4e95acdc06c0f2b89f7a",
            "7d99ff57c79d4f33b4b0c7854526d157",
            "e2c2fcc5df234cbd9487bd79768431b8",
            "4ecfd01cf64b45b78bfc4a0b18afd5db",
            "21f093dae11d4b4e861da80961509c98",
            "fbe4a2fc487d4123a6411df784cf96c6",
            "c6bce9d4e9c24eb1940756484b0ea171",
            "d84217b3e83045f4a7a9f7710beb7222",
            "04b692376ac646838a9e0a2471ae82c7",
            "097913fedca84347a345ef6974d3ae6b",
            "5cb7f8daeb54492794a83709a1145fa3",
            "a5a2313f9f9946f48747438580d70c7d",
            "f006e672922148b89c9cca7ef4297c18",
            "5b17ae2abff849c9af3a51075f24f1c5",
            "ef6fcc874fbe47c4b61c01edc798bdc1",
            "feeddd92353d43c7b8801c10dc07dbec",
            "38cb1189d5024754919c4f62e0e5ac32",
            "dbc93e345590472aa94d72287d698a7e",
            "de13d399656b47398a3e1cbbdb0ce1e6",
            "01a947f787a94c9684f5b71a43bcd2b7",
            "4412ecd1ff72401097270c00858ee7fe",
            "4b6a7d82ad9a40b29d0afc1c0e4094c2",
            "98fbb3449bce48d8bf29e60bd6d34a8c",
            "3d5e416bd56c41f694163b0ca95062dc",
            "9f180ba3b14845548c0359d3154fcf14",
            "2051ad57c43148c081c35769fcf74805",
            "37a221676b3447628e5510e6eb3ff495",
            "caeb9363a9b84db9a13bdd5ad458a8f6",
            "eccb734a720649d180562f1140b50aa7",
            "5dd8822533f84470ad5020ade74a087d"
          ]
        },
        "outputId": "2d35276f-8783-41f9-da0a-2e48bf78b091",
        "id": "05ZA68oGZUgz"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/adapter_config.json:   0%|          | 0.00/455 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "28a3a95470574580b6e74f025d4eb595"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/14 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "04b692376ac646838a9e0a2471ae82c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 18:10:52] Energy consumed for RAM : 0.050571 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 18:10:52] Energy consumed for all GPUs : 0.257863 kWh. Total GPU Power : 31.740000000000006 W\n",
            "[codecarbon INFO @ 18:10:52] Energy consumed for all CPUs : 0.225388 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 18:10:52] 0.533822 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:11:07] Energy consumed for RAM : 0.050611 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 18:11:07] Energy consumed for all GPUs : 0.257995 kWh. Total GPU Power : 31.740000000000006 W\n",
            "[codecarbon INFO @ 18:11:07] Energy consumed for all CPUs : 0.225565 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 18:11:07] 0.534171 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:11:22] Energy consumed for RAM : 0.050650 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 18:11:22] Energy consumed for all GPUs : 0.258127 kWh. Total GPU Power : 31.740000000000006 W\n",
            "[codecarbon INFO @ 18:11:22] Energy consumed for all CPUs : 0.225742 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 18:11:22] 0.534520 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:11:37] Energy consumed for RAM : 0.050690 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 18:11:37] Energy consumed for all GPUs : 0.258260 kWh. Total GPU Power : 31.740000000000006 W\n",
            "[codecarbon INFO @ 18:11:37] Energy consumed for all CPUs : 0.225919 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 18:11:37] 0.534869 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:11:52] Energy consumed for RAM : 0.050730 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 18:11:52] Energy consumed for all GPUs : 0.258392 kWh. Total GPU Power : 31.837999999999997 W\n",
            "[codecarbon INFO @ 18:11:52] Energy consumed for all CPUs : 0.226096 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 18:11:52] 0.535218 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:12:07] Energy consumed for RAM : 0.050770 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 18:12:07] Energy consumed for all GPUs : 0.258524 kWh. Total GPU Power : 31.740000000000006 W\n",
            "[codecarbon INFO @ 18:12:07] Energy consumed for all CPUs : 0.226273 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 18:12:07] 0.535567 kWh of electricity used since the beginning.\n",
            "[codecarbon INFO @ 18:12:22] Energy consumed for RAM : 0.050809 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 18:12:22] Energy consumed for all GPUs : 0.258657 kWh. Total GPU Power : 31.758000000000003 W\n",
            "[codecarbon INFO @ 18:12:22] Energy consumed for all CPUs : 0.226450 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 18:12:22] 0.535916 kWh of electricity used since the beginning.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading adapter_model.bin:   0%|          | 0.00/67.2M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01a947f787a94c9684f5b71a43bcd2b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[codecarbon INFO @ 18:12:37] Energy consumed for RAM : 0.050849 kWh. RAM Power : 9.54426097869873 W\n",
            "[codecarbon INFO @ 18:12:37] Energy consumed for all GPUs : 0.258789 kWh. Total GPU Power : 31.758000000000003 W\n",
            "[codecarbon INFO @ 18:12:37] Energy consumed for all CPUs : 0.226627 kWh. Total CPU Power : 42.5 W\n",
            "[codecarbon INFO @ 18:12:37] 0.536265 kWh of electricity used since the beginning.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from peft import PeftModel, PeftConfig\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "peft_model_id = \"AhmedSSoliman/Llama2-CodeGen-PEFT-QLora\"\n",
        "config = PeftConfig.from_pretrained(peft_model_id)\n",
        "model = AutoModelForCausalLM.from_pretrained(config.base_model_name_or_path, trust_remote_code=True, return_dict=True, load_in_4bit=True, device_map='auto')\n",
        "tokenizer = AutoTokenizer.from_pretrained(config.base_model_name_or_path)\n",
        "\n",
        "# Load the Lora model\n",
        "model = PeftModel.from_pretrained(model, peft_model_id)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#text = \"\"\"Compute anomaly scores for the time series.\"\"\"\n",
        "text = \"\"\"Write a prgram that add two variables\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "Yrjlp8IeZUg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tokenizer(text, return_tensors=\"pt\")\n",
        "outputs = model.generate(**inputs, max_new_tokens=200)\n",
        "print(tokenizer.decode(outputs[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpOYmJYvZUg2",
        "outputId": "46cf64bf-0d5a-44c5-ae23-5b9a16e2bc2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a prgram that add two variables\n",
            "\n",
            "    >>> add_two_variables(1, 2)\n",
            "    3\n",
            "### Response: \n",
            "def add_two_variables(x, y):\n",
            "    \n",
            "    return x + y ### Input: \n",
            "Return\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Inference**"
      ],
      "metadata": {
        "id": "iNiyAHRloeZN"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dF5sbSMeCrBH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer, GenerationConfig\n",
        "\n",
        "\n",
        "def create_prompt(instruction):\n",
        "  system = \"You are using the Llam2-CodeGen model, a coding assistant that will help the user to resolve the following instruction:\\n\"\n",
        "  instruction = \"### Input: \" + instruction\n",
        "  return system + \"\\n\" + instruction + \"\\n\\n\" + \"### Response:\" + \"\\n\"\n",
        "\n",
        "def generate(\n",
        "        instruction,\n",
        "        max_new_tokens=128,\n",
        "        temperature=0.1,\n",
        "        top_p=0.75,\n",
        "        top_k=40,\n",
        "        num_beams=4,\n",
        "        **kwargs,\n",
        "):\n",
        "    prompt = create_prompt(instruction)\n",
        "    print(prompt)\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
        "    #input_ids = inputs[\"input_ids\"].to(\"cuda\")\n",
        "    #attention_mask = inputs[\"attention_mask\"].to(\"cuda\")\n",
        "\n",
        "    generation_config = GenerationConfig(\n",
        "        temperature=temperature,\n",
        "        top_p=top_p,\n",
        "        top_k=top_k,\n",
        "        num_beams=num_beams,\n",
        "        **kwargs,\n",
        "    )\n",
        "    with torch.no_grad():\n",
        "        generation_output = model.generate(\n",
        "            #input_ids=input_ids,\n",
        "            #attention_mask=attention_mask,\n",
        "            **inputs,\n",
        "            generation_config=generation_config,\n",
        "            return_dict_in_generate=True,\n",
        "            output_scores=True,\n",
        "            max_new_tokens=max_new_tokens,\n",
        "            early_stopping=True\n",
        "        )\n",
        "\n",
        "\n",
        "\n",
        "    generated_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    stop_output = \"### Input\"\n",
        "    gen_response = (generated_response.split(stop_output))[0]\n",
        "\n",
        "\n",
        "    #s = generation_output.sequences[0]\n",
        "    #output = tokenizer.decode(s, skip_special_tokens=True)\n",
        "    #stop_output = \"### Input\"\n",
        "\n",
        "    #gen_response = (output.split(stop_output))[0]\n",
        "\n",
        "\n",
        "    #return output.split(\"### Response:\")[1].lstrip(\"\\n\")\n",
        "    return gen_response\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "1am8cvxBdCFo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"\n",
        " Write a python code for the name Ahmed to be in a reversed order\n",
        "\"\"\"\n",
        "print(generate(instruction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RLRHpA-vdHsD",
        "outputId": "0608ecf6-6bc5-42df-f9fe-855859782584"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using the Llam2-CodeGen model, a coding assistant that will help the user to resolve the following instruction:\n",
            "\n",
            "### Input: \n",
            " Write a python code for the name Ahmed to be in a reversed order\n",
            "\n",
            "\n",
            "### Response:\n",
            "\n",
            "Write a python code for the name Ahmed to be in a reversed order.Ћ\n",
            "def reverse_name(name):\n",
            "    return name[::-1] \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"\n",
        "Write a program that add five numbers\n",
        "\"\"\"\n",
        "print(generate(instruction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MjdwDaRl8b0",
        "outputId": "f2c5534c-7a85-46af-c3cc-1e4bd48746df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a coding assistant that will help the user to resolve the following instruction:\n",
            "### Input: \n",
            "Write a program that add five numbers\n",
            "\n",
            "\n",
            "### Response:\n",
            "\n",
            "def main():\n",
            "    \n",
            "    n1 = int(input(\"Enter the first number: \"))\n",
            "    n2 = int(input(\"Enter the second number: \"))\n",
            "    n3 = int(input(\"Enter the third number: \"))\n",
            "    n4 = int(input(\"Enter the fourth number: \"))\n",
            "    n5 = int(input(\"Enter the fifth number: \"))\n",
            "\n",
            "    sum = n1 + n2 + n3 + n4 + n5\n",
            "\n",
            "    print(\"The sum of the five numbers is \" + str(sum))\n",
            "\n",
            "    return main<s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "instruction = \"\"\"\n",
        "Write a python code for reading multiple images from path\n",
        "\"\"\"\n",
        "print(generate(instruction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYULETRVo9gW",
        "outputId": "05169361-7a0d-4442-8087-e59b6079e6af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a coding assistant that will help the user to resolve the following instruction:\n",
            "### Input: \n",
            "Write a python code for reading multiple images from path\n",
            "\n",
            "\n",
            "### Response:\n",
            "\n",
            "def read_multiple_images(path):\n",
            "    \n",
            "    images = []\n",
            "    for image_name in os.listdir(path):\n",
            "        image_path = os.path.join(path, image_name)\n",
            "        if os.path.isfile(image_path):\n",
            "            images.append(cv2.imread(image_path))\n",
            "    return np.array(images)<s> ### Input: \n",
            "Returns a list of all the files in the given directory.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instrution = \"\"\"\n",
        "Set width of output ('auto' will auto-detect terminal width)\n",
        "\"\"\"\n",
        "print(generate(instruction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CP2adeQWqUwC",
        "outputId": "100d7a03-550e-431d-8c28-f6f272ac24f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are a coding assistant that will help the user to resolve the following instruction:\n",
            "### Input: \n",
            "Write a python code for reading multiple images from path\n",
            "\n",
            "\n",
            "### Response:\n",
            "\n",
            "def read_multiple_images(path):\n",
            "    \n",
            "    images = []\n",
            "    for image_name in os.listdir(path):\n",
            "        image_path = os.path.join(path, image_name)\n",
            "        if os.path.isfile(image_path):\n",
            "            images.append(cv2.imread(image_path))\n",
            "    return np.array(images)<s> ### Input: \n",
            "Returns a list of all the files in the given directory.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "instruction = \"\"\"\n",
        " Write a python code for the name Ahmed to be in a reversed order\n",
        "\"\"\"\n",
        "print(generate(instruction))"
      ],
      "metadata": {
        "id": "io_hLDamC3wd"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "collapsed_sections": [
        "gfg4ahEYypTp",
        "Rnqmq7amRrU8",
        "OFcCMFzCWEDO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3a1b1dbe3bae41109d063853bd34374a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d6bb9105ed604843a9b5d78e1f5a1684",
              "IPY_MODEL_90c7541f5d274bf9af2c8887cbe2cc39",
              "IPY_MODEL_6016d6696875478aa25b20b0eb6e5cae"
            ],
            "layout": "IPY_MODEL_71b2df00163b40358b10e8fc3f9b8d45"
          }
        },
        "d6bb9105ed604843a9b5d78e1f5a1684": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f8ff5c66848447c8adc9735642fb434",
            "placeholder": "​",
            "style": "IPY_MODEL_6d52b567a5584451a5470c4cfc4631a0",
            "value": "100%"
          }
        },
        "90c7541f5d274bf9af2c8887cbe2cc39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2bddb364f8ad4f3982e5f69656d89388",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_984cc05deea64b8eb9263af7fdeacca2",
            "value": 3
          }
        },
        "6016d6696875478aa25b20b0eb6e5cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5e4365a3c074c1eaab5c71530dfe2c4",
            "placeholder": "​",
            "style": "IPY_MODEL_bf1548816c7647f8baf3bb005b9c33b3",
            "value": " 3/3 [00:00&lt;00:00, 105.70it/s]"
          }
        },
        "71b2df00163b40358b10e8fc3f9b8d45": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f8ff5c66848447c8adc9735642fb434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d52b567a5584451a5470c4cfc4631a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bddb364f8ad4f3982e5f69656d89388": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984cc05deea64b8eb9263af7fdeacca2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5e4365a3c074c1eaab5c71530dfe2c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1548816c7647f8baf3bb005b9c33b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "28a3a95470574580b6e74f025d4eb595": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90087e4446cc44318f7caa41e7f1f171",
              "IPY_MODEL_efd4197b467d436e8d0b084d5823d045",
              "IPY_MODEL_0e8918d7a2ba4e95acdc06c0f2b89f7a"
            ],
            "layout": "IPY_MODEL_7d99ff57c79d4f33b4b0c7854526d157"
          }
        },
        "90087e4446cc44318f7caa41e7f1f171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e2c2fcc5df234cbd9487bd79768431b8",
            "placeholder": "​",
            "style": "IPY_MODEL_4ecfd01cf64b45b78bfc4a0b18afd5db",
            "value": "Downloading (…)/adapter_config.json: 100%"
          }
        },
        "efd4197b467d436e8d0b084d5823d045": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21f093dae11d4b4e861da80961509c98",
            "max": 455,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fbe4a2fc487d4123a6411df784cf96c6",
            "value": 455
          }
        },
        "0e8918d7a2ba4e95acdc06c0f2b89f7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c6bce9d4e9c24eb1940756484b0ea171",
            "placeholder": "​",
            "style": "IPY_MODEL_d84217b3e83045f4a7a9f7710beb7222",
            "value": " 455/455 [00:00&lt;00:00, 38.1kB/s]"
          }
        },
        "7d99ff57c79d4f33b4b0c7854526d157": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2c2fcc5df234cbd9487bd79768431b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ecfd01cf64b45b78bfc4a0b18afd5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "21f093dae11d4b4e861da80961509c98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbe4a2fc487d4123a6411df784cf96c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c6bce9d4e9c24eb1940756484b0ea171": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d84217b3e83045f4a7a9f7710beb7222": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "04b692376ac646838a9e0a2471ae82c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_097913fedca84347a345ef6974d3ae6b",
              "IPY_MODEL_5cb7f8daeb54492794a83709a1145fa3",
              "IPY_MODEL_a5a2313f9f9946f48747438580d70c7d"
            ],
            "layout": "IPY_MODEL_f006e672922148b89c9cca7ef4297c18"
          }
        },
        "097913fedca84347a345ef6974d3ae6b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5b17ae2abff849c9af3a51075f24f1c5",
            "placeholder": "​",
            "style": "IPY_MODEL_ef6fcc874fbe47c4b61c01edc798bdc1",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "5cb7f8daeb54492794a83709a1145fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_feeddd92353d43c7b8801c10dc07dbec",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38cb1189d5024754919c4f62e0e5ac32",
            "value": 14
          }
        },
        "a5a2313f9f9946f48747438580d70c7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dbc93e345590472aa94d72287d698a7e",
            "placeholder": "​",
            "style": "IPY_MODEL_de13d399656b47398a3e1cbbdb0ce1e6",
            "value": " 14/14 [01:31&lt;00:00,  6.33s/it]"
          }
        },
        "f006e672922148b89c9cca7ef4297c18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b17ae2abff849c9af3a51075f24f1c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef6fcc874fbe47c4b61c01edc798bdc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "feeddd92353d43c7b8801c10dc07dbec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38cb1189d5024754919c4f62e0e5ac32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dbc93e345590472aa94d72287d698a7e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de13d399656b47398a3e1cbbdb0ce1e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "01a947f787a94c9684f5b71a43bcd2b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4412ecd1ff72401097270c00858ee7fe",
              "IPY_MODEL_4b6a7d82ad9a40b29d0afc1c0e4094c2",
              "IPY_MODEL_98fbb3449bce48d8bf29e60bd6d34a8c"
            ],
            "layout": "IPY_MODEL_3d5e416bd56c41f694163b0ca95062dc"
          }
        },
        "4412ecd1ff72401097270c00858ee7fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f180ba3b14845548c0359d3154fcf14",
            "placeholder": "​",
            "style": "IPY_MODEL_2051ad57c43148c081c35769fcf74805",
            "value": "Downloading adapter_model.bin: 100%"
          }
        },
        "4b6a7d82ad9a40b29d0afc1c0e4094c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37a221676b3447628e5510e6eb3ff495",
            "max": 67154893,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_caeb9363a9b84db9a13bdd5ad458a8f6",
            "value": 67154893
          }
        },
        "98fbb3449bce48d8bf29e60bd6d34a8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eccb734a720649d180562f1140b50aa7",
            "placeholder": "​",
            "style": "IPY_MODEL_5dd8822533f84470ad5020ade74a087d",
            "value": " 67.2M/67.2M [00:08&lt;00:00, 13.6MB/s]"
          }
        },
        "3d5e416bd56c41f694163b0ca95062dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f180ba3b14845548c0359d3154fcf14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2051ad57c43148c081c35769fcf74805": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "37a221676b3447628e5510e6eb3ff495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "caeb9363a9b84db9a13bdd5ad458a8f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "eccb734a720649d180562f1140b50aa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5dd8822533f84470ad5020ade74a087d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}